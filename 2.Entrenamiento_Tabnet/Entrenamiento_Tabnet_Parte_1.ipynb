{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UN-GCPDS/Curso-Corto-LLMs/blob/main/2.Entrenamiento_Tabnet/Entrenamiento_Tabnet_Parte_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Logo UNAL CHEC](https://github.com/UN-GCPDS/curso_IA_CHEC/blob/main/logo_unal_chec.jpg?raw=1)\n",
        "\n",
        "# **Entrenamiento modelo Tabnet**\n",
        "\n",
        "## **Descripción**\n",
        "\n",
        "Entrenamiento de modelo Tabnet bajo diversas condiciones.\n",
        "\n",
        "### **Profesor - Sesión 1:** Andrés Marino Álvarez Meza y Diego Armando Pérez Rosero"
      ],
      "metadata": {
        "id": "mFZXuItQprV2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Datos\n",
        "\n",
        "**TabNet para criticidad en redes de media tensión — Planteamiento y datos (Regresión)**\n",
        "\n",
        "Sea el conjunto de datos\n",
        "\n",
        "$$\n",
        "\\mathbf{X}\\in\\mathbb{R}^{N\\times M},\\qquad\n",
        "\\mathbf{y}\\in\\mathbb{R}^{N}.\n",
        "$$\n",
        "\n",
        "Cada fila de $\\mathbf{X}$ representa un evento o periodo entre 2019 y 2024 y contiene las características de los elementos asociados al equipo que operó. El vector $\\mathbf{y}$ almacena el valor continuo del indicador a modelar (SAIDI o SAIFI) para ese mismo evento/periodo.\n",
        "\n",
        "Definimos\n",
        "\n",
        "$$\n",
        "\\mathcal{F}:\\mathcal{X}\\subseteq\\mathbb{R}^{M}\\to\\mathbb{R},\\qquad\n",
        "\\hat{y}=\\mathcal{F}(\\mathbf{x})\n",
        "=\n",
        "\\bigl(\\,\\breve{f}_{L}\\circ \\breve{f}_{L-1}\\circ \\cdots \\circ \\breve{f}_{1}\\,\\bigr)(\\mathbf{x}),\n",
        "$$\n",
        "\n",
        "donde $\\breve{f}_{l}(\\cdot)$ denota el $l$-ésimo bloque del modelo ($l\\in\\{1,\\dots,L\\}$) y $\\circ$ es el operador de composición.\n",
        "\n",
        "En caso multisalida para $(\\text{SAIDI},\\text{SAIFI})$, se toma $\\mathcal{F}:\\mathbb{R}^{M}\\to\\mathbb{R}^{2}$ y $\\mathbf{y}\\in\\mathbb{R}^{N\\times 2}$.\n",
        "![Logo UNAL CHEC](https://raw.githubusercontent.com/Daprosero/Deep-Convolutional-Generative-Adversarial-Network/refs/heads/master/Mercados%20CHEC.png)"
      ],
      "metadata": {
        "id": "NHmuwRJcqrHN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9h3KDG32hY8a",
        "outputId": "98b471f4-a238-486c-bcb1-016388f45dac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openTSNE in /usr/local/lib/python3.12/dist-packages (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.12/dist-packages (from openTSNE) (2.0.2)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.12/dist-packages (from openTSNE) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from openTSNE) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.20->openTSNE) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.20->openTSNE) (3.6.0)\n",
            "Requirement already satisfied: pytorch-tabnet in /usr/local/lib/python3.12/dist-packages (4.1.0)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.12/dist-packages (4.5.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from pytorch-tabnet) (2.0.2)\n",
            "Requirement already satisfied: scikit_learn>0.21 in /usr/local/lib/python3.12/dist-packages (from pytorch-tabnet) (1.6.1)\n",
            "Requirement already satisfied: scipy>1.4 in /usr/local/lib/python3.12/dist-packages (from pytorch-tabnet) (1.16.1)\n",
            "Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.12/dist-packages (from pytorch-tabnet) (2.8.0+cu126)\n",
            "Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.12/dist-packages (from pytorch-tabnet) (4.67.1)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (1.16.5)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.12/dist-packages (from optuna) (6.9.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.43)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (4.15.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (3.6.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (3.19.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.3->pytorch-tabnet) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.3->pytorch-tabnet) (3.0.2)\n",
            "/usr/local/lib/python3.12/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1o_fZIhk6ErrtrM3eVZPF9s2qj8l4FoqS\n",
            "From (redirected): https://drive.google.com/uc?id=1o_fZIhk6ErrtrM3eVZPF9s2qj8l4FoqS&confirm=t&uuid=be8bd5d8-9b06-4fcf-9f09-89d4ef149d5a\n",
            "To: /content/SuperEventos_Criticidad_AguasAbajo_CODEs.zip\n",
            "100% 214M/214M [00:02<00:00, 99.1MB/s]\n",
            "/usr/local/lib/python3.12/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1lBrseLoEmr6-VwNSCHOp2zuc4sKKrkbQ\n",
            "From (redirected): https://drive.google.com/uc?id=1lBrseLoEmr6-VwNSCHOp2zuc4sKKrkbQ&confirm=t&uuid=343fda9b-a2d9-49cf-a50d-3d8ee5a779e4\n",
            "To: /content/model.zip\n",
            "100% 109M/109M [00:01<00:00, 88.2MB/s]\n",
            "/usr/local/lib/python3.12/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=16VIuHLgPGpX4J723Wd48UAPhHivLuUaH\n",
            "From (redirected): https://drive.google.com/uc?id=16VIuHLgPGpX4J723Wd48UAPhHivLuUaH&confirm=t&uuid=a98de35f-f6da-4aee-8312-37d298b96f22\n",
            "To: /content/Data_CHEC.zip\n",
            "100% 336M/336M [00:03<00:00, 106MB/s]\n"
          ]
        }
      ],
      "source": [
        "#@title Librerías\n",
        "# Instalación de paquetes necesarios\n",
        "!pip install -q gdown\n",
        "!pip install openTSNE\n",
        "!pip install pytorch-tabnet optuna\n",
        "!pip install wget --quiet\n",
        "\n",
        "# Importación de librerías necesarias\n",
        "import optuna\n",
        "import warnings\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.special import softmax\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler, QuantileTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, accuracy_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from pytorch_tabnet.tab_model import TabNetRegressor, TabNetClassifier\n",
        "from pytorch_tabnet.augmentations import RegressionSMOTE\n",
        "from google.colab import drive\n",
        "import tensorflow as tf\n",
        "import tensorflow_probability as tfp\n",
        "import os\n",
        "from pathlib import Path\n",
        "import math\n",
        "import wget\n",
        "!gdown --id 1o_fZIhk6ErrtrM3eVZPF9s2qj8l4FoqS -O SuperEventos_Criticidad_AguasAbajo_CODEs.zip\n",
        "!gdown --id 1lBrseLoEmr6-VwNSCHOp2zuc4sKKrkbQ -O model.zip\n",
        "!gdown --id 16VIuHLgPGpX4J723Wd48UAPhHivLuUaH -O Data_CHEC.zip\n",
        "\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_path = \"SuperEventos_Criticidad_AguasAbajo_CODEs.zip\"\n",
        "extract_dir = \"CHEC\"\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)\n",
        "\n",
        "zip_path = \"model.zip\"\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)\n",
        "\n",
        "zip_path = \"Data_CHEC.zip\"\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)\n",
        "\n",
        "# Supresión de warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"pandas\")\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "# Función auxiliar para etiquetas\n",
        "def get_labels(x: pd.Series) -> pd.Series:\n",
        "    labels, _ = pd.factorize(x)\n",
        "    return pd.Series(labels, name=x.name, index=x.index)\n",
        "\n",
        "# Definición de funciones personalizadas de pérdida\n",
        "def my_mse_loss_fn(y_pred, y_true):\n",
        "    mse_loss = (y_true - y_pred) ** 2\n",
        "    return torch.mean(mse_loss)\n",
        "import re\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_var_band(\n",
        "    df,\n",
        "    var_token,\n",
        "    row_index=0,\n",
        "    hours_back=24,\n",
        "    col_patterns=None,\n",
        "    display_name=None,\n",
        "    units=None,\n",
        "    event_label=\"evento reportado\",\n",
        "):\n",
        "    \"\"\"\n",
        "    Grafica una variable climática en una franja de horas hacia atrás.\n",
        "\n",
        "    Parámetros\n",
        "    ----------\n",
        "    df : pd.DataFrame\n",
        "        Contiene columnas por hora para la variable elegida.\n",
        "        Ejemplos de nombres soportados automáticamente:\n",
        "        - 'h0-<var>', 'h1-<var>', ..., 'h24-<var>'\n",
        "        - '<var>_h0', '<var>_h1', ...\n",
        "        con separadores '_' o '-'.\n",
        "\n",
        "    var_token : str\n",
        "        Nombre base de la variable en los nombres de columna (p.ej. 'wind_gust_spd',\n",
        "        'air_temp', 'precip'). Debe coincidir con lo que aparece en las columnas.\n",
        "\n",
        "    row_index : int\n",
        "        Fila (evento) a graficar.\n",
        "\n",
        "    hours_back : int\n",
        "        Cuántas horas hacia atrás mostrar.\n",
        "\n",
        "    col_patterns : list[str] | None\n",
        "        Lista de regex opcionales para detectar columnas por hora.\n",
        "        Si None, se generan automáticamente a partir de var_token.\n",
        "\n",
        "    display_name : str | None\n",
        "        Etiqueta legible para el eje Y (p.ej. 'Ráfaga de viento').\n",
        "        Si None, se usa var_token.\n",
        "\n",
        "    units : str | None\n",
        "        Unidades para concatenar en la etiqueta Y (p.ej. 'm/s', '°C', 'mm').\n",
        "\n",
        "    event_label : str\n",
        "        Texto para la flecha en la hora 0.\n",
        "    \"\"\"\n",
        "    # --- 1) Preparar patrones de columnas ---\n",
        "    if col_patterns is None:\n",
        "        # Permitir '_' o '-' (o espacio) entre partes del var_token\n",
        "        parts = re.split(r'[_\\-\\s]+', var_token.strip())\n",
        "        # Construimos un regex que tolere '_' o '-' entre partes\n",
        "        # ej: 'wind[_-]?gust[_-]?spd'\n",
        "        var_regex = r'[_-]?'.join(map(re.escape, parts))\n",
        "\n",
        "        col_patterns = [\n",
        "            rf'^h(\\d{{1,2}})[-_]?{var_regex}$',   # h0-<var>  o  h0_<var>\n",
        "            rf'^{var_regex}[-_]?h(\\d{{1,2}})$',   # <var>-h0  o  <var>_h0\n",
        "        ]\n",
        "\n",
        "    # --- 2) Detectar columnas y mapear a hora ---\n",
        "    hour_to_col = {}\n",
        "    for c in df.columns:\n",
        "        for pat in col_patterns:\n",
        "            m = re.match(pat, str(c), flags=re.IGNORECASE)\n",
        "            if m:\n",
        "                h = int(m.group(1))\n",
        "                hour_to_col[h] = c\n",
        "                break\n",
        "\n",
        "    if not hour_to_col:\n",
        "        raise ValueError(\n",
        "            f\"No se encontraron columnas con horas para la variable '{var_token}'.\\n\"\n",
        "            f\"Prueba ajustando 'var_token' o pasando 'col_patterns' personalizados.\"\n",
        "        )\n",
        "\n",
        "    # --- 3) Construir serie horas [0..hours_back] si existen, orden ascendente ---\n",
        "    hours = [h for h in sorted(hour_to_col.keys()) if 0 <= h <= hours_back]\n",
        "    vals = np.array(\n",
        "        [pd.to_numeric(df.loc[df.index[row_index], hour_to_col[h]], errors='coerce') for h in hours],\n",
        "        dtype=float\n",
        "    )\n",
        "\n",
        "    # --- 4) Graficar ---\n",
        "    fig, ax = plt.subplots(figsize=(10, 5))\n",
        "\n",
        "    # línea y puntos\n",
        "    ax.plot(hours, vals, marker='o')\n",
        "\n",
        "    # invertir eje X para que se vea 24 -> 0\n",
        "    ax.set_xlim(hours_back, 0)\n",
        "\n",
        "    # franja sombreada\n",
        "    ymin = np.nanmin(vals) if np.isfinite(np.nanmin(vals)) else 0.0\n",
        "    ymax = np.nanmax(vals) if np.isfinite(np.nanmax(vals)) else 1.0\n",
        "    pad  = 0.05 * (ymax - ymin if ymax > ymin else 1.0)\n",
        "    ax.set_ylim(ymin - pad, ymax + pad)\n",
        "    ax.axvspan(0, hours_back, alpha=0.15)\n",
        "\n",
        "    # flecha y etiqueta en hora 0\n",
        "    y0 = vals[hours.index(0)] if 0 in hours else np.nan\n",
        "    if not np.isfinite(y0):\n",
        "        y0 = np.nanmedian(vals) if np.isfinite(np.nanmedian(vals)) else (ymin + ymax) / 2.0\n",
        "\n",
        "    ax.annotate(\n",
        "        event_label,\n",
        "        xy=(0, y0),\n",
        "        xytext=(max(2, min(4, hours_back*0.15)), y0 + (ymax - y0)*0.15),\n",
        "        arrowprops=dict(arrowstyle=\"->\", lw=1),\n",
        "        ha='left', va='bottom'\n",
        "    )\n",
        "\n",
        "    # etiquetas\n",
        "    ylab = display_name if display_name else var_token\n",
        "    if units:\n",
        "        ylab = f\"{ylab} [{units}]\"\n",
        "    ax.set_xlabel(\"Horas antes del evento\")\n",
        "    ax.set_ylabel(ylab)\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "    # ticks principales (24, 18, 12, 6, 0) si corresponde\n",
        "    xticks = [h for h in [hours_back, 18, 12, 6, 0] if 0 <= h <= hours_back]\n",
        "    ax.set_xticks(xticks)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# --- Ejemplo de uso:\n",
        "# plot_wind_gust_band(df=tu_dataframe, row_index=0, hours_back=24)\n",
        "\n",
        "def my_rmse_loss_fn(y_pred, y_true):\n",
        "    mse_loss = (y_true - y_pred) ** 2\n",
        "    mean_mse_loss = torch.mean(mse_loss)\n",
        "    rmse_loss = torch.sqrt(mean_mse_loss)\n",
        "    return rmse_loss\n",
        "\n",
        "def my_mae_loss_fn(y_pred, y_true):\n",
        "    mae_loss = torch.abs(y_true - y_pred)\n",
        "    return torch.mean(mae_loss)\n",
        "\n",
        "def my_mape_loss_fn(y_pred, y_true):\n",
        "    mape_loss = torch.abs((y_true - y_pred) / y_true) * 100\n",
        "    return torch.mean(mape_loss)\n",
        "\n",
        "def my_r2_score_fn(y_pred, y_true):\n",
        "    total_variance = torch.var(y_true, unbiased=False)\n",
        "    unexplained_variance = torch.mean((y_true - y_pred) ** 2)\n",
        "    r2_score = 1 - (unexplained_variance / total_variance)\n",
        "    return 1-r2_score\n",
        "\n",
        "# Etapa 0: imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "# ==== Librerías ====\n",
        "import numpy as np\n",
        "import cupy as cp\n",
        "import xgboost as xgb\n",
        "\n",
        "from cuml.ensemble import RandomForestRegressor as cuRF\n",
        "from cuml.metrics import r2_score as r2_gpu\n",
        "\n",
        "# Si quieres comparar con CPU para sanity-check:\n",
        "from sklearn.metrics import r2_score as r2_cpu\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "# ==== Utilidades ====\n",
        "def to_cpu(a):\n",
        "    \"\"\"Convierte CuPy -> NumPy si aplica.\"\"\"\n",
        "    try:\n",
        "        if isinstance(a, cp.ndarray):\n",
        "            return cp.asnumpy(a)\n",
        "    except Exception:\n",
        "        pass\n",
        "    return a\n",
        "\n",
        "def metrics_gpu(y_true_cp, y_pred_cp):\n",
        "    \"\"\"MAE, RMSE, R2 calculados en GPU (CuPy).\"\"\"\n",
        "    y_true_cp = cp.asarray(y_true_cp)\n",
        "    y_pred_cp = cp.asarray(y_pred_cp)\n",
        "    mae  = float(cp.mean(cp.abs(y_true_cp - y_pred_cp)))\n",
        "    rmse = float(cp.sqrt(cp.mean((y_true_cp - y_pred_cp)**2)))\n",
        "    ssr  = float(cp.sum((y_true_cp - y_pred_cp)**2))\n",
        "    sst  = float(cp.sum((y_true_cp - cp.mean(y_true_cp))**2))\n",
        "    r2   = 1.0 - ssr / sst if sst > 0 else np.nan\n",
        "    return mae, rmse, r2\n",
        "\n",
        "def permutation_importance_rf_gpu(model, X_val_cp, y_val_cp, n_repeats=3, max_feats=None, random_state=42):\n",
        "    \"\"\"\n",
        "    Permutation importance en GPU para RF cuML.\n",
        "    Devuelve importancia por feature (drop medio de R2 en valid).\n",
        "    Si max_feats no es None, calcula solo para las primeras max_feats columnas (para acelerar).\n",
        "    \"\"\"\n",
        "    rs = cp.random.RandomState(random_state)\n",
        "    X_val_cp = cp.asarray(X_val_cp)\n",
        "    y_val_cp = cp.asarray(y_val_cp)\n",
        "\n",
        "    # R2 base\n",
        "    y_pred_base = model.predict(X_val_cp)\n",
        "    _, _, r2_base = metrics_gpu(y_val_cp, y_pred_base)\n",
        "\n",
        "    n, d = X_val_cp.shape\n",
        "    d_eval = d if max_feats is None else int(min(max_feats, d))\n",
        "    importances = cp.zeros(d, dtype=cp.float32)\n",
        "\n",
        "    for j in range(d_eval):\n",
        "        drops = []\n",
        "        for _ in range(n_repeats):\n",
        "            Xp = X_val_cp.copy()\n",
        "            idx = rs.permutation(n)\n",
        "            Xp[:, j] = Xp[idx, j]  # permutar solo la columna j\n",
        "            y_pred_p = model.predict(Xp)\n",
        "            _, _, r2_p = metrics_gpu(y_val_cp, y_pred_p)\n",
        "            drops.append(r2_base - r2_p)\n",
        "        importances[j] = cp.mean(cp.asarray(drops))\n",
        "\n",
        "    return importances  # CuPy array\n",
        "def regression_metrics(y_true, y_pred):\n",
        "    mae  = float(np.mean(np.abs(y_true - y_pred)))\n",
        "    rmse = float(np.sqrt(np.mean((y_true - y_pred)**2)))\n",
        "    ss_res = float(np.sum((y_true - y_pred)**2))\n",
        "    ss_tot = float(np.sum((y_true - np.mean(y_true))**2))\n",
        "    r2 = 1 - ss_res/ss_tot if ss_tot > 0 else np.nan\n",
        "    return mae, rmse, r2\n",
        "class CustomTabNetRegressor(TabNetRegressor):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(CustomTabNetRegressor, self).__init__(*args, **kwargs)\n",
        "\n",
        "    def forward(self, X):\n",
        "        output, M_loss = self.network(X)\n",
        "        output = torch.relu(output)\n",
        "        return output, M_loss\n",
        "\n",
        "    def predict(self, X):\n",
        "        device = next(self.network.parameters()).device\n",
        "        if not isinstance(X, torch.Tensor):\n",
        "            X = torch.tensor(X, dtype=torch.float32)\n",
        "        X = X.to(device)\n",
        "        with torch.no_grad():\n",
        "            output, _ = self.forward(X)\n",
        "        return output.cpu().numpy()\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.spatial import cKDTree\n",
        "from tqdm import tqdm\n",
        "from ast import literal_eval\n",
        "from pandas.api.types import is_numeric_dtype\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "def make_strat_labels(y_vals, n_bins=3, min_per_class=2):\n",
        "    \"\"\"\n",
        "    Genera etiquetas para estratificar a partir de un objetivo continuo.\n",
        "    Reduce bins si no hay suficientes muestras por clase.\n",
        "    \"\"\"\n",
        "    y1d = y_vals.reshape(-1)\n",
        "    for bins in range(n_bins, 1, -1):\n",
        "        pct = np.linspace(0, 100, bins + 1)[1:-1]\n",
        "        cuts = np.percentile(y1d, pct)\n",
        "        if np.any(np.diff(cuts) <= 0):\n",
        "            continue\n",
        "        labels = np.digitize(y1d, bins=cuts).astype(int)\n",
        "        counts = Counter(labels)\n",
        "        if all(c >= min_per_class for c in counts.values()) and len(counts) > 1:\n",
        "            return labels\n",
        "    return None\n",
        "\n",
        "def stratify_from_df_or_y(df_labels, idx, y_subset, col='NIVEL_C'):\n",
        "    \"\"\"Intenta usar df[col] como etiqueta; si falla, usa percentiles en y_subset.\"\"\"\n",
        "    try:\n",
        "        ycat_full = df_labels.loc[:, col].values.astype(int)\n",
        "        ycat = ycat_full[idx]\n",
        "        c10 = Counter(ycat)\n",
        "        if all(v >= 2 for v in c10.values()) and len(c10) > 1:\n",
        "            return ycat\n",
        "    except Exception:\n",
        "        pass\n",
        "    return make_strat_labels(y_subset[:,0], n_bins=3, min_per_class=2)\n",
        "\n",
        "def split_subset(X, y, df_labels=None, n_sub=1000, test_size=0.20, seed=42):\n",
        "    \"\"\"\n",
        "    1) Toma un subset aleatorio de tamaño n_sub.\n",
        "    2) Escala y (MinMax) sobre el subset.\n",
        "    3) Split train/test con estratificación si es viable.\n",
        "    4) Split train/valid (20% del train), con re-estratificación si es posible.\n",
        "    \"\"\"\n",
        "    rng = np.random.RandomState(seed)\n",
        "    n_total = X.shape[0]\n",
        "    n_sub = min(n_sub, n_total)\n",
        "    idx_sub = rng.choice(n_total, size=n_sub, replace=False)\n",
        "\n",
        "    X_sub = X[idx_sub]\n",
        "    y_sub = y[idx_sub]\n",
        "    # etiquetas auxiliares para estratificación\n",
        "    ycat_sub = stratify_from_df_or_y(df_labels, idx_sub, y_sub) if df_labels is not None else make_strat_labels(y_sub[:,0])\n",
        "    # escalar objetivo en el subset\n",
        "    scaler = MinMaxScaler()\n",
        "    y_sub_scaled = scaler.fit_transform(y_sub)\n",
        "\n",
        "    split_kwargs = dict(test_size=test_size, random_state=seed, shuffle=True)\n",
        "    if ycat_sub is not None:\n",
        "        X_tr, X_te, y_tr, y_te, ycat_tr, ycat_te = train_test_split(\n",
        "            X_sub, y_sub_scaled, ycat_sub, stratify=ycat_sub, **split_kwargs\n",
        "        )\n",
        "    else:\n",
        "        X_tr, X_te, y_tr, y_te = train_test_split(X_sub, y_sub_scaled, **split_kwargs)\n",
        "        ycat_tr = ycat_te = None\n",
        "\n",
        "    # Validación (20% del train)\n",
        "    if ycat_tr is not None:\n",
        "        y_tr_raw = y_tr[:,0]\n",
        "        ycat_t = make_strat_labels(y_tr_raw, n_bins=3, min_per_class=2)\n",
        "        if ycat_t is not None:\n",
        "            X_tr, X_va, y_tr, y_va, ycat_tr, ycat_va = train_test_split(\n",
        "                X_tr, y_tr, ycat_tr, test_size=0.20, random_state=seed, stratify=ycat_t\n",
        "            )\n",
        "        else:\n",
        "            X_tr, X_va, y_tr, y_va = train_test_split(\n",
        "                X_tr, y_tr, test_size=0.20, random_state=seed, shuffle=True\n",
        "            )\n",
        "            ycat_va = None\n",
        "    else:\n",
        "        X_tr, X_va, y_tr, y_va = train_test_split(\n",
        "            X_tr, y_tr, test_size=0.20, random_state=seed, shuffle=True\n",
        "        )\n",
        "        ycat_va = None\n",
        "\n",
        "    # Reporte rápido\n",
        "    print(\"Originales (conservados):\", X_orig.shape, y_orig.shape)\n",
        "    print(f\"Subset de {n_sub}:\", X_sub.shape, y_sub.shape)\n",
        "    print(\"Train/Valid/Test:\", X_tr.shape, X_va.shape, X_te.shape)\n",
        "    if ycat_sub is not None:\n",
        "        print(\"Distribución clases subset:\", Counter(ycat_sub))\n",
        "\n",
        "    return {\n",
        "        \"idx_sub\": idx_sub,\n",
        "        \"X_train\": X_tr, \"X_valid\": X_va, \"X_test\": X_te,\n",
        "        \"y_train\": y_tr, \"y_valid\": y_va, \"y_test\": y_te\n",
        "    }\n",
        "from copy import deepcopy\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "def eval_and_print(title, clf_model, X_test, y_test):\n",
        "    \"\"\"Evalúa R² en escala original (inverse_transform) y lo imprime.\"\"\"\n",
        "    y_pred = clf_model.predict(X_test)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    print(f\"{title}: R2={r2:.4f}\")\n",
        "    return r2\n",
        "\n",
        "def run_three_training_strategies(\n",
        "    # modelos / kwargs\n",
        "    clf_base,                   # modelo ya entrenado en la Fase 1 (con warm_start=True)\n",
        "    model_init_kwargs,          # dict con los kwargs para construir un modelo nuevo idéntico (desde cero)\n",
        "    # datos antiguos (Fase 1)\n",
        "    X_train_old, y_train_old,   # típicamente (X_train, y_train[:,0:1]) de los 1000\n",
        "    X_test_old, y_test_old,  # test y scaler usados en la Fase 1\n",
        "    # datos nuevos (Fase 2)\n",
        "    X_tr_new, y_tr_new,         # train de los 500\n",
        "    X_va_new, y_va_new,         # valid de los 500 (para early stopping)\n",
        "    X_te_new, y_te_new,  # test nuevo y su scaler\n",
        "    # entrenamiento\n",
        "    batch_size, virtual_batch_size, aug,\n",
        "    max_epochs_ft_inc=200, patience_ft_inc=70,\n",
        "    max_epochs_ft_new=200, patience_ft_new=70,\n",
        "    max_epochs_scratch=200, patience_scratch=70,\n",
        "    lower_lr_factor=0.1, min_lr=1e-5\n",
        "):\n",
        "    \"\"\"\n",
        "    Ejecuta:\n",
        "      A) Fine-tuning incremental (old + new)\n",
        "      B) Fine-tuning no incremental (solo new)\n",
        "      C) Desde cero (old + new)\n",
        "    y evalúa R² en test viejo y test nuevo (ambos en escala original).\n",
        "    Devuelve un dict con los R².\n",
        "    \"\"\"\n",
        "    results = {}\n",
        "\n",
        "    # =============================\n",
        "    # A) Fine-tuning incremental\n",
        "    # =============================\n",
        "    clf_ft_inc = deepcopy(clf_base)  # copia del clf ya entrenado\n",
        "    # bajar LR para fine-tune (opcional, recomendado)\n",
        "    if hasattr(clf_ft_inc, \"_optimizer\"):\n",
        "        for g in clf_ft_inc._optimizer.param_groups:\n",
        "            g[\"lr\"] = max(g[\"lr\"] * lower_lr_factor, min_lr)\n",
        "\n",
        "    X_inc = np.concatenate([X_train_old, X_tr_new], axis=0)\n",
        "    y_inc = np.concatenate([y_train_old, y_tr_new], axis=0)\n",
        "\n",
        "    clf_ft_inc.fit(\n",
        "        X_train=X_inc, y_train=y_inc,\n",
        "        eval_set=[(X_inc, y_inc), (X_va_new, y_va_new)],\n",
        "        eval_name=['train_inc', 'valid_new'],\n",
        "        eval_metric=['mae'], loss_fn=my_r2_score_fn,\n",
        "        max_epochs=max_epochs_ft_inc, patience=patience_ft_inc,\n",
        "        batch_size=batch_size, virtual_batch_size=virtual_batch_size,\n",
        "        num_workers=1, drop_last=False, augmentations=aug,\n",
        "    )\n",
        "\n",
        "    print(\"\\n== Desempeño: Fine-tuning incremental ==\")\n",
        "    r2_old_inc = eval_and_print(\"Test viejo (FT incremental)\", clf_ft_inc, X_test_old, y_test_old)\n",
        "    r2_new_inc = eval_and_print(\"Test nuevo (FT incremental)\", clf_ft_inc, X_te_new,  y_te_new)\n",
        "    results[\"fine_tune_incremental\"] = {\"R2_old_test\": r2_old_inc, \"R2_new_test\": r2_new_inc, \"model\": clf_ft_inc}\n",
        "\n",
        "    # =============================\n",
        "    # B) Fine-tuning no incremental (solo nuevos)\n",
        "    # =============================\n",
        "    clf_ft_new = deepcopy(clf_base)\n",
        "    if hasattr(clf_ft_new, \"_optimizer\"):\n",
        "        for g in clf_ft_new._optimizer.param_groups:\n",
        "            g[\"lr\"] = max(g[\"lr\"] * lower_lr_factor, min_lr)\n",
        "\n",
        "    clf_ft_new.fit(\n",
        "        X_train=X_tr_new, y_train=y_tr_new,\n",
        "        eval_set=[(X_tr_new, y_tr_new), (X_va_new, y_va_new)],\n",
        "        eval_name=['train_new', 'valid_new'],\n",
        "        eval_metric=['mae'], loss_fn=my_r2_score_fn,\n",
        "        max_epochs=max_epochs_ft_new, patience=patience_ft_new,\n",
        "        batch_size=batch_size, virtual_batch_size=virtual_batch_size,\n",
        "        num_workers=1, drop_last=False, augmentations=aug,\n",
        "    )\n",
        "\n",
        "    print(\"\\n== Desempeño: Fine-tuning NO incremental (solo nuevos) ==\")\n",
        "    r2_old_new = eval_and_print(\"Test viejo (FT no incremental)\", clf_ft_new, X_test_old, y_test_old)\n",
        "    r2_new_new = eval_and_print(\"Test nuevo (FT no incremental)\", clf_ft_new, X_te_new,  y_te_new)\n",
        "    results[\"fine_tune_only_new\"] = {\"R2_old_test\": r2_old_new, \"R2_new_test\": r2_new_new, \"model\": clf_ft_new}\n",
        "\n",
        "    # =============================\n",
        "    # C) Desde cero (cumulative old+new)\n",
        "    # =============================\n",
        "    # model_init_kwargs debe contener todo lo necesario para reconstruir el TabNet\n",
        "    clf_scratch = CustomTabNetRegressor(**model_init_kwargs)\n",
        "\n",
        "    X_cum = np.concatenate([X_train_old, X_tr_new], axis=0)\n",
        "    y_cum = np.concatenate([y_train_old, y_tr_new], axis=0)\n",
        "\n",
        "    clf_scratch.fit(\n",
        "        X_train=X_cum, y_train=y_cum,\n",
        "        eval_set=[(X_cum, y_cum), (X_va_new, y_va_new)],\n",
        "        eval_name=['train_cum', 'valid_new'],\n",
        "        eval_metric=['mae'], loss_fn=my_r2_score_fn,\n",
        "        max_epochs=max_epochs_scratch, patience=patience_scratch,\n",
        "        batch_size=batch_size, virtual_batch_size=virtual_batch_size,\n",
        "        num_workers=1, drop_last=False, augmentations=aug,\n",
        "    )\n",
        "\n",
        "    print(\"\\n== Desempeño: Desde cero (old+new) ==\")\n",
        "    r2_old_sc = eval_and_print(\"Test viejo (desde cero)\", clf_scratch, X_test_old, y_test_old)\n",
        "    r2_new_sc = eval_and_print(\"Test nuevo (desde cero)\", clf_scratch, X_te_new,  y_te_new)\n",
        "    results[\"from_scratch\"] = {\"R2_old_test\": r2_old_sc, \"R2_new_test\": r2_new_sc, \"model\": clf_scratch}\n",
        "    return results\n",
        "def pick_new_indices(n_new=500, seed=123):\n",
        "    rng = np.random.RandomState(seed)\n",
        "    universe = np.setdiff1d(np.arange(X.shape[0]), splits_1000[\"idx_sub\"], assume_unique=True)\n",
        "    n_new = min(n_new, universe.shape[0])\n",
        "    return rng.choice(universe, size=n_new, replace=False)\n",
        "Xdata = df = pd.read_pickle('/content/CHEC/SuperEventos_Criticidad_AguasAbajo_CODEs.pkl')\n",
        "Xdata = Xdata[Xdata['duracion_h'] <= 100]\n",
        "# ---------------------------------------------------------\n",
        "# Etapa 1: seleccionar objetivo (SAIDI o SAIFI) con forma (N,1)\n",
        "# Extraer variables objetivo\n",
        "Dur_h = Xdata['duracion_h'].values\n",
        "SAIDI = Xdata['SAIDI'].values\n",
        "df1=Xdata.copy()\n",
        "# Eliminar columnas no utilizadas\n",
        "Xdata.drop(['inicio_evento', 'h0-solar_rad', 'h0-uv', 'h1-solar_rad', 'h1-uv', 'h2-solar_rad', 'h2-uv', 'h3-solar_rad', 'h3-uv',\n",
        "            'h4-solar_rad', 'h4-uv', 'h5-solar_rad', 'h5-uv', 'h19-solar_rad', 'h19-uv', 'h20-solar_rad', 'h20-uv',\n",
        "            'h21-solar_rad', 'h21-uv', 'h22-solar_rad', 'h22-uv', 'h23-solar_rad', 'h23-uv', 'evento', 'fin', 'inicio',\n",
        "            'cnt_usus', 'DEP', 'MUN', 'FECHA', 'NIVEL_C', 'VALOR_C', 'TRAMOS_AGUAS_ABAJO', 'EQUIPOS_PUNTOS',\n",
        "            'PUNTOS_POLIGONO', 'LONGITUD2', 'LATITUD2', 'FECHA_C','TRAMOS_AGUAS_ABAJO_CODES','ORDER_'],\n",
        "           inplace=True, axis=1)\n",
        "\n",
        "# Definir la variable objetivo y eliminarla del conjunto de características\n",
        "target = ['SAIFI', 'SAIDI', 'duracion_h']\n",
        "y1 = Xdata[target].values\n",
        "Xdata.drop(target, axis=1, inplace=True)\n",
        "y = y1[:, 0:1].astype('float32')\n",
        "\n",
        "# Copia de trabajo de X\n",
        "df = Xdata.copy()\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Etapa 2: tipificar columnas\n",
        "NUMERIC_COLUMNS = df.select_dtypes(include=['number']).columns.tolist()\n",
        "CATEGORICAL_COLUMNS = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Etapa 3: imputación numérica\n",
        "max_values = {}\n",
        "for col in NUMERIC_COLUMNS:\n",
        "    max_value = pd.to_numeric(df[col], errors='coerce').max()\n",
        "    if pd.isna(max_value):\n",
        "        max_value = 0.0\n",
        "    max_values[col] = max_value\n",
        "    df[col] = pd.to_numeric(df[col], errors='coerce').fillna(-10.0 * max_value)\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Etapa 4: codificación categórica\n",
        "label_encoders = {}\n",
        "categorical_dims = {}\n",
        "for col in CATEGORICAL_COLUMNS:\n",
        "    enc = LabelEncoder()\n",
        "    s = df[col].astype(str).fillna(\"no aplica\")\n",
        "    enc.fit(s)\n",
        "    df[col] = enc.transform(s)\n",
        "    label_encoders[col] = enc\n",
        "    categorical_dims[col] = len(enc.classes_)\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Etapa 5: construir matrices X, y\n",
        "unused_feat = []\n",
        "# Si Xdata NO incluye el target, basta con tomar todas las columnas\n",
        "features = [c for c in df.columns if c not in unused_feat]\n",
        "X = df[features].values.astype('float32')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape,y.shape\n",
        "\n",
        "# Etapa 6: clases auxiliares para estratificación\n",
        "try:\n",
        "    # usar etiqueta externa si existe\n",
        "    y_categorized = df1['NIVEL_C'].values.astype(int)\n",
        "except Exception:\n",
        "    # fallback: terciles del objetivo\n",
        "    percentiles = np.percentile(y[:, 0], [33.33, 66.66])\n",
        "    y_categorized = np.digitize(y[:, 0].flatten(), bins=percentiles).astype(int)\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Etapa 7: escalar objetivo (regresión)\n",
        "scaler = MinMaxScaler()\n",
        "y_scaled = scaler.fit_transform(y)\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Etapa 8: split train/test estratificado\n",
        "X_train, X_test, y_train, y_test, ycat_train, ycat_test = train_test_split(\n",
        "    X, y_scaled, y_categorized, test_size=0.20, random_state=42, stratify=y_categorized\n",
        ")\n",
        "\n",
        "# Etapa 8b: split train/valid estratificado por percentiles de y_train\n",
        "percentiles_t = np.percentile(y_train[:, 0], [25, 50, 75])\n",
        "y_categorized_t = np.digitize(y_train[:, 0].flatten(), bins=percentiles_t).astype(int)\n",
        "\n",
        "X_train, X_valid, y_train, y_valid, ycat_train, ycat_valid = train_test_split(\n",
        "    X_train, y_train, ycat_train, test_size=0.20, random_state=42, stratify=y_categorized_t\n",
        ")\n",
        "\n",
        "# Comprobaciones rápidas\n",
        "print(X.shape, y.shape)\n",
        "print(\"Train/Valid/Test:\", X_train.shape, X_valid.shape, X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYsdpiGqsFhP",
        "outputId": "e36f66cd-b749-47cb-ccf2-1cbdd6402bf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(166323, 312) (166323, 1)\n",
            "Train/Valid/Test: (106446, 312) (26612, 312) (33265, 312)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Logo UNAL CHEC](https://catalog.ngc.nvidia.com/_next/image?url=https%3A%2F%2Fassets.nvidiagrid.net%2Fngc%2Flogos%2FOSS-Nvidia-Partnership-Rapids.png&w=828&q=90)\n",
        "\n",
        "\n",
        "**RAPIDS** es un ecosistema de NVIDIA que replica APIs de *pandas/scikit-learn* en GPU (cuDF, cuML, CuPy), permitiendo ejecutar **preprocesamiento** y **modelos** en la misma memoria de la GPU. Para este proyecto (regresión de SAIDI/SAIFI con millones de filas y decenas–centenas de variables), esto aporta:\n",
        "\n",
        "* **Aceleración efectiva**: entrenamientos y predicciones con cuML (**RandomForest**) y XGBoost en GPU reducen tiempos de minutos/horas a segundos/minutos (según tamaño del dataset y GPU), facilitando *grid search* y validaciones repetidas.\n",
        "* **Menos copias CPU↔GPU**: mover $\\mathbf{X}$ y $\\mathbf{y}$ una sola vez a GPU (CuPy/cuDF) evita cuellos de botella y mantiene el *pipeline* end-to-end en dispositivo.\n",
        "* **Escalabilidad y memoria**: el *pool* de memoria de **RMM** disminuye la fragmentación y estabiliza cargas grandes, clave en árboles y *boosting*.\n",
        "* **Compatibilidad**:\n",
        "\n",
        "  * **cuML** mantiene una interfaz tipo scikit-learn (fit/predict), ideal para **RandomForest** en GPU.\n",
        "  * **XGBoost** usa `device=\"cuda\"` + `tree_method=\"hist\"` y `DeviceQuantileDMatrix`, optimizando entrenamiento con datos densos y continuos.\n",
        "* **Reproducibilidad**: fijar semillas y particiones estratificadas mantiene resultados consistentes entre corridas y modelos.\n"
      ],
      "metadata": {
        "id": "9xgy24BJsYl6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ==== Envío de tus datos a GPU ====\n",
        "# Se asume que ya tienes X_train, X_valid, X_test, y_train, y_valid, y_test definidos en RAM (NumPy/Pandas).\n",
        "Xtr = cp.asarray(X_train)\n",
        "Xva = cp.asarray(X_valid)\n",
        "Xte = cp.asarray(X_test)\n",
        "\n",
        "# objetivo 1D float32\n",
        "ytr = cp.asarray(y_train.ravel().astype('float32'))\n",
        "yva = cp.asarray(y_valid.ravel().astype('float32'))\n",
        "yte = cp.asarray(y_test.ravel().astype('float32'))\n",
        "\n",
        "y_train_1d = y_train.ravel().astype('float32')\n",
        "y_valid_1d = y_valid.ravel().astype('float32')\n",
        "y_test_1d  = y_test.ravel().astype('float32')\n",
        "\n",
        "# Nombres de features si existen; si no, genera f0..f{d-1}\n",
        "try:\n",
        "    feature_names = list(features)\n",
        "except NameError:\n",
        "    feature_names = [f\"f{i}\" for i in range(X_train.shape[1])]\n"
      ],
      "metadata": {
        "id": "e7yksqpTsHwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Árboles de decisión y bosques aleatorios\n",
        "\n",
        "- Los árboles de decisión y los bosques aletorios pertenecen al grupo de algoritmos clásicos más potentes, junto con las máquinas de vectores de soporte.\n",
        "\n",
        "- Su principio se centra en la generación de fronteras de decisión mediante umbralizaciones sobre las características.\n",
        "\n",
        "- Un bosque aleatorio se puede entender como un método de ensamble, a partir de la repartición aleatoria de árboles de decisión que actúan en paralelo sobre distintos atributos, y la decisión final se obtiene mediante voto mayoritario o promedio.\n",
        "![RandomForest](https://github.com/amalvarezme/AprendizajeMaquina/blob/main/4_Clasificacion_Clustering_DR/randomforest.png?raw=1)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GfVgQLk7sgTl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hiperparámetros recomendados (evita el warning de 'rows_sample' no soportado)\n",
        "rf = cuRF(\n",
        "    n_estimators=400,       # más ligero que 600\n",
        "    max_depth=16,          # reduce tiempo/sobreajuste\n",
        "    max_features=0.7,      # fracción de variables por split\n",
        "    min_samples_leaf=5,\n",
        "    min_samples_split=10,\n",
        "    bootstrap=True,\n",
        "    n_streams=8,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "rf.fit(Xtr, ytr)\n",
        "\n",
        "# Predicciones\n",
        "y_pred_val_rf = rf.predict(Xva)\n",
        "y_pred_te_rf  = rf.predict(Xte)\n",
        "\n",
        "# Métricas (GPU)\n",
        "mae_v, rmse_v, r2_v = metrics_gpu(yva, y_pred_val_rf)\n",
        "mae_t, rmse_t, r2_t = metrics_gpu(yte, y_pred_te_rf)\n",
        "\n",
        "\n",
        "print(f\"[RF cuML] Test  -> R2={r2_t:.4f}  MAE={mae_t:.4f}  RMSE={rmse_t:.4f}\")\n",
        "\n",
        "# (Opcional) comparación con sklearn en CPU para sanity-check\n",
        "print(f\"[RF sklearn] R2 Test (CPU): {r2_cpu(to_cpu(yte), to_cpu(y_pred_te_rf)):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8huQZANMsb_t",
        "outputId": "11f170cd-ecad-451a-bc1b-a1b964450ffe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RF cuML] Test  -> R2=0.8709  MAE=0.0008  RMSE=0.0051\n",
            "[RF sklearn] R2 Test (CPU): 0.8709\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost (Gradient Boosted Trees)\n",
        "\n",
        "* XGBoost es una implementación optimizada de *gradient boosting* para árboles de decisión, ampliamente competitiva en datos tabulares por su eficiencia, control de sobreajuste y soporte nativo en GPU.\n",
        "\n",
        "* Su principio consiste en **aprender de forma aditiva** una suma de árboles que van corrigiendo el error del modelo previo mediante gradientes (de primer y segundo orden) de la función de pérdida, con regularización $L_1/L_2$, tasa de aprendizaje (*shrinkage*), y submuestreo de filas/columnas.\n",
        "\n",
        "* A diferencia de los bosques aleatorios (árboles en paralelo con voto/promedio), en XGBoost los árboles se **entrenan secuencialmente** y la predicción es la **suma** de sus salidas; además incorpora *early stopping*, manejo explícito de valores faltantes y entrenamiento acelerado con `tree_method=\"hist\"` y `device=\"cuda\"`.\n",
        "\n",
        "![RandomForest](https://www.researchgate.net/publication/356698772/figure/fig2/AS:1096436418641951@1638422221975/The-architecture-of-Gradient-Boosting-Decision-Tree.png)\n"
      ],
      "metadata": {
        "id": "jfGle7PNsmrq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dtrain = xgb.DMatrix(Xtr, label=y_train_1d)\n",
        "dvalid = xgb.DMatrix(Xva, label=y_valid_1d)\n",
        "dtest  = xgb.DMatrix(Xte,  label=y_test_1d)\n",
        "\n",
        "# Parámetros XGBoost para regresión en GPU\n",
        "params = {\n",
        "    \"objective\": \"reg:squarederror\",\n",
        "    \"tree_method\": \"hist\",   # <- ya no 'gpu_hist'\n",
        "    \"device\": \"cuda\",        # <- activa GPU\n",
        "    \"max_depth\": 8,\n",
        "    \"eta\": 0.05,\n",
        "    \"subsample\": 0.8,\n",
        "    \"colsample_bytree\": 0.8,\n",
        "    \"lambda\": 1.0,\n",
        "    \"alpha\": 0.0,\n",
        "    \"random_state\": 42,\n",
        "    \"eval_metric\": \"rmse\",\n",
        "    \"verbosity\": 0           # <- silencia logs internos de XGB\n",
        "}\n",
        "\n",
        "num_boost_round = 3000\n",
        "early_stopping_rounds = 100\n",
        "\n",
        "watchlist = [(dtrain, \"train\"), (dvalid, \"valid\")]\n",
        "booster = xgb.train(\n",
        "    params=params,\n",
        "    dtrain=dtrain,\n",
        "    num_boost_round=num_boost_round,\n",
        "    evals=watchlist,\n",
        "    early_stopping_rounds=early_stopping_rounds,\n",
        "    verbose_eval=0\n",
        ")\n",
        "\n",
        "# Predicciones con el mejor número de iteraciones\n",
        "y_pred_valid = booster.predict(dvalid, iteration_range=(0, booster.best_iteration+1))\n",
        "y_pred_test  = booster.predict(dtest,  iteration_range=(0, booster.best_iteration+1))\n",
        "\n",
        "r2_v = regression_metrics(y_valid_1d, y_pred_valid)[2]\n",
        "r2_t = regression_metrics(y_test_1d,  y_pred_test)[2]\n",
        "\n",
        "print(f\"[XGB GPU] Test  -> R2={r2_t:.4f}\")\n",
        "# Obtener nombres de features\n",
        "try:\n",
        "    feature_names = list(features)\n",
        "except NameError:\n",
        "    feature_names = [f\"f{i}\" for i in range(X_train.shape[1])]\n",
        "\n",
        "# Importancias por ganancia\n",
        "imp = booster.get_score(importance_type=\"gain\")  # {'f0':..., 'f12':...}\n",
        "scores = np.zeros(len(feature_names), dtype=np.float32)\n",
        "for k, v in imp.items():\n",
        "    if k.startswith('f'):\n",
        "        idx = int(k[1:])  # 'f10' -> 10\n",
        "        if 0 <= idx < scores.size:\n",
        "            scores[idx] = v\n",
        "\n",
        "# Fallback si 'gain' está vacío\n",
        "if not np.any(scores):\n",
        "    imp = booster.get_score(importance_type=\"weight\")\n",
        "    for k, v in imp.items():\n",
        "        if k.startswith('f'):\n",
        "            idx = int(k[1:])\n",
        "            if 0 <= idx < scores.size:\n",
        "                scores[idx] = v\n",
        "\n",
        "# Normalizar para una escala [0,1] legible\n",
        "if scores.max() > 0:\n",
        "    scores = scores / scores.max()\n",
        "\n",
        "# Seleccionar Top-20\n",
        "TOPK = 20\n",
        "order = np.argsort(scores)[::-1][:TOPK]\n",
        "top_names = [feature_names[i] for i in order]\n",
        "top_scores = scores[order]\n",
        "\n",
        "# Gráfico de barras (vertical), eje x con nombres rotados 90°\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(range(TOPK), top_scores)\n",
        "plt.xticks(range(TOPK), top_names, rotation=90)\n",
        "plt.ylabel(\"Importancia (gain normalizado)\")\n",
        "plt.xlabel(\"Características\")\n",
        "plt.title(\"XGBoost — Top 20 características por importancia\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624
        },
        "id": "HafQJ1L0smMG",
        "outputId": "7e28502c-a48b-4442-d8c8-40ca12d04419"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB GPU] Test  -> R2=0.8861\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TabNet (Attentive Neural Networks for Tabular Data)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EC_HWd_MwhFE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* TabNet es un modelo de *deep learning* para datos tabulares que combina **atención secuencial** y **selección esparsa de variables**, logrando buen rendimiento en regresión/clasificación con interpretabilidad nativa y entrenamiento en GPU (PyTorch/TF).\n",
        "\n",
        "* Su principio consiste en **decisiones en pasos**: en cada paso $t$, un *attentive transformer* produce una máscara $\\mathbf{M}^{(t)}$ (vía *sparsemax*) que **selecciona un subconjunto de características**; un *decision transformer* procesa solo esas columnas y genera una contribución. Las salidas de todos los pasos se **agregan aditivamente** para la predicción, mientras una regularización de **esparsidad** limita el número de variables usadas y controla su reuso ($\\gamma$).\n",
        "\n",
        "* A diferencia de los ensambles de árboles, TabNet **aprende representaciones no lineales** y **selección de variables dependiente del contexto** en un solo modelo end-to-end; además, ofrece **importancias globales** (promedio de máscaras) y **explicaciones locales** por muestra, maneja variables categóricas mediante **embeddings**, soporta *early stopping* y *mini-batches*, y se beneficia de la aceleración en GPU para grandes volúmenes de datos.\n",
        "\n",
        "![RandomForest](https://miro.medium.com/v2/resize:fit:1100/format:webp/1*XWoroyIDVa_ACzcKmigwOQ.png)"
      ],
      "metadata": {
        "id": "qJWz1GUcHDRU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = torch.load(\"/content/CHEC/model.pth\",weights_only=False)\n",
        "\n",
        "y_pred=clf.predict(X_test)\n",
        "y_pred_=np.tile(y_pred, (1, 2))\n",
        "y_pred_ = scaler.inverse_transform(y_pred_)\n",
        "y_test_ = scaler.inverse_transform(y_test)\n",
        "# Plot 2\n",
        "r2_1 = r2_score(y_test_[:, 0], y_pred_[:, 0])\n",
        "print(f\" Test  -> R2={r2_1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WiRs_tmJwnFt",
        "outputId": "744132c8-f1ae-4351-f87b-e33bae6b2baf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Test  -> R2=0.8832\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Importancias globales del modelo (promedio de máscaras de atención)\n",
        "imp = getattr(clf, \"feature_importances_\", None)\n",
        "if imp is None:\n",
        "    raise ValueError(\"clf.feature_importances_ no está disponible; entrena el modelo antes de graficar.\")\n",
        "\n",
        "imp = np.asarray(imp, dtype=float)\n",
        "\n",
        "# Nombres de features\n",
        "try:\n",
        "    feature_names = list(features)\n",
        "except NameError:\n",
        "    feature_names = [f\"f{i}\" for i in range(len(imp))]\n",
        "\n",
        "# Normalizar a [0, 1] para lectura\n",
        "imp_norm = imp / imp.max() if imp.max() > 0 else imp\n",
        "\n",
        "# Top-20\n",
        "TOPK = 20\n",
        "order = np.argsort(imp_norm)[::-1][:TOPK]\n",
        "top_names = [feature_names[i] for i in order]\n",
        "top_scores = imp_norm[order]\n",
        "\n",
        "# Gráfico de barras (como la primera gráfica)\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(range(TOPK), top_scores)\n",
        "plt.xticks(range(TOPK), top_names, rotation=90)\n",
        "plt.ylabel(\"Importancia (normalizada)\")\n",
        "plt.xlabel(\"Características\")\n",
        "plt.title(\"TabNet — Top 20 características (global)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "3eLz8b8bwpGW",
        "outputId": "84b0ce11-caa2-4b0c-b44f-2c7828e80f85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Relevancia local por muestra con TabNet (pytorch-tabnet)\n",
        "# Se asume que tienes un TabNetRegressor entrenado llamado `clf`\n",
        "# y una lista `features` con los nombres de columnas en el mismo orden que X_*.\n",
        "\n",
        "# 1) Selecciona algunas muestras (por índice sobre X_test)\n",
        "idx = [0,100]  # cámbialos por las filas que te interesen\n",
        "X_samples = X_test[idx]\n",
        "\n",
        "# 2) Explicaciones locales\n",
        "# M_explain: (n_muestras, n_features)\n",
        "# masks: lista de largo n_steps con matrices (n_muestras, n_features) por paso\n",
        "M_explain, masks = clf.explain(X_samples)\n",
        "\n",
        "# 3) Normaliza por fila para leer como “peso relativo” (opcional pero útil)\n",
        "M_norm = M_explain / (M_explain.sum(axis=1, keepdims=True) + 1e-12)\n",
        "\n",
        "# 4) Nombres de features\n",
        "try:\n",
        "    feature_names = list(features)\n",
        "except NameError:\n",
        "    feature_names = [f\"f{i}\" for i in range(M_norm.shape[1])]\n",
        "\n",
        "TOPK = 20\n",
        "\n",
        "# 5) Gráfico por muestra (una figura por muestra, barras con rotación 90°)\n",
        "for r, row in enumerate(M_norm):\n",
        "    order = np.argsort(row)[::-1][:TOPK]\n",
        "    names = [feature_names[i] for i in order]\n",
        "    scores = row[order]\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.bar(range(TOPK), scores)\n",
        "    plt.xticks(range(TOPK), names, rotation=90)\n",
        "    plt.ylabel(\"Relevancia normalizada\")\n",
        "    plt.xlabel(\"Características\")\n",
        "    plt.title(f\"TabNet — Top {TOPK} características (muestra idx={idx[r]})\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0l6FamOBwrsA",
        "outputId": "fe142d3f-c09e-4abd-c50d-0896848ffb4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TabNet: fundamentos matemáticos\n"
      ],
      "metadata": {
        "id": "YrnTBU3HBpVO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "![Logo UNAL CHEC](https://ars.els-cdn.com/content/image/1-s2.0-S2590123025027392-gr002.jpg)\n",
        "\n",
        "| **Ecuación** | **Explicación práctica** |\n",
        "|--------------|---------------------------|\n",
        "| $$\\hat{y} = f(X|\\theta) = (N_{\\text{steps}} \\circ N_{\\text{steps-1}} \\circ \\cdots \\circ N_1)(X)$$ | La predicción final se construye aplicando secuencialmente varios bloques de decisión. |\n",
        "| $$a^i = \\text{sparsemax}(P^{i-1} \\odot h_i(a^{i-1}))$$ | En cada paso, el modelo aplica una máscara que selecciona solo algunas variables importantes. |\n",
        "| $$P^i[j] = \\sum_{j=1}^{i} \\frac{1}{\\gamma} \\big(M^i[j]\\big)$$ | Se controla cuántas veces se ha usado cada variable para no repetir siempre las mismas. |\n",
        "| $$[d[i], a[i]] = \\mathcal{F}(M^i \\odot X)$$ | Las variables seleccionadas pasan por un transformador que genera nuevas representaciones útiles. |\n",
        "| $$GLU(h) = (W_h h + b) \\odot \\sigma(W_g h + b_g)$$ | Módulos tipo “puerta” que deciden qué información pasa y cuál se bloquea. |\n",
        "| $$\\hat{X} = \\frac{X - \\mu_{B_v}}{\\sqrt{\\sigma^2_{B_v} + \\epsilon}}$$ | Normalización por mini-lotes virtuales para estabilizar el entrenamiento. |\n",
        "| $$d_{\\text{out}} = \\sum_{i=1}^{N_{\\text{steps}}} \\text{ReLU}(d[i])$$ | Se suman las contribuciones de todos los pasos de decisión. |\n",
        "| $$\\hat{y} = W_{\\text{final}} \\cdot d_{\\text{out}}$$ | El vector combinado se transforma en la predicción final. |\n",
        "| $$\\mathcal{L}_{\\text{task}} = \\tfrac{1}{B} \\sum_{i=1}^{B} \\| y_i - \\hat{y}_i \\|^2$$ | Error cuadrático medio: compara valores reales y predichos. |\n",
        "| $$\\mathcal{L}_{\\text{sparse}} = \\sum_{i=1}^{N_{\\text{steps}}} \\sum_{j=1}^{B} \\sum_{p=1}^{D} M^i_{jp} \\log(M^i_{jp} + \\epsilon)$$ | Penaliza cuando se usan demasiadas variables, fomentando interpretabilidad. |\n",
        "| $$\\mathcal{L} = \\mathcal{L}_{\\text{task}} + \\lambda_{\\text{sparse}} \\mathcal{L}_{\\text{sparse}}$$ | Pérdida total = error de predicción + penalización por esparsidad. |\n",
        "| $$M_{\\text{agg}}^j = \\sum_{i=1}^{N_{\\text{steps}}} \\tfrac{1}{B} \\sum_{b=1}^{B} M^i_{b,j} \\cdot \\text{Imp}_i$$ | Se calcula la importancia global de cada variable sumando las máscaras de todos los pasos. |\n",
        "\n",
        "---\n",
        "\n",
        "Este esquema muestra cómo TabNet combina:  \n",
        "1. **Selección secuencial de variables** (máscaras).  \n",
        "2. **Transformaciones controladas** (GLU, normalización).  \n",
        "3. **Predicción final regulada** (pérdida con sparsidad).  \n",
        "4. **Interpretabilidad** (importancia global de las variables).  \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "H-0-PUtGG-I2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Hiperparámetros propios de TabNet\n",
        "\n"
      ],
      "metadata": {
        "id": "0PPwOe3iHErY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **n_d (dimensión de decisión)** y **n_a (dimensión de atención):**  \n",
        "  Pueden entenderse como la capacidad del modelo para \"pensar\" y \"mirar\".  \n",
        "  - `n_d` es como el tamaño de la libreta donde el modelo escribe lo aprendido para predecir.  \n",
        "  - `n_a` es como el tamaño de los lentes con los que el modelo observa las variables.  \n",
        "  Valores más grandes permiten procesar información con más detalle, pero hacen el modelo más complejo y lento.\n",
        "\n",
        "- **n_steps (número de pasos de decisión):**  \n",
        "  Indica cuántas veces el modelo analiza la información antes de dar una respuesta.  \n",
        "  Más pasos equivalen a revisar los datos con mayor profundidad.\n",
        "\n",
        "- **gamma:**  \n",
        "  Regula cuánto busca el modelo nuevas variables en cada paso.  \n",
        "  Un gamma alto implica mayor exploración, mientras que un gamma bajo concentra la atención en lo ya encontrado.\n",
        "\n",
        "- **lambda_sparse:**  \n",
        "  Controla cuántas variables se seleccionan en cada paso.  \n",
        "  Valores altos fuerzan al modelo a enfocarse en pocas variables (más interpretabilidad),  \n",
        "  mientras que valores bajos permiten considerar más variables (más flexibilidad).\n",
        "\n",
        "- **batch_size:**  \n",
        "  Define cuántas filas del conjunto de datos se procesan al mismo tiempo durante el entrenamiento.  \n",
        "  Batches grandes aceleran el entrenamiento pero requieren más memoria.\n",
        "\n",
        "\n",
        "- **emb (embedding para variables categóricas):**  \n",
        "  Convierte las categorías en vectores numéricos que capturan mejor la información.  \n",
        "  Un tamaño mayor de embedding permite representaciones más ricas, aunque con mayor costo computacional.\n",
        "\n",
        "- **virtual_batch_size:**  \n",
        "  Subdivisión interna del batch, utilizada para estabilizar el entrenamiento mediante  \n",
        "  la técnica llamada *Ghost Batch Normalization*.  \n",
        "  Sirve para que los cálculos estadísticos de normalización sean más estables incluso con batches grandes.\n",
        "\n",
        "---\n",
        "\n",
        "En conjunto, estos hiperparámetros permiten balancear tres aspectos clave:  \n",
        "1. **Capacidad predictiva** (precisión del modelo).  \n",
        "2. **Eficiencia computacional** (tiempo y recursos de entrenamiento).  \n",
        "3. **Interpretabilidad** (capacidad de explicar qué variables fueron importantes).  "
      ],
      "metadata": {
        "id": "8UUZ7C6zHIg8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_orig = X.copy()\n",
        "y_orig = y.copy()"
      ],
      "metadata": {
        "id": "Zrp6KXM0q6gk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Custom TabNet + Objective\n",
        "# =========================\n",
        "import torch\n",
        "from pytorch_tabnet.tab_model import TabNetRegressor\n",
        "\n",
        "class CustomTabNetRegressor(TabNetRegressor):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(CustomTabNetRegressor, self).__init__(*args, **kwargs)\n",
        "    def forward(self, X):\n",
        "        output, M_loss = self.network(X)\n",
        "        output = torch.relu(output)\n",
        "        return output, M_loss\n",
        "    def predict(self, X):\n",
        "        device = next(self.network.parameters()).device\n",
        "        if not isinstance(X, torch.Tensor):\n",
        "            X = torch.tensor(X, dtype=torch.float32)\n",
        "        X = X.to(device)\n",
        "        with torch.no_grad():\n",
        "            output, _ = self.forward(X)\n",
        "        return output.cpu().numpy()\n",
        "\n",
        "# ---- prepara el subset de 1000 para HPO ----\n",
        "splits_1000 = split_subset(X, y, df_labels=df1, n_sub=1000, test_size=0.20, seed=42)\n",
        "X_train, X_valid = splits_1000[\"X_train\"], splits_1000[\"X_valid\"]\n",
        "y_train, y_valid = splits_1000[\"y_train\"], splits_1000[\"y_valid\"]\n",
        "X_test,  y_test  = splits_1000[\"X_test\"],  splits_1000[\"y_test\"]\n",
        "\n",
        "# Supone que ya tienes:\n",
        "# - features, CATEGORICAL_COLUMNS, categorical_dims\n",
        "# - RegressionSMOTE, my_r2_score_fn, optuna importados\n",
        "\n",
        "def make_tabnet(cat_info, params):\n",
        "    cat_idxs = [i for i, f in enumerate(features) if f in CATEGORICAL_COLUMNS]\n",
        "    cat_dims = [categorical_dims[f] for f in features if f in CATEGORICAL_COLUMNS]\n",
        "    cat_emb_dim = [min(params['emb'], max(4, (dim + 1)//2)) for dim in cat_dims]\n",
        "    return cat_idxs, cat_dims, cat_emb_dim\n",
        "\n",
        "def build_optimizer(optimizer_type, learning_rate, momentum, weight_decay):\n",
        "    if optimizer_type == 'adam':\n",
        "        return torch.optim.Adam, {'lr': float(min(max(learning_rate, 1e-4), 3e-3)), 'weight_decay': weight_decay}\n",
        "    if optimizer_type == 'adamw':\n",
        "        return torch.optim.AdamW, {'lr': float(min(max(learning_rate, 1e-4), 3e-3)), 'weight_decay': weight_decay}\n",
        "    if optimizer_type == 'sgd':\n",
        "        return torch.optim.SGD, {'lr': float(min(max(learning_rate, 1e-3), 1e-1)), 'momentum': momentum, 'weight_decay': weight_decay}\n",
        "    if optimizer_type == 'rmsprop':\n",
        "        return torch.optim.RMSprop, {'lr': float(min(max(learning_rate, 1e-4), 3e-3)), 'momentum': momentum, 'weight_decay': weight_decay}\n",
        "\n",
        "def objective_regression(trial):\n",
        "    # Capacidad TabNet\n",
        "    n_d     = trial.suggest_int('n_d', 8, 32)\n",
        "    n_a     = trial.suggest_int('n_a', 8, 32)\n",
        "    n_steps = trial.suggest_int('n_steps', 3, 5)\n",
        "\n",
        "    gamma         = trial.suggest_float('gamma', 1.0, 2.0)\n",
        "    lambda_sparse = trial.suggest_float('lambda_sparse', 1e-6, 1e-3, log=True)\n",
        "\n",
        "    batch_size  = trial.suggest_categorical('batch_size', [64, 128, 256])\n",
        "    mask_type   = trial.suggest_categorical('mask_type', ['entmax', 'sparsemax'])\n",
        "    emb         = trial.suggest_int('emb', 4, 24)\n",
        "\n",
        "    momentum      = trial.suggest_float('momentum', 0.5, 0.95)\n",
        "    learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-1, log=True)\n",
        "    weight_decay  = trial.suggest_float('weight_decay', 1e-6, 1e-4, log=True)\n",
        "\n",
        "    scheduler_gamma = trial.suggest_float('scheduler_gamma', 0.95, 0.995)\n",
        "    step_size       = trial.suggest_int('step_size', 5, 15)\n",
        "\n",
        "    virtual_batch_size = trial.suggest_categorical('virtual_batch_size', [32, 64])\n",
        "    if isinstance(batch_size, int) and isinstance(virtual_batch_size, int) and virtual_batch_size > batch_size:\n",
        "        virtual_batch_size = batch_size // 2 if batch_size >= 64 else batch_size\n",
        "\n",
        "    optimizer_type = trial.suggest_categorical('optimizer_type', ['adam', 'adamw', 'sgd', 'rmsprop'])\n",
        "    optimizer_fn, optimizer_params = build_optimizer(optimizer_type, learning_rate, momentum, weight_decay)\n",
        "\n",
        "    p   = trial.suggest_float('p', 0.0, 0.30)\n",
        "    aug = RegressionSMOTE(p=p)\n",
        "\n",
        "    cat_idxs = [i for i, f in enumerate(features) if f in CATEGORICAL_COLUMNS]\n",
        "    cat_dims = [categorical_dims[f] for f in features if f in CATEGORICAL_COLUMNS]\n",
        "    cat_emb_dim = [min(emb, max(4, (dim + 1)//2)) for dim in cat_dims]\n",
        "\n",
        "    model = CustomTabNetRegressor(\n",
        "        cat_dims=cat_dims, cat_emb_dim=cat_emb_dim, cat_idxs=cat_idxs,\n",
        "        n_d=n_d, n_a=n_a, n_steps=n_steps, gamma=gamma, lambda_sparse=lambda_sparse,\n",
        "        mask_type=mask_type, optimizer_fn=optimizer_fn, optimizer_params=optimizer_params,\n",
        "        scheduler_params={\"gamma\": scheduler_gamma, \"step_size\": step_size},\n",
        "        scheduler_fn=torch.optim.lr_scheduler.StepLR, verbose=True\n",
        "    )\n",
        "    model.fit(\n",
        "        X_train=X_train, y_train=y_train,\n",
        "        eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
        "        eval_name=['train', 'valid'],\n",
        "        eval_metric=['mae'],\n",
        "        loss_fn=my_r2_score_fn,  # (conserva tu lógica)\n",
        "        max_epochs=100, patience=40,\n",
        "        batch_size=batch_size, virtual_batch_size=virtual_batch_size,\n",
        "        num_workers=1, drop_last=False, augmentations=aug,\n",
        "    )\n",
        "    mae = model.history['loss'][-1]\n",
        "    return mae\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OldRpimYoeCf",
        "outputId": "9406ad9a-69ad-4cd5-bbde-25d40771be9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Originales (conservados): (166323, 312) (166323, 1)\n",
            "Subset de 1000: (1000, 312) (1000, 1)\n",
            "Train/Valid/Test: (640, 312) (160, 312) (200, 312)\n",
            "Distribución clases subset: Counter({np.int64(2): 265, np.int64(1): 251, np.int64(3): 249, np.int64(0): 235})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Búsqueda de hiperparámetros\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QRUrfbdmnXFG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Logo UNAL CHEC](https://miro.medium.com/v2/resize:fit:1100/format:webp/0*lu62RCEko0VYe-YZ)\n",
        "**Objetivo:** encontrar combinaciones de hiperparámetros que minimicen una métrica de validación (p. ej., MAE, RMSE, 1–R²) bajo un protocolo de evaluación (holdout/K-fold).\n",
        "\n",
        "---\n",
        "\n",
        "#### 1) Grid Search (búsqueda exhaustiva)\n",
        "\n",
        "* **Idea:** evalúa **todas** las combinaciones de un **grid** predefinido.\n",
        "* **Ventajas:** sistemático; fácil de reproducir y explicar; bueno en espacios **pequeños**.\n",
        "* **Desventajas:** costo **exponencial** con el número de hiperparámetros; ineficiente si muchos valores son malos.\n",
        "* **Cuándo usar:** pocos hiperparámetros y rangos **acotados**; validación de resultados “finales”.\n",
        "\n",
        "---\n",
        "\n",
        "#### 2) Random Search (búsqueda aleatoria)\n",
        "\n",
        "* **Idea:** toma **muestras aleatorias** de distribuciones definidas para cada hiperparámetro.\n",
        "* **Ventajas:** explora **mejor** espacios grandes con el mismo presupuesto; rápido de configurar.\n",
        "* **Desventajas:** no usa **información** de pruebas previas; puede omitir regiones prometedoras por azar.\n",
        "* **Cuándo usar:** presupuestos limitados; muchos hiperparámetros con rangos amplios; etapa **exploratoria** inicial.\n",
        "\n",
        "---\n",
        "\n",
        "#### 3) Optimización Bayesiana (p. ej., TPE, GP-BO)\n",
        "\n",
        "* **Idea:** construye un **modelo sustituto** del desempeño $f(\\theta)$ y elige el siguiente punto maximizando una **función de adquisición** (p. ej., *Expected Improvement*).\n",
        "* **Ventajas:** usa el **historial** para balancear *exploración*/*explotación*; suele requerir **menos** evaluaciones para llegar a buenos resultados.\n",
        "* **Desventajas:** mayor **complejidad**; sensibilidad a la configuración (modelo, adquisición); coste extra de ajuste del sustituto.\n",
        "* **Cuándo usar:** evaluación costosa; espacios **medianos/grandes**; se busca **eficiencia** con presupuesto fijo.\n"
      ],
      "metadata": {
        "id": "Fx2h9BhtHOet"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler())\n",
        "study.optimize(objective_regression, n_trials=15)\n",
        "\n",
        "print(\"Best hyperparameters for regression: \", study.best_params)\n",
        "print(\"Best mae: \", study.best_value)\n",
        "par = study.best_params\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAr65LvI_ZSj",
        "outputId": "db59ed75-0e40-4cff-cc49-5b8e20392d6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-09-05 00:58:05,390] A new study created in memory with name: no-name-55bd5b58-0703-4bc9-927f-5a0e164cfba4\n",
            "/usr/local/lib/python3.12/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 31.88583| train_mae: 1.4373  | valid_mae: 1.57791 |  0:00:01s\n",
            "epoch 1  | loss: 32.36552| train_mae: 0.92973 | valid_mae: 0.93015 |  0:00:01s\n",
            "epoch 2  | loss: 24.83098| train_mae: 0.7759  | valid_mae: 0.66527 |  0:00:02s\n",
            "epoch 3  | loss: 25.27773| train_mae: 0.72873 | valid_mae: 0.58456 |  0:00:03s\n",
            "epoch 4  | loss: 23.23252| train_mae: 0.75707 | valid_mae: 0.6061  |  0:00:04s\n",
            "epoch 5  | loss: 21.33306| train_mae: 0.77684 | valid_mae: 0.60856 |  0:00:05s\n",
            "epoch 6  | loss: 20.49553| train_mae: 0.59813 | valid_mae: 0.49186 |  0:00:06s\n",
            "epoch 7  | loss: 18.71511| train_mae: 0.51733 | valid_mae: 0.52666 |  0:00:06s\n",
            "epoch 8  | loss: 21.67417| train_mae: 0.43976 | valid_mae: 0.42323 |  0:00:07s\n",
            "epoch 9  | loss: 22.39866| train_mae: 0.43309 | valid_mae: 0.45107 |  0:00:07s\n",
            "epoch 10 | loss: 13.7614 | train_mae: 0.3636  | valid_mae: 0.38149 |  0:00:08s\n",
            "epoch 11 | loss: 15.77027| train_mae: 0.35347 | valid_mae: 0.30581 |  0:00:09s\n",
            "epoch 12 | loss: 12.66591| train_mae: 0.3759  | valid_mae: 0.34308 |  0:00:09s\n",
            "epoch 13 | loss: 10.21922| train_mae: 0.43182 | valid_mae: 0.42768 |  0:00:10s\n",
            "epoch 14 | loss: 11.29294| train_mae: 0.48995 | valid_mae: 0.46138 |  0:00:11s\n",
            "epoch 15 | loss: 11.30433| train_mae: 0.5554  | valid_mae: 0.496   |  0:00:11s\n",
            "epoch 16 | loss: 10.21307| train_mae: 0.58124 | valid_mae: 0.59986 |  0:00:12s\n",
            "epoch 17 | loss: 9.59559 | train_mae: 0.53159 | valid_mae: 0.61921 |  0:00:12s\n",
            "epoch 18 | loss: 8.20328 | train_mae: 0.56945 | valid_mae: 0.60154 |  0:00:13s\n",
            "epoch 19 | loss: 7.9263  | train_mae: 0.5669  | valid_mae: 0.62324 |  0:00:14s\n",
            "epoch 20 | loss: 9.40215 | train_mae: 0.57721 | valid_mae: 0.64255 |  0:00:14s\n",
            "epoch 21 | loss: 7.24501 | train_mae: 0.55521 | valid_mae: 0.6237  |  0:00:16s\n",
            "epoch 22 | loss: 7.23575 | train_mae: 0.57467 | valid_mae: 0.6658  |  0:00:17s\n",
            "epoch 23 | loss: 6.37592 | train_mae: 0.52108 | valid_mae: 0.54961 |  0:00:19s\n",
            "epoch 24 | loss: 4.42102 | train_mae: 0.47871 | valid_mae: 0.49985 |  0:00:19s\n",
            "epoch 25 | loss: 4.53179 | train_mae: 0.44325 | valid_mae: 0.47415 |  0:00:20s\n",
            "epoch 26 | loss: 5.58295 | train_mae: 0.40296 | valid_mae: 0.46295 |  0:00:21s\n",
            "epoch 27 | loss: 5.75308 | train_mae: 0.36177 | valid_mae: 0.40407 |  0:00:22s\n",
            "epoch 28 | loss: 4.67097 | train_mae: 0.3563  | valid_mae: 0.35047 |  0:00:22s\n",
            "epoch 29 | loss: 3.57732 | train_mae: 0.30235 | valid_mae: 0.3288  |  0:00:23s\n",
            "epoch 30 | loss: 4.46259 | train_mae: 0.29012 | valid_mae: 0.30626 |  0:00:23s\n",
            "epoch 31 | loss: 3.179   | train_mae: 0.26315 | valid_mae: 0.27821 |  0:00:24s\n",
            "epoch 32 | loss: 3.27835 | train_mae: 0.24275 | valid_mae: 0.28785 |  0:00:25s\n",
            "epoch 33 | loss: 2.52548 | train_mae: 0.21127 | valid_mae: 0.23282 |  0:00:25s\n",
            "epoch 34 | loss: 2.83357 | train_mae: 0.17832 | valid_mae: 0.19729 |  0:00:26s\n",
            "epoch 35 | loss: 2.91165 | train_mae: 0.15469 | valid_mae: 0.17173 |  0:00:27s\n",
            "epoch 36 | loss: 2.44841 | train_mae: 0.13153 | valid_mae: 0.14019 |  0:00:27s\n",
            "epoch 37 | loss: 3.26524 | train_mae: 0.12551 | valid_mae: 0.12362 |  0:00:28s\n",
            "epoch 38 | loss: 2.28381 | train_mae: 0.10098 | valid_mae: 0.10643 |  0:00:28s\n",
            "epoch 39 | loss: 1.75771 | train_mae: 0.09953 | valid_mae: 0.10482 |  0:00:29s\n",
            "epoch 40 | loss: 1.79355 | train_mae: 0.08942 | valid_mae: 0.09242 |  0:00:31s\n",
            "epoch 41 | loss: 1.69457 | train_mae: 0.08109 | valid_mae: 0.076   |  0:00:32s\n",
            "epoch 42 | loss: 1.40468 | train_mae: 0.0791  | valid_mae: 0.06956 |  0:00:33s\n",
            "epoch 43 | loss: 1.30677 | train_mae: 0.07047 | valid_mae: 0.06718 |  0:00:34s\n",
            "epoch 44 | loss: 1.24194 | train_mae: 0.06658 | valid_mae: 0.06612 |  0:00:34s\n",
            "epoch 45 | loss: 1.2455  | train_mae: 0.06136 | valid_mae: 0.06234 |  0:00:35s\n",
            "epoch 46 | loss: 1.11013 | train_mae: 0.0503  | valid_mae: 0.05395 |  0:00:35s\n",
            "epoch 47 | loss: 1.18351 | train_mae: 0.04604 | valid_mae: 0.04857 |  0:00:36s\n",
            "epoch 48 | loss: 1.1199  | train_mae: 0.04681 | valid_mae: 0.05082 |  0:00:37s\n",
            "epoch 49 | loss: 1.09995 | train_mae: 0.04433 | valid_mae: 0.05009 |  0:00:37s\n",
            "epoch 50 | loss: 1.07054 | train_mae: 0.03869 | valid_mae: 0.04763 |  0:00:38s\n",
            "epoch 51 | loss: 1.12609 | train_mae: 0.03934 | valid_mae: 0.04696 |  0:00:39s\n",
            "epoch 52 | loss: 1.08123 | train_mae: 0.04126 | valid_mae: 0.04726 |  0:00:39s\n",
            "epoch 53 | loss: 1.13679 | train_mae: 0.04413 | valid_mae: 0.04966 |  0:00:40s\n",
            "epoch 54 | loss: 1.02942 | train_mae: 0.03508 | valid_mae: 0.03934 |  0:00:40s\n",
            "epoch 55 | loss: 1.05389 | train_mae: 0.03616 | valid_mae: 0.04001 |  0:00:41s\n",
            "epoch 56 | loss: 1.02694 | train_mae: 0.0418  | valid_mae: 0.04442 |  0:00:42s\n",
            "epoch 57 | loss: 1.01609 | train_mae: 0.04631 | valid_mae: 0.04871 |  0:00:42s\n",
            "epoch 58 | loss: 1.11268 | train_mae: 0.03776 | valid_mae: 0.04111 |  0:00:43s\n",
            "epoch 59 | loss: 1.05709 | train_mae: 0.03159 | valid_mae: 0.03556 |  0:00:44s\n",
            "epoch 60 | loss: 1.0435  | train_mae: 0.0366  | valid_mae: 0.04104 |  0:00:45s\n",
            "epoch 61 | loss: 1.01197 | train_mae: 0.04365 | valid_mae: 0.04909 |  0:00:46s\n",
            "epoch 62 | loss: 1.04636 | train_mae: 0.04333 | valid_mae: 0.05118 |  0:00:46s\n",
            "epoch 63 | loss: 1.0296  | train_mae: 0.03874 | valid_mae: 0.04369 |  0:00:47s\n",
            "epoch 64 | loss: 1.02255 | train_mae: 0.03446 | valid_mae: 0.03746 |  0:00:47s\n",
            "epoch 65 | loss: 1.02631 | train_mae: 0.03449 | valid_mae: 0.03795 |  0:00:48s\n",
            "epoch 66 | loss: 1.02891 | train_mae: 0.03803 | valid_mae: 0.04202 |  0:00:49s\n",
            "epoch 67 | loss: 1.03297 | train_mae: 0.03859 | valid_mae: 0.04167 |  0:00:49s\n",
            "epoch 68 | loss: 1.03445 | train_mae: 0.03768 | valid_mae: 0.03855 |  0:00:50s\n",
            "epoch 69 | loss: 1.01209 | train_mae: 0.03582 | valid_mae: 0.03823 |  0:00:50s\n",
            "epoch 70 | loss: 1.0226  | train_mae: 0.03648 | valid_mae: 0.03936 |  0:00:51s\n",
            "epoch 71 | loss: 1.04383 | train_mae: 0.03692 | valid_mae: 0.04189 |  0:00:52s\n",
            "epoch 72 | loss: 1.03688 | train_mae: 0.03753 | valid_mae: 0.04277 |  0:00:52s\n",
            "epoch 73 | loss: 1.01791 | train_mae: 0.03643 | valid_mae: 0.04196 |  0:00:53s\n",
            "epoch 74 | loss: 0.99621 | train_mae: 0.03668 | valid_mae: 0.04063 |  0:00:53s\n",
            "epoch 75 | loss: 1.01905 | train_mae: 0.03542 | valid_mae: 0.03899 |  0:00:54s\n",
            "epoch 76 | loss: 1.00968 | train_mae: 0.03815 | valid_mae: 0.04037 |  0:00:55s\n",
            "epoch 77 | loss: 1.04518 | train_mae: 0.03749 | valid_mae: 0.03916 |  0:00:55s\n",
            "epoch 78 | loss: 1.01865 | train_mae: 0.03344 | valid_mae: 0.03561 |  0:00:56s\n",
            "epoch 79 | loss: 1.0347  | train_mae: 0.03361 | valid_mae: 0.03617 |  0:00:57s\n",
            "epoch 80 | loss: 0.99373 | train_mae: 0.03731 | valid_mae: 0.04008 |  0:00:58s\n",
            "epoch 81 | loss: 1.02841 | train_mae: 0.04012 | valid_mae: 0.04182 |  0:00:59s\n",
            "epoch 82 | loss: 1.01143 | train_mae: 0.03947 | valid_mae: 0.04161 |  0:00:59s\n",
            "epoch 83 | loss: 0.99792 | train_mae: 0.03792 | valid_mae: 0.03956 |  0:01:00s\n",
            "epoch 84 | loss: 1.02788 | train_mae: 0.03554 | valid_mae: 0.03789 |  0:01:00s\n",
            "epoch 85 | loss: 0.97729 | train_mae: 0.0362  | valid_mae: 0.03862 |  0:01:01s\n",
            "epoch 86 | loss: 1.00744 | train_mae: 0.03652 | valid_mae: 0.03876 |  0:01:02s\n",
            "epoch 87 | loss: 0.97084 | train_mae: 0.03627 | valid_mae: 0.03904 |  0:01:02s\n",
            "epoch 88 | loss: 0.97417 | train_mae: 0.03437 | valid_mae: 0.03711 |  0:01:03s\n",
            "epoch 89 | loss: 1.00175 | train_mae: 0.03305 | valid_mae: 0.03481 |  0:01:03s\n",
            "epoch 90 | loss: 1.04632 | train_mae: 0.03289 | valid_mae: 0.03333 |  0:01:04s\n",
            "epoch 91 | loss: 0.96816 | train_mae: 0.03588 | valid_mae: 0.03435 |  0:01:05s\n",
            "epoch 92 | loss: 0.99881 | train_mae: 0.04075 | valid_mae: 0.03817 |  0:01:05s\n",
            "epoch 93 | loss: 0.96664 | train_mae: 0.04167 | valid_mae: 0.03992 |  0:01:06s\n",
            "epoch 94 | loss: 0.90268 | train_mae: 0.03967 | valid_mae: 0.04    |  0:01:06s\n",
            "epoch 95 | loss: 0.89439 | train_mae: 0.03661 | valid_mae: 0.03626 |  0:01:07s\n",
            "epoch 96 | loss: 0.96729 | train_mae: 0.03411 | valid_mae: 0.03457 |  0:01:08s\n",
            "epoch 97 | loss: 0.87155 | train_mae: 0.03253 | valid_mae: 0.02909 |  0:01:08s\n",
            "epoch 98 | loss: 0.97181 | train_mae: 0.03169 | valid_mae: 0.02837 |  0:01:09s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-09-05 00:59:25,956] Trial 0 finished with value: 0.9738839268684387 and parameters: {'n_d': 8, 'n_a': 13, 'n_steps': 4, 'gamma': 1.6853392806353038, 'lambda_sparse': 1.0928132847713737e-06, 'batch_size': 256, 'mask_type': 'sparsemax', 'emb': 20, 'momentum': 0.9047649761929001, 'learning_rate': 0.0022449312065940083, 'weight_decay': 6.160794864301858e-06, 'scheduler_gamma': 0.9813016634410717, 'step_size': 12, 'virtual_batch_size': 64, 'optimizer_type': 'adamw', 'p': 0.2728982184483242}. Best is trial 0 with value: 0.9738839268684387.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 99 | loss: 0.97388 | train_mae: 0.03286 | valid_mae: 0.03153 |  0:01:10s\n",
            "Stop training because you reached max_epochs = 100 with best_epoch = 98 and best_valid_mae = 0.02837\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 529.32442| train_mae: 4.84413 | valid_mae: 4.92422 |  0:00:00s\n",
            "epoch 1  | loss: 434.27403| train_mae: 1.88573 | valid_mae: 1.91856 |  0:00:01s\n",
            "epoch 2  | loss: 314.46213| train_mae: 1.28585 | valid_mae: 1.3629  |  0:00:02s\n",
            "epoch 3  | loss: 194.56678| train_mae: 1.30501 | valid_mae: 1.24101 |  0:00:03s\n",
            "epoch 4  | loss: 286.26581| train_mae: 1.17294 | valid_mae: 1.22351 |  0:00:04s\n",
            "epoch 5  | loss: 171.85439| train_mae: 1.11649 | valid_mae: 1.04918 |  0:00:05s\n",
            "epoch 6  | loss: 234.70943| train_mae: 1.23845 | valid_mae: 1.21944 |  0:00:06s\n",
            "epoch 7  | loss: 366.25521| train_mae: 1.0973  | valid_mae: 1.10429 |  0:00:07s\n",
            "epoch 8  | loss: 135.96989| train_mae: 1.01414 | valid_mae: 1.11073 |  0:00:08s\n",
            "epoch 9  | loss: 155.94174| train_mae: 1.04943 | valid_mae: 1.03474 |  0:00:10s\n",
            "epoch 10 | loss: 199.35704| train_mae: 0.97972 | valid_mae: 0.97763 |  0:00:11s\n",
            "epoch 11 | loss: 115.17115| train_mae: 0.9338  | valid_mae: 1.13595 |  0:00:12s\n",
            "epoch 12 | loss: 232.06324| train_mae: 0.8715  | valid_mae: 0.78597 |  0:00:13s\n",
            "epoch 13 | loss: 188.324 | train_mae: 0.72801 | valid_mae: 0.61795 |  0:00:14s\n",
            "epoch 14 | loss: 129.98064| train_mae: 0.74759 | valid_mae: 0.57401 |  0:00:15s\n",
            "epoch 15 | loss: 270.4828| train_mae: 0.68642 | valid_mae: 0.54316 |  0:00:16s\n",
            "epoch 16 | loss: 350.8195| train_mae: 0.60698 | valid_mae: 0.49103 |  0:00:17s\n",
            "epoch 17 | loss: 117.68567| train_mae: 0.54849 | valid_mae: 0.50558 |  0:00:17s\n",
            "epoch 18 | loss: 134.18217| train_mae: 0.50468 | valid_mae: 0.51873 |  0:00:18s\n",
            "epoch 19 | loss: 165.16703| train_mae: 0.48479 | valid_mae: 0.54964 |  0:00:20s\n",
            "epoch 20 | loss: 92.63049| train_mae: 0.445   | valid_mae: 0.49819 |  0:00:21s\n",
            "epoch 21 | loss: 196.00129| train_mae: 0.48474 | valid_mae: 0.43262 |  0:00:22s\n",
            "epoch 22 | loss: 107.21101| train_mae: 0.45936 | valid_mae: 0.47315 |  0:00:24s\n",
            "epoch 23 | loss: 195.26129| train_mae: 0.45284 | valid_mae: 0.44078 |  0:00:24s\n",
            "epoch 24 | loss: 138.07528| train_mae: 0.44174 | valid_mae: 0.39614 |  0:00:25s\n",
            "epoch 25 | loss: 154.41642| train_mae: 0.4356  | valid_mae: 0.37186 |  0:00:26s\n",
            "epoch 26 | loss: 91.43793| train_mae: 0.41358 | valid_mae: 0.3499  |  0:00:27s\n",
            "epoch 27 | loss: 183.68112| train_mae: 0.41656 | valid_mae: 0.35742 |  0:00:28s\n",
            "epoch 28 | loss: 107.61348| train_mae: 0.38022 | valid_mae: 0.31372 |  0:00:29s\n",
            "epoch 29 | loss: 187.94743| train_mae: 0.36813 | valid_mae: 0.31004 |  0:00:30s\n",
            "epoch 30 | loss: 131.66643| train_mae: 0.34189 | valid_mae: 0.27969 |  0:00:31s\n",
            "epoch 31 | loss: 93.08518| train_mae: 0.34877 | valid_mae: 0.28523 |  0:00:32s\n",
            "epoch 32 | loss: 108.44711| train_mae: 0.3082  | valid_mae: 0.2817  |  0:00:33s\n",
            "epoch 33 | loss: 181.36421| train_mae: 0.30077 | valid_mae: 0.29645 |  0:00:34s\n",
            "epoch 34 | loss: 107.25165| train_mae: 0.31714 | valid_mae: 0.28926 |  0:00:36s\n",
            "epoch 35 | loss: 76.50932| train_mae: 0.31195 | valid_mae: 0.26695 |  0:00:37s\n",
            "epoch 36 | loss: 133.39847| train_mae: 0.27065 | valid_mae: 0.29279 |  0:00:38s\n",
            "epoch 37 | loss: 127.70333| train_mae: 0.28254 | valid_mae: 0.3081  |  0:00:39s\n",
            "epoch 38 | loss: 129.07522| train_mae: 0.27473 | valid_mae: 0.30821 |  0:00:40s\n",
            "epoch 39 | loss: 166.50721| train_mae: 0.25686 | valid_mae: 0.31232 |  0:00:40s\n",
            "epoch 40 | loss: 102.32641| train_mae: 0.26042 | valid_mae: 0.29211 |  0:00:41s\n",
            "epoch 41 | loss: 140.01776| train_mae: 0.27105 | valid_mae: 0.29615 |  0:00:42s\n",
            "epoch 42 | loss: 116.49813| train_mae: 0.27345 | valid_mae: 0.29403 |  0:00:43s\n",
            "epoch 43 | loss: 114.31902| train_mae: 0.31792 | valid_mae: 0.25452 |  0:00:44s\n",
            "epoch 44 | loss: 78.02575| train_mae: 0.26907 | valid_mae: 0.23799 |  0:00:45s\n",
            "epoch 45 | loss: 168.58662| train_mae: 0.27427 | valid_mae: 0.23878 |  0:00:46s\n",
            "epoch 46 | loss: 75.91091| train_mae: 0.28023 | valid_mae: 0.23007 |  0:00:47s\n",
            "epoch 47 | loss: 106.96077| train_mae: 0.2989  | valid_mae: 0.23454 |  0:00:49s\n",
            "epoch 48 | loss: 139.60451| train_mae: 0.25352 | valid_mae: 0.23891 |  0:00:50s\n",
            "epoch 49 | loss: 79.32758| train_mae: 0.26476 | valid_mae: 0.27185 |  0:00:51s\n",
            "epoch 50 | loss: 106.52626| train_mae: 0.27742 | valid_mae: 0.31219 |  0:00:52s\n",
            "epoch 51 | loss: 79.04939| train_mae: 0.25891 | valid_mae: 0.28304 |  0:00:53s\n",
            "epoch 52 | loss: 86.23597| train_mae: 0.24925 | valid_mae: 0.24704 |  0:00:54s\n",
            "epoch 53 | loss: 62.42386| train_mae: 0.25761 | valid_mae: 0.25923 |  0:00:54s\n",
            "epoch 54 | loss: 122.32771| train_mae: 0.27289 | valid_mae: 0.25786 |  0:00:55s\n",
            "epoch 55 | loss: 99.13993| train_mae: 0.24918 | valid_mae: 0.26085 |  0:00:56s\n",
            "epoch 56 | loss: 114.68798| train_mae: 0.23535 | valid_mae: 0.23499 |  0:00:57s\n",
            "epoch 57 | loss: 71.48649| train_mae: 0.2683  | valid_mae: 0.25522 |  0:00:58s\n",
            "epoch 58 | loss: 73.08117| train_mae: 0.23182 | valid_mae: 0.23776 |  0:00:59s\n",
            "epoch 59 | loss: 62.09157| train_mae: 0.21482 | valid_mae: 0.27214 |  0:01:00s\n",
            "epoch 60 | loss: 130.08694| train_mae: 0.21909 | valid_mae: 0.23235 |  0:01:02s\n",
            "epoch 61 | loss: 104.46607| train_mae: 0.25035 | valid_mae: 0.22286 |  0:01:03s\n",
            "epoch 62 | loss: 119.48686| train_mae: 0.22589 | valid_mae: 0.22757 |  0:01:04s\n",
            "epoch 63 | loss: 60.31233| train_mae: 0.22366 | valid_mae: 0.222   |  0:01:05s\n",
            "epoch 64 | loss: 75.91445| train_mae: 0.22396 | valid_mae: 0.21241 |  0:01:06s\n",
            "epoch 65 | loss: 65.30572| train_mae: 0.25707 | valid_mae: 0.19042 |  0:01:07s\n",
            "epoch 66 | loss: 54.31006| train_mae: 0.23197 | valid_mae: 0.22912 |  0:01:08s\n",
            "epoch 67 | loss: 64.64433| train_mae: 0.2149  | valid_mae: 0.21591 |  0:01:09s\n",
            "epoch 68 | loss: 68.99771| train_mae: 0.20973 | valid_mae: 0.22707 |  0:01:09s\n",
            "epoch 69 | loss: 71.16841| train_mae: 0.23274 | valid_mae: 0.20425 |  0:01:10s\n",
            "epoch 70 | loss: 94.02463| train_mae: 0.20591 | valid_mae: 0.22049 |  0:01:11s\n",
            "epoch 71 | loss: 84.81295| train_mae: 0.21488 | valid_mae: 0.19632 |  0:01:12s\n",
            "epoch 72 | loss: 104.41692| train_mae: 0.2699  | valid_mae: 0.21578 |  0:01:14s\n",
            "epoch 73 | loss: 102.93726| train_mae: 0.2609  | valid_mae: 0.22993 |  0:01:15s\n",
            "epoch 74 | loss: 53.72938| train_mae: 0.22691 | valid_mae: 0.24349 |  0:01:16s\n",
            "epoch 75 | loss: 59.40709| train_mae: 0.22679 | valid_mae: 0.2269  |  0:01:17s\n",
            "epoch 76 | loss: 58.95632| train_mae: 0.21368 | valid_mae: 0.24043 |  0:01:18s\n",
            "epoch 77 | loss: 69.7553 | train_mae: 0.23478 | valid_mae: 0.21494 |  0:01:19s\n",
            "epoch 78 | loss: 121.40936| train_mae: 0.23519 | valid_mae: 0.24661 |  0:01:20s\n",
            "epoch 79 | loss: 72.58179| train_mae: 0.20978 | valid_mae: 0.21435 |  0:01:21s\n",
            "epoch 80 | loss: 63.78077| train_mae: 0.20407 | valid_mae: 0.37461 |  0:01:22s\n",
            "epoch 81 | loss: 39.97249| train_mae: 0.21064 | valid_mae: 0.4229  |  0:01:23s\n",
            "epoch 82 | loss: 66.77461| train_mae: 0.20196 | valid_mae: 0.22924 |  0:01:23s\n",
            "epoch 83 | loss: 43.84158| train_mae: 0.21672 | valid_mae: 0.22375 |  0:01:24s\n",
            "epoch 84 | loss: 78.02037| train_mae: 0.20073 | valid_mae: 0.23678 |  0:01:25s\n",
            "epoch 85 | loss: 54.28364| train_mae: 0.24534 | valid_mae: 0.21094 |  0:01:27s\n",
            "epoch 86 | loss: 45.82337| train_mae: 0.22895 | valid_mae: 0.24631 |  0:01:28s\n",
            "epoch 87 | loss: 80.11497| train_mae: 0.20956 | valid_mae: 0.23264 |  0:01:29s\n",
            "epoch 88 | loss: 61.25809| train_mae: 0.18473 | valid_mae: 0.22251 |  0:01:30s\n",
            "epoch 89 | loss: 40.45098| train_mae: 0.18574 | valid_mae: 0.21921 |  0:01:31s\n",
            "epoch 90 | loss: 73.08625| train_mae: 0.20471 | valid_mae: 0.24768 |  0:01:32s\n",
            "epoch 91 | loss: 45.26827| train_mae: 0.18808 | valid_mae: 0.23344 |  0:01:33s\n",
            "epoch 92 | loss: 73.12632| train_mae: 0.19327 | valid_mae: 0.21559 |  0:01:34s\n",
            "epoch 93 | loss: 47.67937| train_mae: 0.19183 | valid_mae: 0.19934 |  0:01:35s\n",
            "epoch 94 | loss: 42.22249| train_mae: 0.18456 | valid_mae: 0.19713 |  0:01:36s\n",
            "epoch 95 | loss: 79.63657| train_mae: 0.19937 | valid_mae: 0.18707 |  0:01:37s\n",
            "epoch 96 | loss: 82.77101| train_mae: 0.19431 | valid_mae: 0.19534 |  0:01:38s\n",
            "epoch 97 | loss: 48.08766| train_mae: 0.20064 | valid_mae: 0.17361 |  0:01:39s\n",
            "epoch 98 | loss: 366.41625| train_mae: 0.18742 | valid_mae: 0.2127  |  0:01:40s\n",
            "epoch 99 | loss: 60.19615| train_mae: 0.18759 | valid_mae: 0.20826 |  0:01:41s\n",
            "Stop training because you reached max_epochs = 100 with best_epoch = 97 and best_valid_mae = 0.17361\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-09-05 01:01:11,106] Trial 1 finished with value: 60.1961464881897 and parameters: {'n_d': 17, 'n_a': 22, 'n_steps': 3, 'gamma': 1.279047079780749, 'lambda_sparse': 9.335282202424502e-05, 'batch_size': 64, 'mask_type': 'sparsemax', 'emb': 12, 'momentum': 0.5834587488113198, 'learning_rate': 0.00024243851017301097, 'weight_decay': 1.9377512841942382e-05, 'scheduler_gamma': 0.9744217724711142, 'step_size': 10, 'virtual_batch_size': 32, 'optimizer_type': 'adamw', 'p': 0.06307793360530106}. Best is trial 0 with value: 0.9738839268684387.\n",
            "/usr/local/lib/python3.12/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 74.15213| train_mae: 6.2236  | valid_mae: 5.7787  |  0:00:00s\n",
            "epoch 1  | loss: 78.30111| train_mae: 1.05345 | valid_mae: 1.03107 |  0:00:01s\n",
            "epoch 2  | loss: 95.82647| train_mae: 0.90368 | valid_mae: 0.8548  |  0:00:02s\n",
            "epoch 3  | loss: 84.24873| train_mae: 1.23722 | valid_mae: 1.35802 |  0:00:03s\n",
            "epoch 4  | loss: 59.93914| train_mae: 1.09827 | valid_mae: 1.49122 |  0:00:04s\n",
            "epoch 5  | loss: 74.60342| train_mae: 1.35651 | valid_mae: 1.42501 |  0:00:04s\n",
            "epoch 6  | loss: 74.10597| train_mae: 1.71911 | valid_mae: 1.75235 |  0:00:05s\n",
            "epoch 7  | loss: 77.91185| train_mae: 1.78813 | valid_mae: 2.18661 |  0:00:06s\n",
            "epoch 8  | loss: 64.73233| train_mae: 1.80369 | valid_mae: 2.57896 |  0:00:06s\n",
            "epoch 9  | loss: 74.77361| train_mae: 2.55215 | valid_mae: 3.4028  |  0:00:07s\n",
            "epoch 10 | loss: 51.36455| train_mae: 2.91401 | valid_mae: 3.40027 |  0:00:08s\n",
            "epoch 11 | loss: 66.40853| train_mae: 2.42081 | valid_mae: 2.79136 |  0:00:09s\n",
            "epoch 12 | loss: 54.42372| train_mae: 2.62093 | valid_mae: 2.91821 |  0:00:10s\n",
            "epoch 13 | loss: 52.27279| train_mae: 2.84251 | valid_mae: 2.97473 |  0:00:11s\n",
            "epoch 14 | loss: 55.19893| train_mae: 2.52687 | valid_mae: 2.75926 |  0:00:12s\n",
            "epoch 15 | loss: 48.21092| train_mae: 2.48145 | valid_mae: 3.06397 |  0:00:12s\n",
            "epoch 16 | loss: 42.4399 | train_mae: 2.38242 | valid_mae: 2.32659 |  0:00:13s\n",
            "epoch 17 | loss: 47.40836| train_mae: 1.77379 | valid_mae: 2.45145 |  0:00:14s\n",
            "epoch 18 | loss: 55.94069| train_mae: 1.77885 | valid_mae: 1.83697 |  0:00:14s\n",
            "epoch 19 | loss: 70.46957| train_mae: 1.30991 | valid_mae: 1.50914 |  0:00:15s\n",
            "epoch 20 | loss: 48.98752| train_mae: 1.35953 | valid_mae: 1.24366 |  0:00:16s\n",
            "epoch 21 | loss: 72.18923| train_mae: 1.14754 | valid_mae: 1.14745 |  0:00:17s\n",
            "epoch 22 | loss: 59.65794| train_mae: 1.12543 | valid_mae: 1.06822 |  0:00:17s\n",
            "epoch 23 | loss: 41.14881| train_mae: 1.16665 | valid_mae: 1.19482 |  0:00:18s\n",
            "epoch 24 | loss: 50.80455| train_mae: 1.02097 | valid_mae: 1.15285 |  0:00:19s\n",
            "epoch 25 | loss: 32.84405| train_mae: 0.98634 | valid_mae: 1.10255 |  0:00:19s\n",
            "epoch 26 | loss: 40.06999| train_mae: 0.93675 | valid_mae: 0.97757 |  0:00:20s\n",
            "epoch 27 | loss: 37.41413| train_mae: 0.98795 | valid_mae: 0.95937 |  0:00:22s\n",
            "epoch 28 | loss: 32.1152 | train_mae: 0.93225 | valid_mae: 1.01013 |  0:00:23s\n",
            "epoch 29 | loss: 43.16416| train_mae: 0.86224 | valid_mae: 0.89889 |  0:00:24s\n",
            "epoch 30 | loss: 31.75196| train_mae: 0.95178 | valid_mae: 0.76404 |  0:00:25s\n",
            "epoch 31 | loss: 40.09388| train_mae: 1.01855 | valid_mae: 0.87866 |  0:00:25s\n",
            "epoch 32 | loss: 33.20756| train_mae: 0.83811 | valid_mae: 0.77649 |  0:00:26s\n",
            "epoch 33 | loss: 26.56789| train_mae: 0.83719 | valid_mae: 0.68002 |  0:00:27s\n",
            "epoch 34 | loss: 40.48266| train_mae: 0.8064  | valid_mae: 0.65901 |  0:00:27s\n",
            "epoch 35 | loss: 39.62082| train_mae: 0.64235 | valid_mae: 0.62801 |  0:00:28s\n",
            "epoch 36 | loss: 25.84086| train_mae: 0.65605 | valid_mae: 0.54574 |  0:00:29s\n",
            "epoch 37 | loss: 34.3031 | train_mae: 0.64648 | valid_mae: 0.55652 |  0:00:30s\n",
            "epoch 38 | loss: 20.04086| train_mae: 0.68062 | valid_mae: 0.65684 |  0:00:30s\n",
            "epoch 39 | loss: 32.55748| train_mae: 0.68897 | valid_mae: 0.54945 |  0:00:31s\n",
            "epoch 40 | loss: 21.1099 | train_mae: 0.62146 | valid_mae: 0.5353  |  0:00:32s\n",
            "epoch 41 | loss: 35.05389| train_mae: 0.59763 | valid_mae: 0.49066 |  0:00:32s\n",
            "epoch 42 | loss: 30.54688| train_mae: 0.55306 | valid_mae: 0.65156 |  0:00:33s\n",
            "epoch 43 | loss: 20.59297| train_mae: 0.55902 | valid_mae: 0.50345 |  0:00:34s\n",
            "epoch 44 | loss: 26.6076 | train_mae: 0.59561 | valid_mae: 0.5787  |  0:00:35s\n",
            "epoch 45 | loss: 18.52874| train_mae: 0.60714 | valid_mae: 0.59044 |  0:00:36s\n",
            "epoch 46 | loss: 38.84499| train_mae: 0.60568 | valid_mae: 0.56552 |  0:00:37s\n",
            "epoch 47 | loss: 22.05889| train_mae: 0.49768 | valid_mae: 0.5203  |  0:00:38s\n",
            "epoch 48 | loss: 22.43793| train_mae: 0.56471 | valid_mae: 0.57935 |  0:00:38s\n",
            "epoch 49 | loss: 18.43767| train_mae: 0.57843 | valid_mae: 0.5098  |  0:00:39s\n",
            "epoch 50 | loss: 19.8792 | train_mae: 0.53763 | valid_mae: 0.46796 |  0:00:40s\n",
            "epoch 51 | loss: 15.62684| train_mae: 0.56643 | valid_mae: 0.53676 |  0:00:40s\n",
            "epoch 52 | loss: 16.01617| train_mae: 0.48661 | valid_mae: 0.56296 |  0:00:41s\n",
            "epoch 53 | loss: 16.02653| train_mae: 0.4579  | valid_mae: 0.5702  |  0:00:42s\n",
            "epoch 54 | loss: 17.55247| train_mae: 0.45664 | valid_mae: 0.45608 |  0:00:43s\n",
            "epoch 55 | loss: 14.22315| train_mae: 0.40505 | valid_mae: 0.49007 |  0:00:43s\n",
            "epoch 56 | loss: 13.92286| train_mae: 0.38446 | valid_mae: 0.34841 |  0:00:44s\n",
            "epoch 57 | loss: 16.8747 | train_mae: 0.3858  | valid_mae: 0.32749 |  0:00:45s\n",
            "epoch 58 | loss: 14.85731| train_mae: 0.35713 | valid_mae: 0.32669 |  0:00:45s\n",
            "epoch 59 | loss: 14.36058| train_mae: 0.34276 | valid_mae: 0.31259 |  0:00:46s\n",
            "epoch 60 | loss: 19.80748| train_mae: 0.35085 | valid_mae: 0.31129 |  0:00:47s\n",
            "epoch 61 | loss: 14.53706| train_mae: 0.32081 | valid_mae: 0.37282 |  0:00:48s\n",
            "epoch 62 | loss: 13.0574 | train_mae: 0.3093  | valid_mae: 0.36502 |  0:00:49s\n",
            "epoch 63 | loss: 13.77044| train_mae: 0.29027 | valid_mae: 0.39165 |  0:00:50s\n",
            "epoch 64 | loss: 12.14131| train_mae: 0.27452 | valid_mae: 0.32094 |  0:00:51s\n",
            "epoch 65 | loss: 12.20603| train_mae: 0.29965 | valid_mae: 0.33279 |  0:00:51s\n",
            "epoch 66 | loss: 14.20273| train_mae: 0.26357 | valid_mae: 0.3407  |  0:00:52s\n",
            "epoch 67 | loss: 11.74772| train_mae: 0.23469 | valid_mae: 0.34662 |  0:00:53s\n",
            "epoch 68 | loss: 10.43888| train_mae: 0.22112 | valid_mae: 0.27154 |  0:00:54s\n",
            "epoch 69 | loss: 13.37476| train_mae: 0.22706 | valid_mae: 0.20899 |  0:00:54s\n",
            "epoch 70 | loss: 14.34727| train_mae: 0.21733 | valid_mae: 0.25961 |  0:00:55s\n",
            "epoch 71 | loss: 12.04879| train_mae: 0.20695 | valid_mae: 0.24144 |  0:00:56s\n",
            "epoch 72 | loss: 8.89984 | train_mae: 0.17724 | valid_mae: 0.23071 |  0:00:56s\n",
            "epoch 73 | loss: 9.01984 | train_mae: 0.17202 | valid_mae: 0.21227 |  0:00:57s\n",
            "epoch 74 | loss: 13.54203| train_mae: 0.15398 | valid_mae: 0.19517 |  0:00:58s\n",
            "epoch 75 | loss: 8.92579 | train_mae: 0.13716 | valid_mae: 0.17737 |  0:00:59s\n",
            "epoch 76 | loss: 7.81488 | train_mae: 0.15021 | valid_mae: 0.18208 |  0:00:59s\n",
            "epoch 77 | loss: 8.51195 | train_mae: 0.14903 | valid_mae: 0.18407 |  0:01:00s\n",
            "epoch 78 | loss: 9.35929 | train_mae: 0.14833 | valid_mae: 0.17284 |  0:01:01s\n",
            "epoch 79 | loss: 7.23268 | train_mae: 0.1393  | valid_mae: 0.15256 |  0:01:02s\n",
            "epoch 80 | loss: 7.62926 | train_mae: 0.11935 | valid_mae: 0.13408 |  0:01:03s\n",
            "epoch 81 | loss: 9.86163 | train_mae: 0.12304 | valid_mae: 0.15644 |  0:01:04s\n",
            "epoch 82 | loss: 7.0697  | train_mae: 0.10797 | valid_mae: 0.12231 |  0:01:05s\n",
            "epoch 83 | loss: 7.2381  | train_mae: 0.10041 | valid_mae: 0.10865 |  0:01:05s\n",
            "epoch 84 | loss: 7.07679 | train_mae: 0.1084  | valid_mae: 0.14029 |  0:01:06s\n",
            "epoch 85 | loss: 6.57428 | train_mae: 0.1144  | valid_mae: 0.10943 |  0:01:07s\n",
            "epoch 86 | loss: 7.15612 | train_mae: 0.10736 | valid_mae: 0.09572 |  0:01:07s\n",
            "epoch 87 | loss: 7.09661 | train_mae: 0.09865 | valid_mae: 0.0946  |  0:01:08s\n",
            "epoch 88 | loss: 6.13603 | train_mae: 0.0891  | valid_mae: 0.10119 |  0:01:09s\n",
            "epoch 89 | loss: 5.41008 | train_mae: 0.09518 | valid_mae: 0.10316 |  0:01:10s\n",
            "epoch 90 | loss: 6.93472 | train_mae: 0.08833 | valid_mae: 0.09669 |  0:01:10s\n",
            "epoch 91 | loss: 5.48985 | train_mae: 0.09077 | valid_mae: 0.25413 |  0:01:11s\n",
            "epoch 92 | loss: 6.14217 | train_mae: 0.08952 | valid_mae: 0.13359 |  0:01:12s\n",
            "epoch 93 | loss: 4.78415 | train_mae: 0.07857 | valid_mae: 0.09746 |  0:01:13s\n",
            "epoch 94 | loss: 6.03652 | train_mae: 0.07835 | valid_mae: 0.13819 |  0:01:14s\n",
            "epoch 95 | loss: 4.90678 | train_mae: 0.08583 | valid_mae: 0.11106 |  0:01:15s\n",
            "epoch 96 | loss: 4.13848 | train_mae: 0.08423 | valid_mae: 0.16354 |  0:01:16s\n",
            "epoch 97 | loss: 6.41548 | train_mae: 0.07639 | valid_mae: 0.0699  |  0:01:16s\n",
            "epoch 98 | loss: 3.57044 | train_mae: 0.06804 | valid_mae: 0.13299 |  0:01:17s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-09-05 01:02:32,443] Trial 2 finished with value: 4.936153697967529 and parameters: {'n_d': 8, 'n_a': 12, 'n_steps': 5, 'gamma': 1.4316795677301206, 'lambda_sparse': 3.2485218626779113e-05, 'batch_size': 256, 'mask_type': 'entmax', 'emb': 6, 'momentum': 0.9467559134402905, 'learning_rate': 0.0011826041257479401, 'weight_decay': 4.518611248024321e-06, 'scheduler_gamma': 0.9756649455693126, 'step_size': 5, 'virtual_batch_size': 32, 'optimizer_type': 'adam', 'p': 0.08822131660935402}. Best is trial 0 with value: 0.9738839268684387.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 99 | loss: 4.93615 | train_mae: 0.07298 | valid_mae: 0.0705  |  0:01:18s\n",
            "Stop training because you reached max_epochs = 100 with best_epoch = 97 and best_valid_mae = 0.0699\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 609.0941| train_mae: 6.66176 | valid_mae: 8.71244 |  0:00:00s\n",
            "epoch 1  | loss: 381.23792| train_mae: 4.54399 | valid_mae: 4.14481 |  0:00:01s\n",
            "epoch 2  | loss: 579.53526| train_mae: 3.39494 | valid_mae: 3.33356 |  0:00:02s\n",
            "epoch 3  | loss: 495.69136| train_mae: 2.86887 | valid_mae: 2.92078 |  0:00:03s\n",
            "epoch 4  | loss: 369.47667| train_mae: 2.30602 | valid_mae: 2.09243 |  0:00:04s\n",
            "epoch 5  | loss: 317.84471| train_mae: 2.63731 | valid_mae: 2.61594 |  0:00:05s\n",
            "epoch 6  | loss: 310.97735| train_mae: 2.96057 | valid_mae: 3.15197 |  0:00:06s\n",
            "epoch 7  | loss: 550.63432| train_mae: 2.68025 | valid_mae: 3.10458 |  0:00:07s\n",
            "epoch 8  | loss: 638.97012| train_mae: 2.97397 | valid_mae: 3.46706 |  0:00:08s\n",
            "epoch 9  | loss: 235.24534| train_mae: 3.00919 | valid_mae: 3.05993 |  0:00:09s\n",
            "epoch 10 | loss: 158.8979| train_mae: 2.99379 | valid_mae: 3.21097 |  0:00:10s\n",
            "epoch 11 | loss: 238.98396| train_mae: 3.03426 | valid_mae: 2.79092 |  0:00:11s\n",
            "epoch 12 | loss: 147.84565| train_mae: 2.72145 | valid_mae: 2.93353 |  0:00:11s\n",
            "epoch 13 | loss: 121.4034| train_mae: 2.67619 | valid_mae: 2.5707  |  0:00:12s\n",
            "epoch 14 | loss: 115.32306| train_mae: 2.33875 | valid_mae: 2.8011  |  0:00:13s\n",
            "epoch 15 | loss: 126.18504| train_mae: 2.27722 | valid_mae: 2.2041  |  0:00:14s\n",
            "epoch 16 | loss: 105.47277| train_mae: 1.85968 | valid_mae: 1.70647 |  0:00:15s\n",
            "epoch 17 | loss: 128.11121| train_mae: 1.50786 | valid_mae: 1.59694 |  0:00:16s\n",
            "epoch 18 | loss: 87.82388| train_mae: 1.4044  | valid_mae: 1.03445 |  0:00:17s\n",
            "epoch 19 | loss: 112.94582| train_mae: 1.29441 | valid_mae: 1.25241 |  0:00:18s\n",
            "epoch 20 | loss: 82.64618| train_mae: 1.26158 | valid_mae: 1.25783 |  0:00:19s\n",
            "epoch 21 | loss: 98.49353| train_mae: 1.18738 | valid_mae: 1.00611 |  0:00:20s\n",
            "epoch 22 | loss: 94.37547| train_mae: 1.06976 | valid_mae: 0.94005 |  0:00:21s\n",
            "epoch 23 | loss: 58.34456| train_mae: 0.91829 | valid_mae: 1.01371 |  0:00:22s\n",
            "epoch 24 | loss: 72.14651| train_mae: 0.87869 | valid_mae: 0.88356 |  0:00:23s\n",
            "epoch 25 | loss: 57.10412| train_mae: 0.81538 | valid_mae: 0.77702 |  0:00:23s\n",
            "epoch 26 | loss: 56.26688| train_mae: 0.73019 | valid_mae: 0.79297 |  0:00:24s\n",
            "epoch 27 | loss: 44.04809| train_mae: 0.62645 | valid_mae: 0.73948 |  0:00:25s\n",
            "epoch 28 | loss: 41.05929| train_mae: 0.59404 | valid_mae: 0.55329 |  0:00:26s\n",
            "epoch 29 | loss: 47.27641| train_mae: 0.61748 | valid_mae: 0.50811 |  0:00:27s\n",
            "epoch 30 | loss: 46.28235| train_mae: 0.49254 | valid_mae: 0.4438  |  0:00:28s\n",
            "epoch 31 | loss: 32.74413| train_mae: 0.44667 | valid_mae: 0.37156 |  0:00:29s\n",
            "epoch 32 | loss: 28.78522| train_mae: 0.37062 | valid_mae: 0.35783 |  0:00:30s\n",
            "epoch 33 | loss: 41.08532| train_mae: 0.36725 | valid_mae: 0.29711 |  0:00:30s\n",
            "epoch 34 | loss: 33.53346| train_mae: 0.39772 | valid_mae: 0.25574 |  0:00:32s\n",
            "epoch 35 | loss: 25.43053| train_mae: 0.34314 | valid_mae: 0.23805 |  0:00:33s\n",
            "epoch 36 | loss: 29.5019 | train_mae: 0.26723 | valid_mae: 0.23326 |  0:00:34s\n",
            "epoch 37 | loss: 22.51817| train_mae: 0.23859 | valid_mae: 0.17044 |  0:00:35s\n",
            "epoch 38 | loss: 25.55824| train_mae: 0.20503 | valid_mae: 0.27568 |  0:00:36s\n",
            "epoch 39 | loss: 16.1548 | train_mae: 0.21129 | valid_mae: 0.19566 |  0:00:36s\n",
            "epoch 40 | loss: 20.10858| train_mae: 0.18949 | valid_mae: 0.15454 |  0:00:37s\n",
            "epoch 41 | loss: 15.70262| train_mae: 0.18    | valid_mae: 0.16183 |  0:00:38s\n",
            "epoch 42 | loss: 13.97734| train_mae: 0.17776 | valid_mae: 0.16722 |  0:00:39s\n",
            "epoch 43 | loss: 12.68821| train_mae: 0.20569 | valid_mae: 0.14555 |  0:00:40s\n",
            "epoch 44 | loss: 13.18108| train_mae: 0.17125 | valid_mae: 0.12647 |  0:00:41s\n",
            "epoch 45 | loss: 14.77084| train_mae: 0.15415 | valid_mae: 0.11726 |  0:00:42s\n",
            "epoch 46 | loss: 12.15568| train_mae: 0.15435 | valid_mae: 0.11745 |  0:00:42s\n",
            "epoch 47 | loss: 12.9229 | train_mae: 0.11462 | valid_mae: 0.12204 |  0:00:43s\n",
            "epoch 48 | loss: 7.90742 | train_mae: 0.12892 | valid_mae: 0.11811 |  0:00:44s\n",
            "epoch 49 | loss: 9.53829 | train_mae: 0.10281 | valid_mae: 0.10345 |  0:00:46s\n",
            "epoch 50 | loss: 13.09763| train_mae: 0.09167 | valid_mae: 0.10794 |  0:00:47s\n",
            "epoch 51 | loss: 5.57341 | train_mae: 0.09075 | valid_mae: 0.09896 |  0:00:48s\n",
            "epoch 52 | loss: 6.436   | train_mae: 0.09531 | valid_mae: 0.07676 |  0:00:49s\n",
            "epoch 53 | loss: 5.45194 | train_mae: 0.08066 | valid_mae: 0.06863 |  0:00:49s\n",
            "epoch 54 | loss: 4.5636  | train_mae: 0.07561 | valid_mae: 0.068   |  0:00:50s\n",
            "epoch 55 | loss: 4.51113 | train_mae: 0.08167 | valid_mae: 0.06321 |  0:00:51s\n",
            "epoch 56 | loss: 4.75983 | train_mae: 0.07316 | valid_mae: 0.06835 |  0:00:52s\n",
            "epoch 57 | loss: 2.87919 | train_mae: 0.0741  | valid_mae: 0.05799 |  0:00:53s\n",
            "epoch 58 | loss: 2.51671 | train_mae: 0.06757 | valid_mae: 0.07401 |  0:00:54s\n",
            "epoch 59 | loss: 2.38668 | train_mae: 0.05064 | valid_mae: 0.05614 |  0:00:55s\n",
            "epoch 60 | loss: 2.08607 | train_mae: 0.05489 | valid_mae: 0.04589 |  0:00:55s\n",
            "epoch 61 | loss: 1.9007  | train_mae: 0.0496  | valid_mae: 0.0496  |  0:00:56s\n",
            "epoch 62 | loss: 1.82008 | train_mae: 0.04503 | valid_mae: 0.04006 |  0:00:57s\n",
            "epoch 63 | loss: 1.45571 | train_mae: 0.04639 | valid_mae: 0.04453 |  0:00:59s\n",
            "epoch 64 | loss: 1.50676 | train_mae: 0.05512 | valid_mae: 0.04816 |  0:01:00s\n",
            "epoch 65 | loss: 2.81842 | train_mae: 0.03865 | valid_mae: 0.04281 |  0:01:01s\n",
            "epoch 66 | loss: 1.48837 | train_mae: 0.0349  | valid_mae: 0.04041 |  0:01:02s\n",
            "epoch 67 | loss: 1.11561 | train_mae: 0.03786 | valid_mae: 0.03752 |  0:01:03s\n",
            "epoch 68 | loss: 1.02697 | train_mae: 0.03471 | valid_mae: 0.04294 |  0:01:03s\n",
            "epoch 69 | loss: 1.14555 | train_mae: 0.03167 | valid_mae: 0.03384 |  0:01:04s\n",
            "epoch 70 | loss: 1.03259 | train_mae: 0.03006 | valid_mae: 0.0349  |  0:01:05s\n",
            "epoch 71 | loss: 1.11777 | train_mae: 0.03805 | valid_mae: 0.03836 |  0:01:06s\n",
            "epoch 72 | loss: 1.21943 | train_mae: 0.0353  | valid_mae: 0.03757 |  0:01:07s\n",
            "epoch 73 | loss: 1.11077 | train_mae: 0.03782 | valid_mae: 0.04201 |  0:01:08s\n",
            "epoch 74 | loss: 1.01707 | train_mae: 0.02933 | valid_mae: 0.03458 |  0:01:08s\n",
            "epoch 75 | loss: 1.05685 | train_mae: 0.0313  | valid_mae: 0.03336 |  0:01:09s\n",
            "epoch 76 | loss: 1.18439 | train_mae: 0.03873 | valid_mae: 0.03867 |  0:01:10s\n",
            "epoch 77 | loss: 1.0818  | train_mae: 0.03033 | valid_mae: 0.03386 |  0:01:12s\n",
            "epoch 78 | loss: 1.07529 | train_mae: 0.0324  | valid_mae: 0.03685 |  0:01:13s\n",
            "epoch 79 | loss: 1.04829 | train_mae: 0.03082 | valid_mae: 0.03372 |  0:01:14s\n",
            "epoch 80 | loss: 1.04971 | train_mae: 0.03149 | valid_mae: 0.03586 |  0:01:15s\n",
            "epoch 81 | loss: 1.04545 | train_mae: 0.03111 | valid_mae: 0.03503 |  0:01:15s\n",
            "epoch 82 | loss: 0.98677 | train_mae: 0.03089 | valid_mae: 0.03606 |  0:01:16s\n",
            "epoch 83 | loss: 1.00994 | train_mae: 0.0313  | valid_mae: 0.03627 |  0:01:17s\n",
            "epoch 84 | loss: 1.04613 | train_mae: 0.03402 | valid_mae: 0.03933 |  0:01:18s\n",
            "epoch 85 | loss: 1.06924 | train_mae: 0.0315  | valid_mae: 0.03605 |  0:01:19s\n",
            "epoch 86 | loss: 1.0184  | train_mae: 0.033   | valid_mae: 0.0378  |  0:01:20s\n",
            "epoch 87 | loss: 1.01726 | train_mae: 0.03375 | valid_mae: 0.03846 |  0:01:20s\n",
            "epoch 88 | loss: 1.1327  | train_mae: 0.03293 | valid_mae: 0.03844 |  0:01:21s\n",
            "epoch 89 | loss: 1.12615 | train_mae: 0.02872 | valid_mae: 0.03392 |  0:01:22s\n",
            "epoch 90 | loss: 0.97591 | train_mae: 0.03225 | valid_mae: 0.03735 |  0:01:23s\n",
            "epoch 91 | loss: 1.06244 | train_mae: 0.03179 | valid_mae: 0.03811 |  0:01:24s\n",
            "epoch 92 | loss: 1.02978 | train_mae: 0.03136 | valid_mae: 0.03901 |  0:01:26s\n",
            "epoch 93 | loss: 0.99557 | train_mae: 0.03434 | valid_mae: 0.03967 |  0:01:26s\n",
            "epoch 94 | loss: 1.01549 | train_mae: 0.02989 | valid_mae: 0.03404 |  0:01:27s\n",
            "epoch 95 | loss: 1.03119 | train_mae: 0.03371 | valid_mae: 0.03819 |  0:01:28s\n",
            "epoch 96 | loss: 1.00607 | train_mae: 0.03009 | valid_mae: 0.03377 |  0:01:29s\n",
            "epoch 97 | loss: 1.02038 | train_mae: 0.03441 | valid_mae: 0.03858 |  0:01:30s\n",
            "epoch 98 | loss: 1.14877 | train_mae: 0.03483 | valid_mae: 0.03646 |  0:01:31s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-09-05 01:04:07,523] Trial 3 finished with value: 1.194831085205078 and parameters: {'n_d': 28, 'n_a': 27, 'n_steps': 5, 'gamma': 1.2495920381949346, 'lambda_sparse': 0.0009250338708854, 'batch_size': 128, 'mask_type': 'entmax', 'emb': 7, 'momentum': 0.6857381061431107, 'learning_rate': 0.034190280227121395, 'weight_decay': 4.690039315714738e-06, 'scheduler_gamma': 0.9565161090657542, 'step_size': 13, 'virtual_batch_size': 32, 'optimizer_type': 'adamw', 'p': 0.1543181299843592}. Best is trial 0 with value: 0.9738839268684387.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 99 | loss: 1.19483 | train_mae: 0.03837 | valid_mae: 0.04316 |  0:01:32s\n",
            "Stop training because you reached max_epochs = 100 with best_epoch = 75 and best_valid_mae = 0.03336\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 962.46525| train_mae: 6.68152 | valid_mae: 8.43294 |  0:00:00s\n",
            "epoch 1  | loss: 486.95857| train_mae: 3.65691 | valid_mae: 3.97851 |  0:00:01s\n",
            "epoch 2  | loss: 366.68249| train_mae: 2.87012 | valid_mae: 2.74586 |  0:00:02s\n",
            "epoch 3  | loss: 275.65892| train_mae: 3.41702 | valid_mae: 3.57654 |  0:00:03s\n",
            "epoch 4  | loss: 220.21466| train_mae: 2.51612 | valid_mae: 2.54628 |  0:00:04s\n",
            "epoch 5  | loss: 236.5451| train_mae: 1.84592 | valid_mae: 2.07188 |  0:00:05s\n",
            "epoch 6  | loss: 288.76661| train_mae: 2.05965 | valid_mae: 1.92918 |  0:00:06s\n",
            "epoch 7  | loss: 217.16182| train_mae: 1.75842 | valid_mae: 2.20854 |  0:00:06s\n",
            "epoch 8  | loss: 179.72555| train_mae: 1.7915  | valid_mae: 1.44215 |  0:00:07s\n",
            "epoch 9  | loss: 151.61989| train_mae: 1.87635 | valid_mae: 1.9799  |  0:00:08s\n",
            "epoch 10 | loss: 167.93586| train_mae: 1.60824 | valid_mae: 2.16505 |  0:00:09s\n",
            "epoch 11 | loss: 202.62447| train_mae: 1.49691 | valid_mae: 1.94063 |  0:00:09s\n",
            "epoch 12 | loss: 168.4035| train_mae: 1.51277 | valid_mae: 1.48131 |  0:00:10s\n",
            "epoch 13 | loss: 191.57277| train_mae: 1.69048 | valid_mae: 1.58819 |  0:00:11s\n",
            "epoch 14 | loss: 166.71732| train_mae: 1.84371 | valid_mae: 1.62201 |  0:00:12s\n",
            "epoch 15 | loss: 143.55527| train_mae: 1.75759 | valid_mae: 1.75602 |  0:00:12s\n",
            "epoch 16 | loss: 144.47729| train_mae: 1.66949 | valid_mae: 1.57816 |  0:00:13s\n",
            "epoch 17 | loss: 136.30183| train_mae: 1.50812 | valid_mae: 1.53948 |  0:00:14s\n",
            "epoch 18 | loss: 132.09899| train_mae: 1.16986 | valid_mae: 1.21291 |  0:00:15s\n",
            "epoch 19 | loss: 211.23727| train_mae: 1.28295 | valid_mae: 1.33208 |  0:00:16s\n",
            "epoch 20 | loss: 95.85945| train_mae: 1.23677 | valid_mae: 1.23724 |  0:00:17s\n",
            "epoch 21 | loss: 105.32298| train_mae: 1.28885 | valid_mae: 1.34759 |  0:00:18s\n",
            "epoch 22 | loss: 94.27575| train_mae: 1.39665 | valid_mae: 1.44149 |  0:00:18s\n",
            "epoch 23 | loss: 144.09962| train_mae: 1.31937 | valid_mae: 1.39477 |  0:00:19s\n",
            "epoch 24 | loss: 103.03529| train_mae: 1.2101  | valid_mae: 1.14726 |  0:00:20s\n",
            "epoch 25 | loss: 94.61199| train_mae: 1.17716 | valid_mae: 1.1546  |  0:00:21s\n",
            "epoch 26 | loss: 82.55786| train_mae: 1.22418 | valid_mae: 1.15174 |  0:00:21s\n",
            "epoch 27 | loss: 96.20786| train_mae: 1.17369 | valid_mae: 1.14997 |  0:00:22s\n",
            "epoch 28 | loss: 99.31468| train_mae: 1.06776 | valid_mae: 1.08816 |  0:00:23s\n",
            "epoch 29 | loss: 77.25213| train_mae: 1.06512 | valid_mae: 1.05884 |  0:00:24s\n",
            "epoch 30 | loss: 92.86196| train_mae: 1.00561 | valid_mae: 0.90282 |  0:00:24s\n",
            "epoch 31 | loss: 76.31391| train_mae: 0.94851 | valid_mae: 0.79553 |  0:00:25s\n",
            "epoch 32 | loss: 133.86625| train_mae: 0.81464 | valid_mae: 0.88118 |  0:00:26s\n",
            "epoch 33 | loss: 70.86717| train_mae: 0.76218 | valid_mae: 0.71241 |  0:00:27s\n",
            "epoch 34 | loss: 88.52294| train_mae: 0.73377 | valid_mae: 0.71746 |  0:00:28s\n",
            "epoch 35 | loss: 69.68799| train_mae: 0.74533 | valid_mae: 0.65897 |  0:00:29s\n",
            "epoch 36 | loss: 76.28628| train_mae: 0.73262 | valid_mae: 0.6154  |  0:00:30s\n",
            "epoch 37 | loss: 70.23931| train_mae: 0.59199 | valid_mae: 0.51266 |  0:00:31s\n",
            "epoch 38 | loss: 93.63741| train_mae: 0.51457 | valid_mae: 0.43439 |  0:00:31s\n",
            "epoch 39 | loss: 79.18315| train_mae: 0.48517 | valid_mae: 0.49945 |  0:00:32s\n",
            "epoch 40 | loss: 72.28199| train_mae: 0.47664 | valid_mae: 0.52267 |  0:00:33s\n",
            "epoch 41 | loss: 58.36132| train_mae: 0.39799 | valid_mae: 0.53296 |  0:00:33s\n",
            "epoch 42 | loss: 69.95267| train_mae: 0.38024 | valid_mae: 0.41044 |  0:00:34s\n",
            "epoch 43 | loss: 73.02163| train_mae: 0.36091 | valid_mae: 0.37458 |  0:00:35s\n",
            "epoch 44 | loss: 127.8899| train_mae: 0.3665  | valid_mae: 0.339   |  0:00:36s\n",
            "epoch 45 | loss: 73.40322| train_mae: 0.35547 | valid_mae: 0.31267 |  0:00:36s\n",
            "epoch 46 | loss: 63.05045| train_mae: 0.32991 | valid_mae: 0.35044 |  0:00:37s\n",
            "epoch 47 | loss: 64.89467| train_mae: 0.34517 | valid_mae: 0.35261 |  0:00:38s\n",
            "epoch 48 | loss: 65.93544| train_mae: 0.36924 | valid_mae: 0.41815 |  0:00:39s\n",
            "epoch 49 | loss: 54.03774| train_mae: 0.4604  | valid_mae: 0.41579 |  0:00:39s\n",
            "epoch 50 | loss: 47.07887| train_mae: 0.4299  | valid_mae: 0.37336 |  0:00:41s\n",
            "epoch 51 | loss: 51.32466| train_mae: 0.33849 | valid_mae: 0.35072 |  0:00:42s\n",
            "epoch 52 | loss: 56.44604| train_mae: 0.29521 | valid_mae: 0.43002 |  0:00:43s\n",
            "epoch 53 | loss: 54.78629| train_mae: 0.2841  | valid_mae: 0.47616 |  0:00:43s\n",
            "epoch 54 | loss: 57.66564| train_mae: 0.27573 | valid_mae: 0.35135 |  0:00:44s\n",
            "epoch 55 | loss: 46.47835| train_mae: 0.28604 | valid_mae: 0.3053  |  0:00:45s\n",
            "epoch 56 | loss: 46.51673| train_mae: 0.26768 | valid_mae: 0.36276 |  0:00:46s\n",
            "epoch 57 | loss: 66.1249 | train_mae: 0.29138 | valid_mae: 0.37542 |  0:00:46s\n",
            "epoch 58 | loss: 49.30576| train_mae: 0.25642 | valid_mae: 0.31794 |  0:00:47s\n",
            "epoch 59 | loss: 41.28388| train_mae: 0.2449  | valid_mae: 0.24535 |  0:00:48s\n",
            "epoch 60 | loss: 51.05593| train_mae: 0.26537 | valid_mae: 0.23725 |  0:00:49s\n",
            "epoch 61 | loss: 37.35767| train_mae: 0.24801 | valid_mae: 0.22475 |  0:00:49s\n",
            "epoch 62 | loss: 48.37229| train_mae: 0.22298 | valid_mae: 0.308   |  0:00:50s\n",
            "epoch 63 | loss: 31.33733| train_mae: 0.23121 | valid_mae: 0.22804 |  0:00:51s\n",
            "epoch 64 | loss: 52.35288| train_mae: 0.2441  | valid_mae: 0.27964 |  0:00:52s\n",
            "epoch 65 | loss: 40.57233| train_mae: 0.2341  | valid_mae: 0.25238 |  0:00:52s\n",
            "epoch 66 | loss: 49.18125| train_mae: 0.22986 | valid_mae: 0.25472 |  0:00:53s\n",
            "epoch 67 | loss: 50.03593| train_mae: 0.22568 | valid_mae: 0.23399 |  0:00:54s\n",
            "epoch 68 | loss: 39.90319| train_mae: 0.2107  | valid_mae: 0.23676 |  0:00:55s\n",
            "epoch 69 | loss: 36.74433| train_mae: 0.22835 | valid_mae: 0.24312 |  0:00:56s\n",
            "epoch 70 | loss: 38.87142| train_mae: 0.21974 | valid_mae: 0.22995 |  0:00:57s\n",
            "epoch 71 | loss: 45.08905| train_mae: 0.21711 | valid_mae: 0.19875 |  0:00:58s\n",
            "epoch 72 | loss: 38.60699| train_mae: 0.2085  | valid_mae: 0.23184 |  0:00:58s\n",
            "epoch 73 | loss: 29.80987| train_mae: 0.21233 | valid_mae: 0.2386  |  0:00:59s\n",
            "epoch 74 | loss: 33.42074| train_mae: 0.19949 | valid_mae: 0.22004 |  0:01:00s\n",
            "epoch 75 | loss: 50.36977| train_mae: 0.20611 | valid_mae: 0.19704 |  0:01:00s\n",
            "epoch 76 | loss: 31.82796| train_mae: 0.21117 | valid_mae: 0.16934 |  0:01:01s\n",
            "epoch 77 | loss: 33.53651| train_mae: 0.21867 | valid_mae: 0.27664 |  0:01:02s\n",
            "epoch 78 | loss: 27.86164| train_mae: 0.21129 | valid_mae: 0.29364 |  0:01:03s\n",
            "epoch 79 | loss: 35.9061 | train_mae: 0.19714 | valid_mae: 0.25973 |  0:01:03s\n",
            "epoch 80 | loss: 36.43798| train_mae: 0.19699 | valid_mae: 0.35821 |  0:01:04s\n",
            "epoch 81 | loss: 32.742  | train_mae: 0.19775 | valid_mae: 0.43314 |  0:01:05s\n",
            "epoch 82 | loss: 29.37542| train_mae: 0.26178 | valid_mae: 0.18447 |  0:01:06s\n",
            "epoch 83 | loss: 29.94975| train_mae: 0.24141 | valid_mae: 0.19837 |  0:01:07s\n",
            "epoch 84 | loss: 21.78635| train_mae: 0.24799 | valid_mae: 0.20113 |  0:01:08s\n",
            "epoch 85 | loss: 22.66777| train_mae: 0.24234 | valid_mae: 0.16131 |  0:01:09s\n",
            "epoch 86 | loss: 22.91552| train_mae: 0.23532 | valid_mae: 0.16359 |  0:01:10s\n",
            "epoch 87 | loss: 21.08174| train_mae: 0.2313  | valid_mae: 0.18967 |  0:01:10s\n",
            "epoch 88 | loss: 28.4746 | train_mae: 0.23646 | valid_mae: 0.21196 |  0:01:11s\n",
            "epoch 89 | loss: 38.34851| train_mae: 0.23331 | valid_mae: 0.16279 |  0:01:12s\n",
            "epoch 90 | loss: 25.35707| train_mae: 0.23932 | valid_mae: 0.19082 |  0:01:12s\n",
            "epoch 91 | loss: 27.1823 | train_mae: 0.25352 | valid_mae: 0.18012 |  0:01:13s\n",
            "epoch 92 | loss: 24.21344| train_mae: 0.23295 | valid_mae: 0.1648  |  0:01:14s\n",
            "epoch 93 | loss: 22.56907| train_mae: 0.234   | valid_mae: 0.16649 |  0:01:15s\n",
            "epoch 94 | loss: 26.45346| train_mae: 0.23606 | valid_mae: 0.15628 |  0:01:15s\n",
            "epoch 95 | loss: 28.78664| train_mae: 0.22976 | valid_mae: 0.15022 |  0:01:16s\n",
            "epoch 96 | loss: 24.63747| train_mae: 0.22831 | valid_mae: 0.14562 |  0:01:17s\n",
            "epoch 97 | loss: 35.96938| train_mae: 0.22495 | valid_mae: 0.16156 |  0:01:18s\n",
            "epoch 98 | loss: 18.00125| train_mae: 0.22234 | valid_mae: 0.15188 |  0:01:18s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-09-05 01:05:30,503] Trial 4 finished with value: 22.55940475463867 and parameters: {'n_d': 29, 'n_a': 12, 'n_steps': 4, 'gamma': 1.6443726056923176, 'lambda_sparse': 4.652883904534736e-06, 'batch_size': 128, 'mask_type': 'sparsemax', 'emb': 21, 'momentum': 0.8314368442703023, 'learning_rate': 0.00012594572072765616, 'weight_decay': 9.81344544332143e-05, 'scheduler_gamma': 0.9551474070678609, 'step_size': 10, 'virtual_batch_size': 64, 'optimizer_type': 'rmsprop', 'p': 0.06688762176971015}. Best is trial 0 with value: 0.9738839268684387.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 99 | loss: 22.5594 | train_mae: 0.21492 | valid_mae: 0.16104 |  0:01:19s\n",
            "Stop training because you reached max_epochs = 100 with best_epoch = 96 and best_valid_mae = 0.14562\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 991.35767| train_mae: 13.67062| valid_mae: 13.06469|  0:00:00s\n",
            "epoch 1  | loss: 757.55277| train_mae: 9.29333 | valid_mae: 9.06096 |  0:00:01s\n",
            "epoch 2  | loss: 743.9282| train_mae: 7.37148 | valid_mae: 8.86803 |  0:00:01s\n",
            "epoch 3  | loss: 899.97821| train_mae: 5.3395  | valid_mae: 8.08884 |  0:00:02s\n",
            "epoch 4  | loss: 741.38276| train_mae: 5.57284 | valid_mae: 6.56157 |  0:00:02s\n",
            "epoch 5  | loss: 779.46013| train_mae: 5.06104 | valid_mae: 5.947   |  0:00:03s\n",
            "epoch 6  | loss: 872.3205| train_mae: 4.69869 | valid_mae: 5.00539 |  0:00:04s\n",
            "epoch 7  | loss: 721.66542| train_mae: 4.76428 | valid_mae: 4.85289 |  0:00:04s\n",
            "epoch 8  | loss: 614.10013| train_mae: 3.90543 | valid_mae: 4.5283  |  0:00:05s\n",
            "epoch 9  | loss: 642.94136| train_mae: 3.27986 | valid_mae: 4.03052 |  0:00:05s\n",
            "epoch 10 | loss: 627.92684| train_mae: 3.15923 | valid_mae: 3.60973 |  0:00:06s\n",
            "epoch 11 | loss: 629.4043| train_mae: 3.00987 | valid_mae: 3.21151 |  0:00:07s\n",
            "epoch 12 | loss: 508.75687| train_mae: 3.50572 | valid_mae: 3.28175 |  0:00:07s\n",
            "epoch 13 | loss: 504.15482| train_mae: 2.67156 | valid_mae: 2.5352  |  0:00:08s\n",
            "epoch 14 | loss: 422.07109| train_mae: 2.72436 | valid_mae: 2.36559 |  0:00:09s\n",
            "epoch 15 | loss: 513.58871| train_mae: 3.20051 | valid_mae: 2.98589 |  0:00:09s\n",
            "epoch 16 | loss: 601.54313| train_mae: 3.00764 | valid_mae: 2.69453 |  0:00:10s\n",
            "epoch 17 | loss: 533.2578| train_mae: 3.17845 | valid_mae: 2.94424 |  0:00:11s\n",
            "epoch 18 | loss: 358.19239| train_mae: 3.26487 | valid_mae: 2.6054  |  0:00:12s\n",
            "epoch 19 | loss: 418.23398| train_mae: 3.25944 | valid_mae: 2.52963 |  0:00:12s\n",
            "epoch 20 | loss: 455.18268| train_mae: 3.15258 | valid_mae: 2.59784 |  0:00:13s\n",
            "epoch 21 | loss: 425.46757| train_mae: 2.91391 | valid_mae: 2.593   |  0:00:13s\n",
            "epoch 22 | loss: 539.11966| train_mae: 2.56673 | valid_mae: 2.25689 |  0:00:14s\n",
            "epoch 23 | loss: 533.3483| train_mae: 2.84525 | valid_mae: 2.75338 |  0:00:15s\n",
            "epoch 24 | loss: 429.18372| train_mae: 2.54901 | valid_mae: 3.0503  |  0:00:15s\n",
            "epoch 25 | loss: 440.79889| train_mae: 2.7918  | valid_mae: 3.00652 |  0:00:16s\n",
            "epoch 26 | loss: 461.23053| train_mae: 2.59913 | valid_mae: 3.43679 |  0:00:16s\n",
            "epoch 27 | loss: 564.43868| train_mae: 2.44581 | valid_mae: 2.55781 |  0:00:17s\n",
            "epoch 28 | loss: 370.25737| train_mae: 2.32708 | valid_mae: 2.45156 |  0:00:18s\n",
            "epoch 29 | loss: 411.32584| train_mae: 2.17233 | valid_mae: 2.82448 |  0:00:18s\n",
            "epoch 30 | loss: 344.23925| train_mae: 2.44852 | valid_mae: 2.31842 |  0:00:19s\n",
            "epoch 31 | loss: 329.10579| train_mae: 2.25119 | valid_mae: 2.23383 |  0:00:19s\n",
            "epoch 32 | loss: 315.82158| train_mae: 2.29717 | valid_mae: 1.8316  |  0:00:20s\n",
            "epoch 33 | loss: 375.64889| train_mae: 2.11436 | valid_mae: 1.66564 |  0:00:21s\n",
            "epoch 34 | loss: 278.21064| train_mae: 2.08128 | valid_mae: 1.83193 |  0:00:21s\n",
            "epoch 35 | loss: 217.88907| train_mae: 1.92278 | valid_mae: 1.86734 |  0:00:22s\n",
            "epoch 36 | loss: 245.06396| train_mae: 2.06986 | valid_mae: 1.87688 |  0:00:23s\n",
            "epoch 37 | loss: 197.23768| train_mae: 1.86631 | valid_mae: 1.83737 |  0:00:24s\n",
            "epoch 38 | loss: 275.02968| train_mae: 1.96444 | valid_mae: 1.66467 |  0:00:24s\n",
            "epoch 39 | loss: 309.87562| train_mae: 1.88171 | valid_mae: 2.12833 |  0:00:25s\n",
            "epoch 40 | loss: 224.16673| train_mae: 1.75863 | valid_mae: 1.70134 |  0:00:26s\n",
            "epoch 41 | loss: 242.76573| train_mae: 1.80159 | valid_mae: 1.69493 |  0:00:26s\n",
            "epoch 42 | loss: 260.89399| train_mae: 1.64397 | valid_mae: 1.39745 |  0:00:27s\n",
            "epoch 43 | loss: 208.7702| train_mae: 1.6218  | valid_mae: 1.32423 |  0:00:27s\n",
            "epoch 44 | loss: 316.27628| train_mae: 1.6464  | valid_mae: 1.14774 |  0:00:28s\n",
            "epoch 45 | loss: 331.93546| train_mae: 1.63641 | valid_mae: 1.27877 |  0:00:28s\n",
            "epoch 46 | loss: 397.64456| train_mae: 1.54145 | valid_mae: 1.31945 |  0:00:29s\n",
            "epoch 47 | loss: 272.22953| train_mae: 1.56504 | valid_mae: 1.34881 |  0:00:30s\n",
            "epoch 48 | loss: 246.83854| train_mae: 1.50029 | valid_mae: 0.94138 |  0:00:30s\n",
            "epoch 49 | loss: 223.34513| train_mae: 1.41231 | valid_mae: 1.12181 |  0:00:31s\n",
            "epoch 50 | loss: 247.94655| train_mae: 1.23626 | valid_mae: 1.11984 |  0:00:31s\n",
            "epoch 51 | loss: 222.68535| train_mae: 1.16924 | valid_mae: 1.78802 |  0:00:32s\n",
            "epoch 52 | loss: 175.45836| train_mae: 1.1283  | valid_mae: 1.60382 |  0:00:33s\n",
            "epoch 53 | loss: 182.39164| train_mae: 0.98913 | valid_mae: 1.13899 |  0:00:33s\n",
            "epoch 54 | loss: 166.64548| train_mae: 0.97338 | valid_mae: 0.89546 |  0:00:34s\n",
            "epoch 55 | loss: 205.07169| train_mae: 0.92701 | valid_mae: 0.8506  |  0:00:34s\n",
            "epoch 56 | loss: 289.47639| train_mae: 0.89041 | valid_mae: 0.9106  |  0:00:35s\n",
            "epoch 57 | loss: 356.51445| train_mae: 1.01998 | valid_mae: 0.81301 |  0:00:36s\n",
            "epoch 58 | loss: 163.06274| train_mae: 0.9557  | valid_mae: 0.72046 |  0:00:37s\n",
            "epoch 59 | loss: 233.90254| train_mae: 0.81274 | valid_mae: 0.63301 |  0:00:38s\n",
            "epoch 60 | loss: 275.75677| train_mae: 0.77375 | valid_mae: 0.65606 |  0:00:38s\n",
            "epoch 61 | loss: 216.6603| train_mae: 0.69316 | valid_mae: 0.63292 |  0:00:39s\n",
            "epoch 62 | loss: 220.72257| train_mae: 0.62537 | valid_mae: 0.75067 |  0:00:39s\n",
            "epoch 63 | loss: 183.6055| train_mae: 0.62528 | valid_mae: 0.6074  |  0:00:40s\n",
            "epoch 64 | loss: 167.72273| train_mae: 0.66526 | valid_mae: 0.62903 |  0:00:40s\n",
            "epoch 65 | loss: 175.14605| train_mae: 0.66302 | valid_mae: 0.75715 |  0:00:41s\n",
            "epoch 66 | loss: 176.8578| train_mae: 0.62463 | valid_mae: 0.55657 |  0:00:42s\n",
            "epoch 67 | loss: 218.29266| train_mae: 0.63901 | valid_mae: 0.55557 |  0:00:42s\n",
            "epoch 68 | loss: 207.24937| train_mae: 0.57529 | valid_mae: 0.57793 |  0:00:43s\n",
            "epoch 69 | loss: 184.69583| train_mae: 0.55129 | valid_mae: 0.49082 |  0:00:43s\n",
            "epoch 70 | loss: 197.49648| train_mae: 0.58588 | valid_mae: 0.51013 |  0:00:44s\n",
            "epoch 71 | loss: 200.29635| train_mae: 0.58223 | valid_mae: 0.44149 |  0:00:45s\n",
            "epoch 72 | loss: 211.79465| train_mae: 0.60448 | valid_mae: 0.44376 |  0:00:45s\n",
            "epoch 73 | loss: 175.05482| train_mae: 0.57185 | valid_mae: 0.46848 |  0:00:46s\n",
            "epoch 74 | loss: 164.63177| train_mae: 0.55371 | valid_mae: 0.45385 |  0:00:46s\n",
            "epoch 75 | loss: 187.72942| train_mae: 0.5863  | valid_mae: 0.47966 |  0:00:47s\n",
            "epoch 76 | loss: 175.97493| train_mae: 0.57084 | valid_mae: 0.47194 |  0:00:48s\n",
            "epoch 77 | loss: 209.01861| train_mae: 0.5631  | valid_mae: 0.46576 |  0:00:49s\n",
            "epoch 78 | loss: 175.6818| train_mae: 0.5108  | valid_mae: 0.4278  |  0:00:49s\n",
            "epoch 79 | loss: 244.75078| train_mae: 0.50737 | valid_mae: 0.37395 |  0:00:50s\n",
            "epoch 80 | loss: 193.12726| train_mae: 0.52375 | valid_mae: 0.38643 |  0:00:51s\n",
            "epoch 81 | loss: 175.47837| train_mae: 0.48833 | valid_mae: 0.39328 |  0:00:51s\n",
            "epoch 82 | loss: 123.39592| train_mae: 0.49523 | valid_mae: 0.40855 |  0:00:52s\n",
            "epoch 83 | loss: 230.27472| train_mae: 0.45586 | valid_mae: 0.37757 |  0:00:53s\n",
            "epoch 84 | loss: 165.96817| train_mae: 0.50168 | valid_mae: 0.36627 |  0:00:53s\n",
            "epoch 85 | loss: 183.80363| train_mae: 0.48362 | valid_mae: 0.41289 |  0:00:54s\n",
            "epoch 86 | loss: 145.8763| train_mae: 0.4503  | valid_mae: 0.36159 |  0:00:54s\n",
            "epoch 87 | loss: 158.9464| train_mae: 0.44946 | valid_mae: 0.36322 |  0:00:55s\n",
            "epoch 88 | loss: 177.34094| train_mae: 0.45529 | valid_mae: 0.39082 |  0:00:56s\n",
            "epoch 89 | loss: 131.94327| train_mae: 0.45058 | valid_mae: 0.40515 |  0:00:56s\n",
            "epoch 90 | loss: 191.51707| train_mae: 0.44103 | valid_mae: 0.37605 |  0:00:57s\n",
            "epoch 91 | loss: 136.61753| train_mae: 0.4343  | valid_mae: 0.35517 |  0:00:57s\n",
            "epoch 92 | loss: 155.90032| train_mae: 0.45023 | valid_mae: 0.38746 |  0:00:58s\n",
            "epoch 93 | loss: 198.76805| train_mae: 0.41948 | valid_mae: 0.36964 |  0:00:59s\n",
            "epoch 94 | loss: 144.4165| train_mae: 0.41756 | valid_mae: 0.40144 |  0:00:59s\n",
            "epoch 95 | loss: 126.27527| train_mae: 0.4037  | valid_mae: 0.40207 |  0:01:00s\n",
            "epoch 96 | loss: 139.46447| train_mae: 0.4019  | valid_mae: 0.43375 |  0:01:00s\n",
            "epoch 97 | loss: 155.57475| train_mae: 0.3659  | valid_mae: 0.44772 |  0:01:01s\n",
            "epoch 98 | loss: 153.05412| train_mae: 0.36232 | valid_mae: 0.41728 |  0:01:02s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-09-05 01:06:37,513] Trial 5 finished with value: 173.59736328125 and parameters: {'n_d': 28, 'n_a': 13, 'n_steps': 3, 'gamma': 1.5166302694434597, 'lambda_sparse': 0.00039427604737276233, 'batch_size': 256, 'mask_type': 'sparsemax', 'emb': 7, 'momentum': 0.5010669272295919, 'learning_rate': 0.04832702929865175, 'weight_decay': 7.892817903140774e-06, 'scheduler_gamma': 0.9866203377915265, 'step_size': 8, 'virtual_batch_size': 64, 'optimizer_type': 'sgd', 'p': 0.10812783563072348}. Best is trial 0 with value: 0.9738839268684387.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 99 | loss: 173.59736| train_mae: 0.35609 | valid_mae: 0.38004 |  0:01:03s\n",
            "Stop training because you reached max_epochs = 100 with best_epoch = 91 and best_valid_mae = 0.35517\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 507.6759| train_mae: 10.27267| valid_mae: 10.12384|  0:00:00s\n",
            "epoch 1  | loss: 220.62203| train_mae: 8.3332  | valid_mae: 9.06415 |  0:00:01s\n",
            "epoch 2  | loss: 134.58636| train_mae: 4.85297 | valid_mae: 4.76894 |  0:00:01s\n",
            "epoch 3  | loss: 77.9097 | train_mae: 3.4975  | valid_mae: 3.61771 |  0:00:02s\n",
            "epoch 4  | loss: 69.2581 | train_mae: 1.9714  | valid_mae: 1.97882 |  0:00:03s\n",
            "epoch 5  | loss: 71.11578| train_mae: 2.236   | valid_mae: 2.2312  |  0:00:03s\n",
            "epoch 6  | loss: 45.69907| train_mae: 1.80991 | valid_mae: 1.80325 |  0:00:04s\n",
            "epoch 7  | loss: 44.90573| train_mae: 1.78267 | valid_mae: 1.59591 |  0:00:05s\n",
            "epoch 8  | loss: 48.90499| train_mae: 1.11093 | valid_mae: 1.31297 |  0:00:05s\n",
            "epoch 9  | loss: 37.45775| train_mae: 1.71921 | valid_mae: 1.67412 |  0:00:06s\n",
            "epoch 10 | loss: 31.91646| train_mae: 1.72807 | valid_mae: 1.98666 |  0:00:06s\n",
            "epoch 11 | loss: 31.98235| train_mae: 1.34753 | valid_mae: 1.65278 |  0:00:07s\n",
            "epoch 12 | loss: 17.4158 | train_mae: 1.45339 | valid_mae: 1.71567 |  0:00:08s\n",
            "epoch 13 | loss: 17.32984| train_mae: 1.25693 | valid_mae: 1.36737 |  0:00:09s\n",
            "epoch 14 | loss: 15.40237| train_mae: 1.23091 | valid_mae: 1.728   |  0:00:10s\n",
            "epoch 15 | loss: 15.28391| train_mae: 1.30862 | valid_mae: 1.40329 |  0:00:10s\n",
            "epoch 16 | loss: 12.48828| train_mae: 1.42623 | valid_mae: 1.36987 |  0:00:11s\n",
            "epoch 17 | loss: 14.19615| train_mae: 1.80571 | valid_mae: 1.81709 |  0:00:12s\n",
            "epoch 18 | loss: 11.95388| train_mae: 1.85098 | valid_mae: 1.88527 |  0:00:12s\n",
            "epoch 19 | loss: 12.21572| train_mae: 1.69784 | valid_mae: 1.69416 |  0:00:13s\n",
            "epoch 20 | loss: 11.87555| train_mae: 1.87689 | valid_mae: 1.7526  |  0:00:14s\n",
            "epoch 21 | loss: 9.87726 | train_mae: 1.91412 | valid_mae: 1.85548 |  0:00:14s\n",
            "epoch 22 | loss: 8.67297 | train_mae: 1.46785 | valid_mae: 1.46209 |  0:00:15s\n",
            "epoch 23 | loss: 7.53204 | train_mae: 1.39831 | valid_mae: 1.40326 |  0:00:15s\n",
            "epoch 24 | loss: 6.4363  | train_mae: 0.87623 | valid_mae: 0.79938 |  0:00:16s\n",
            "epoch 25 | loss: 6.77476 | train_mae: 0.80447 | valid_mae: 0.80501 |  0:00:17s\n",
            "epoch 26 | loss: 6.9195  | train_mae: 0.7428  | valid_mae: 0.75886 |  0:00:17s\n",
            "epoch 27 | loss: 5.49916 | train_mae: 0.57548 | valid_mae: 0.56394 |  0:00:18s\n",
            "epoch 28 | loss: 6.02872 | train_mae: 0.49078 | valid_mae: 0.41034 |  0:00:19s\n",
            "epoch 29 | loss: 9.66971 | train_mae: 0.29545 | valid_mae: 0.30834 |  0:00:19s\n",
            "epoch 30 | loss: 5.84594 | train_mae: 0.30453 | valid_mae: 0.30083 |  0:00:20s\n",
            "epoch 31 | loss: 3.90798 | train_mae: 0.30038 | valid_mae: 0.25192 |  0:00:21s\n",
            "epoch 32 | loss: 3.88039 | train_mae: 0.24973 | valid_mae: 0.22479 |  0:00:22s\n",
            "epoch 33 | loss: 3.39376 | train_mae: 0.23889 | valid_mae: 0.22655 |  0:00:23s\n",
            "epoch 34 | loss: 3.91523 | train_mae: 0.21872 | valid_mae: 0.19222 |  0:00:23s\n",
            "epoch 35 | loss: 3.458   | train_mae: 0.1947  | valid_mae: 0.17777 |  0:00:24s\n",
            "epoch 36 | loss: 3.0092  | train_mae: 0.17028 | valid_mae: 0.18253 |  0:00:25s\n",
            "epoch 37 | loss: 3.07225 | train_mae: 0.16208 | valid_mae: 0.1542  |  0:00:25s\n",
            "epoch 38 | loss: 2.21124 | train_mae: 0.13431 | valid_mae: 0.12401 |  0:00:26s\n",
            "epoch 39 | loss: 3.03392 | train_mae: 0.11129 | valid_mae: 0.15975 |  0:00:27s\n",
            "epoch 40 | loss: 2.41777 | train_mae: 0.10645 | valid_mae: 0.11992 |  0:00:27s\n",
            "epoch 41 | loss: 2.18575 | train_mae: 0.10662 | valid_mae: 0.09608 |  0:00:28s\n",
            "epoch 42 | loss: 1.91908 | train_mae: 0.11832 | valid_mae: 0.11683 |  0:00:28s\n",
            "epoch 43 | loss: 2.02326 | train_mae: 0.09777 | valid_mae: 0.09068 |  0:00:29s\n",
            "epoch 44 | loss: 1.80592 | train_mae: 0.09613 | valid_mae: 0.10684 |  0:00:30s\n",
            "epoch 45 | loss: 1.65208 | train_mae: 0.08627 | valid_mae: 0.10183 |  0:00:30s\n",
            "epoch 46 | loss: 1.63168 | train_mae: 0.08254 | valid_mae: 0.10243 |  0:00:31s\n",
            "epoch 47 | loss: 1.65652 | train_mae: 0.07618 | valid_mae: 0.09828 |  0:00:32s\n",
            "epoch 48 | loss: 1.74717 | train_mae: 0.0703  | valid_mae: 0.0877  |  0:00:34s\n",
            "epoch 49 | loss: 1.61191 | train_mae: 0.06611 | valid_mae: 0.08905 |  0:00:37s\n",
            "epoch 50 | loss: 1.44682 | train_mae: 0.058   | valid_mae: 0.07689 |  0:00:38s\n",
            "epoch 51 | loss: 1.32144 | train_mae: 0.05721 | valid_mae: 0.0827  |  0:00:39s\n",
            "epoch 52 | loss: 1.72823 | train_mae: 0.05252 | valid_mae: 0.07753 |  0:00:40s\n",
            "epoch 53 | loss: 1.32768 | train_mae: 0.05043 | valid_mae: 0.07446 |  0:00:42s\n",
            "epoch 54 | loss: 1.19997 | train_mae: 0.04956 | valid_mae: 0.07113 |  0:00:43s\n",
            "epoch 55 | loss: 1.26891 | train_mae: 0.04618 | valid_mae: 0.07072 |  0:00:44s\n",
            "epoch 56 | loss: 1.76537 | train_mae: 0.04377 | valid_mae: 0.06175 |  0:00:45s\n",
            "epoch 57 | loss: 1.4618  | train_mae: 0.04521 | valid_mae: 0.07005 |  0:00:46s\n",
            "epoch 58 | loss: 1.31461 | train_mae: 0.04545 | valid_mae: 0.06788 |  0:00:47s\n",
            "epoch 59 | loss: 1.1129  | train_mae: 0.04322 | valid_mae: 0.0605  |  0:00:48s\n",
            "epoch 60 | loss: 1.10894 | train_mae: 0.04104 | valid_mae: 0.05838 |  0:00:48s\n",
            "epoch 61 | loss: 1.10666 | train_mae: 0.04136 | valid_mae: 0.0647  |  0:00:49s\n",
            "epoch 62 | loss: 1.04029 | train_mae: 0.04161 | valid_mae: 0.06203 |  0:00:50s\n",
            "epoch 63 | loss: 1.08524 | train_mae: 0.04708 | valid_mae: 0.06306 |  0:00:51s\n",
            "epoch 64 | loss: 0.99595 | train_mae: 0.04726 | valid_mae: 0.05232 |  0:00:51s\n",
            "epoch 65 | loss: 0.97698 | train_mae: 0.0574  | valid_mae: 0.05903 |  0:00:52s\n",
            "epoch 66 | loss: 1.0461  | train_mae: 0.04556 | valid_mae: 0.04721 |  0:00:53s\n",
            "epoch 67 | loss: 1.08101 | train_mae: 0.04231 | valid_mae: 0.05091 |  0:00:53s\n",
            "epoch 68 | loss: 1.01858 | train_mae: 0.05199 | valid_mae: 0.04936 |  0:00:54s\n",
            "epoch 69 | loss: 1.03397 | train_mae: 0.0379  | valid_mae: 0.04361 |  0:00:54s\n",
            "epoch 70 | loss: 1.05218 | train_mae: 0.03864 | valid_mae: 0.04323 |  0:00:55s\n",
            "epoch 71 | loss: 0.96085 | train_mae: 0.04021 | valid_mae: 0.04482 |  0:00:56s\n",
            "epoch 72 | loss: 1.06693 | train_mae: 0.03703 | valid_mae: 0.04532 |  0:00:56s\n",
            "epoch 73 | loss: 0.9597  | train_mae: 0.03451 | valid_mae: 0.04435 |  0:00:57s\n",
            "epoch 74 | loss: 0.93503 | train_mae: 0.03935 | valid_mae: 0.04815 |  0:00:58s\n",
            "epoch 75 | loss: 0.93388 | train_mae: 0.03567 | valid_mae: 0.04153 |  0:00:58s\n",
            "epoch 76 | loss: 0.95766 | train_mae: 0.03648 | valid_mae: 0.04216 |  0:00:59s\n",
            "epoch 77 | loss: 0.94518 | train_mae: 0.03588 | valid_mae: 0.04168 |  0:01:00s\n",
            "epoch 78 | loss: 0.93828 | train_mae: 0.03523 | valid_mae: 0.04125 |  0:01:00s\n",
            "epoch 79 | loss: 0.94522 | train_mae: 0.03458 | valid_mae: 0.04046 |  0:01:01s\n",
            "epoch 80 | loss: 0.82768 | train_mae: 0.03455 | valid_mae: 0.03935 |  0:01:02s\n",
            "epoch 81 | loss: 0.90707 | train_mae: 0.03636 | valid_mae: 0.03967 |  0:01:03s\n",
            "epoch 82 | loss: 0.94525 | train_mae: 0.0348  | valid_mae: 0.03768 |  0:01:04s\n",
            "epoch 83 | loss: 0.90372 | train_mae: 0.03544 | valid_mae: 0.03978 |  0:01:04s\n",
            "epoch 84 | loss: 0.90753 | train_mae: 0.03424 | valid_mae: 0.03829 |  0:01:05s\n",
            "epoch 85 | loss: 0.95557 | train_mae: 0.03473 | valid_mae: 0.03881 |  0:01:05s\n",
            "epoch 86 | loss: 0.89226 | train_mae: 0.03363 | valid_mae: 0.03884 |  0:01:06s\n",
            "epoch 87 | loss: 0.95117 | train_mae: 0.03444 | valid_mae: 0.0381  |  0:01:07s\n",
            "epoch 88 | loss: 0.86277 | train_mae: 0.03408 | valid_mae: 0.03795 |  0:01:07s\n",
            "epoch 89 | loss: 0.8556  | train_mae: 0.03196 | valid_mae: 0.0365  |  0:01:08s\n",
            "epoch 90 | loss: 0.86882 | train_mae: 0.03145 | valid_mae: 0.03662 |  0:01:09s\n",
            "epoch 91 | loss: 0.87919 | train_mae: 0.03364 | valid_mae: 0.03757 |  0:01:09s\n",
            "epoch 92 | loss: 0.93971 | train_mae: 0.0323  | valid_mae: 0.03624 |  0:01:10s\n",
            "epoch 93 | loss: 0.904   | train_mae: 0.03251 | valid_mae: 0.0363  |  0:01:11s\n",
            "epoch 94 | loss: 0.8909  | train_mae: 0.03319 | valid_mae: 0.03787 |  0:01:11s\n",
            "epoch 95 | loss: 0.81513 | train_mae: 0.03233 | valid_mae: 0.0374  |  0:01:12s\n",
            "epoch 96 | loss: 0.83116 | train_mae: 0.03336 | valid_mae: 0.03778 |  0:01:12s\n",
            "epoch 97 | loss: 0.81755 | train_mae: 0.03041 | valid_mae: 0.03554 |  0:01:13s\n",
            "epoch 98 | loss: 0.81098 | train_mae: 0.03259 | valid_mae: 0.03677 |  0:01:14s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-09-05 01:07:55,922] Trial 6 finished with value: 0.8286593317985534 and parameters: {'n_d': 29, 'n_a': 22, 'n_steps': 3, 'gamma': 1.0914655943540263, 'lambda_sparse': 0.000293379507210615, 'batch_size': 256, 'mask_type': 'sparsemax', 'emb': 8, 'momentum': 0.7421249798770542, 'learning_rate': 0.000890795793142868, 'weight_decay': 3.335440542460507e-05, 'scheduler_gamma': 0.9544262382899281, 'step_size': 8, 'virtual_batch_size': 32, 'optimizer_type': 'rmsprop', 'p': 0.1878584177648014}. Best is trial 6 with value: 0.8286593317985534.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 99 | loss: 0.82866 | train_mae: 0.02995 | valid_mae: 0.03765 |  0:01:15s\n",
            "Stop training because you reached max_epochs = 100 with best_epoch = 97 and best_valid_mae = 0.03554\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 870.42612| train_mae: 18.2956 | valid_mae: 19.19712|  0:00:00s\n",
            "epoch 1  | loss: 510.69359| train_mae: 6.75912 | valid_mae: 5.8878  |  0:00:01s\n",
            "epoch 2  | loss: 452.63261| train_mae: 3.7679  | valid_mae: 3.89659 |  0:00:02s\n",
            "epoch 3  | loss: 568.27393| train_mae: 2.09629 | valid_mae: 2.0334  |  0:00:03s\n",
            "epoch 4  | loss: 937.94355| train_mae: 1.71664 | valid_mae: 1.67417 |  0:00:03s\n",
            "epoch 5  | loss: 446.84781| train_mae: 1.42225 | valid_mae: 1.64735 |  0:00:04s\n",
            "epoch 6  | loss: 546.98413| train_mae: 1.25378 | valid_mae: 1.52529 |  0:00:05s\n",
            "epoch 7  | loss: 538.01695| train_mae: 1.27377 | valid_mae: 1.78143 |  0:00:06s\n",
            "epoch 8  | loss: 645.01199| train_mae: 1.31448 | valid_mae: 1.6105  |  0:00:06s\n",
            "epoch 9  | loss: 549.1875| train_mae: 1.30483 | valid_mae: 1.67208 |  0:00:07s\n",
            "epoch 10 | loss: 551.66564| train_mae: 1.20579 | valid_mae: 1.64224 |  0:00:08s\n",
            "epoch 11 | loss: 516.17104| train_mae: 1.36049 | valid_mae: 2.81473 |  0:00:09s\n",
            "epoch 12 | loss: 733.45988| train_mae: 1.26518 | valid_mae: 3.13788 |  0:00:10s\n",
            "epoch 13 | loss: 502.22031| train_mae: 1.41294 | valid_mae: 3.29449 |  0:00:11s\n",
            "epoch 14 | loss: 538.27925| train_mae: 1.51271 | valid_mae: 1.8116  |  0:00:12s\n",
            "epoch 15 | loss: 784.53098| train_mae: 1.70265 | valid_mae: 2.13249 |  0:00:12s\n",
            "epoch 16 | loss: 490.78495| train_mae: 1.5329  | valid_mae: 2.27487 |  0:00:13s\n",
            "epoch 17 | loss: 558.84032| train_mae: 1.62955 | valid_mae: 2.12266 |  0:00:14s\n",
            "epoch 18 | loss: 592.29275| train_mae: 1.40832 | valid_mae: 2.22123 |  0:00:15s\n",
            "epoch 19 | loss: 496.91533| train_mae: 1.54845 | valid_mae: 2.33759 |  0:00:15s\n",
            "epoch 20 | loss: 644.90945| train_mae: 1.48455 | valid_mae: 2.30833 |  0:00:16s\n",
            "epoch 21 | loss: 480.07542| train_mae: 1.48703 | valid_mae: 2.40425 |  0:00:17s\n",
            "epoch 22 | loss: 350.41895| train_mae: 1.44737 | valid_mae: 2.30107 |  0:00:18s\n",
            "epoch 23 | loss: 483.02379| train_mae: 1.39212 | valid_mae: 2.27809 |  0:00:18s\n",
            "epoch 24 | loss: 491.07089| train_mae: 1.37282 | valid_mae: 2.4037  |  0:00:19s\n",
            "epoch 25 | loss: 866.06955| train_mae: 1.31242 | valid_mae: 2.36177 |  0:00:20s\n",
            "epoch 26 | loss: 462.88516| train_mae: 1.22623 | valid_mae: 2.4274  |  0:00:21s\n",
            "epoch 27 | loss: 409.77744| train_mae: 1.21653 | valid_mae: 2.29453 |  0:00:22s\n",
            "epoch 28 | loss: 542.9688| train_mae: 1.15462 | valid_mae: 2.37572 |  0:00:23s\n",
            "epoch 29 | loss: 592.17701| train_mae: 1.10036 | valid_mae: 2.13719 |  0:00:24s\n",
            "epoch 30 | loss: 454.19283| train_mae: 1.07328 | valid_mae: 1.88217 |  0:00:25s\n",
            "epoch 31 | loss: 423.77474| train_mae: 1.16933 | valid_mae: 1.89317 |  0:00:25s\n",
            "epoch 32 | loss: 466.7206| train_mae: 1.08036 | valid_mae: 1.72918 |  0:00:26s\n",
            "epoch 33 | loss: 405.28693| train_mae: 1.02712 | valid_mae: 1.91265 |  0:00:27s\n",
            "epoch 34 | loss: 432.7008| train_mae: 1.00232 | valid_mae: 1.8758  |  0:00:28s\n",
            "epoch 35 | loss: 442.81106| train_mae: 0.96447 | valid_mae: 1.8799  |  0:00:28s\n",
            "epoch 36 | loss: 461.90177| train_mae: 0.951   | valid_mae: 1.77798 |  0:00:29s\n",
            "epoch 37 | loss: 922.1213| train_mae: 0.99191 | valid_mae: 1.69418 |  0:00:30s\n",
            "epoch 38 | loss: 533.83973| train_mae: 0.9747  | valid_mae: 1.74129 |  0:00:31s\n",
            "epoch 39 | loss: 452.80636| train_mae: 0.91314 | valid_mae: 1.7093  |  0:00:31s\n",
            "epoch 40 | loss: 457.99538| train_mae: 0.88956 | valid_mae: 1.46481 |  0:00:32s\n",
            "epoch 41 | loss: 550.37117| train_mae: 0.86129 | valid_mae: 1.20365 |  0:00:33s\n",
            "epoch 42 | loss: 509.14159| train_mae: 0.8105  | valid_mae: 0.87543 |  0:00:34s\n",
            "epoch 43 | loss: 464.25428| train_mae: 0.75661 | valid_mae: 1.2261  |  0:00:35s\n",
            "epoch 44 | loss: 855.3851| train_mae: 0.6802  | valid_mae: 0.77379 |  0:00:36s\n",
            "epoch 45 | loss: 380.16704| train_mae: 0.65553 | valid_mae: 0.65599 |  0:00:37s\n",
            "epoch 46 | loss: 327.77123| train_mae: 0.66627 | valid_mae: 0.73195 |  0:00:38s\n",
            "epoch 47 | loss: 417.22375| train_mae: 0.68546 | valid_mae: 0.78127 |  0:00:38s\n",
            "epoch 48 | loss: 426.47165| train_mae: 0.61984 | valid_mae: 1.05244 |  0:00:39s\n",
            "epoch 49 | loss: 554.45696| train_mae: 0.62135 | valid_mae: 1.03774 |  0:00:40s\n",
            "epoch 50 | loss: 466.1421| train_mae: 0.58414 | valid_mae: 0.80921 |  0:00:41s\n",
            "epoch 51 | loss: 380.08311| train_mae: 0.59131 | valid_mae: 0.84726 |  0:00:41s\n",
            "epoch 52 | loss: 451.32756| train_mae: 0.6028  | valid_mae: 0.58823 |  0:00:42s\n",
            "epoch 53 | loss: 776.96758| train_mae: 0.56629 | valid_mae: 0.7508  |  0:00:43s\n",
            "epoch 54 | loss: 350.59727| train_mae: 0.53745 | valid_mae: 1.1074  |  0:00:44s\n",
            "epoch 55 | loss: 478.73313| train_mae: 0.60993 | valid_mae: 1.04125 |  0:00:44s\n",
            "epoch 56 | loss: 503.35095| train_mae: 0.59485 | valid_mae: 1.07795 |  0:00:45s\n",
            "epoch 57 | loss: 426.22964| train_mae: 0.57066 | valid_mae: 1.12751 |  0:00:46s\n",
            "epoch 58 | loss: 324.80779| train_mae: 0.53892 | valid_mae: 1.06985 |  0:00:47s\n",
            "epoch 59 | loss: 470.20197| train_mae: 0.64153 | valid_mae: 0.72344 |  0:00:48s\n",
            "epoch 60 | loss: 453.98951| train_mae: 0.59086 | valid_mae: 0.61992 |  0:00:49s\n",
            "epoch 61 | loss: 341.19061| train_mae: 0.51752 | valid_mae: 0.70808 |  0:00:50s\n",
            "epoch 62 | loss: 482.42846| train_mae: 0.53874 | valid_mae: 0.73805 |  0:00:51s\n",
            "epoch 63 | loss: 439.80052| train_mae: 0.51526 | valid_mae: 0.80227 |  0:00:51s\n",
            "epoch 64 | loss: 346.14313| train_mae: 0.54034 | valid_mae: 0.69279 |  0:00:52s\n",
            "epoch 65 | loss: 462.88467| train_mae: 0.60767 | valid_mae: 0.67707 |  0:00:53s\n",
            "epoch 66 | loss: 302.04621| train_mae: 0.59355 | valid_mae: 0.54733 |  0:00:54s\n",
            "epoch 67 | loss: 654.97661| train_mae: 0.53114 | valid_mae: 0.68613 |  0:00:54s\n",
            "epoch 68 | loss: 384.30066| train_mae: 0.49601 | valid_mae: 0.70241 |  0:00:55s\n",
            "epoch 69 | loss: 424.19657| train_mae: 0.49815 | valid_mae: 0.48297 |  0:00:56s\n",
            "epoch 70 | loss: 297.13479| train_mae: 0.55705 | valid_mae: 0.52024 |  0:00:57s\n",
            "epoch 71 | loss: 273.36794| train_mae: 0.63497 | valid_mae: 0.5251  |  0:00:58s\n",
            "epoch 72 | loss: 524.19421| train_mae: 0.51843 | valid_mae: 0.58519 |  0:00:59s\n",
            "epoch 73 | loss: 299.65354| train_mae: 0.51094 | valid_mae: 0.66313 |  0:01:00s\n",
            "epoch 74 | loss: 398.42334| train_mae: 0.49792 | valid_mae: 0.56075 |  0:01:01s\n",
            "epoch 75 | loss: 339.53307| train_mae: 0.48061 | valid_mae: 0.48088 |  0:01:02s\n",
            "epoch 76 | loss: 636.93179| train_mae: 0.47719 | valid_mae: 0.48329 |  0:01:03s\n",
            "epoch 77 | loss: 681.62528| train_mae: 0.59119 | valid_mae: 0.54983 |  0:01:04s\n",
            "epoch 78 | loss: 311.35545| train_mae: 0.57676 | valid_mae: 0.51625 |  0:01:04s\n",
            "epoch 79 | loss: 331.86393| train_mae: 0.47501 | valid_mae: 0.47747 |  0:01:05s\n",
            "epoch 80 | loss: 370.34882| train_mae: 0.50237 | valid_mae: 0.45043 |  0:01:06s\n",
            "epoch 81 | loss: 1242.32499| train_mae: 0.51302 | valid_mae: 0.78864 |  0:01:07s\n",
            "epoch 82 | loss: 271.08774| train_mae: 0.48934 | valid_mae: 0.70549 |  0:01:08s\n",
            "epoch 83 | loss: 280.41298| train_mae: 0.47884 | valid_mae: 0.8391  |  0:01:09s\n",
            "epoch 84 | loss: 463.13987| train_mae: 0.48412 | valid_mae: 0.82792 |  0:01:09s\n",
            "epoch 85 | loss: 316.61827| train_mae: 0.48119 | valid_mae: 0.75824 |  0:01:10s\n",
            "epoch 86 | loss: 395.96681| train_mae: 0.49048 | valid_mae: 0.42013 |  0:01:11s\n",
            "epoch 87 | loss: 366.57891| train_mae: 0.48315 | valid_mae: 0.42465 |  0:01:12s\n",
            "epoch 88 | loss: 327.85098| train_mae: 0.55567 | valid_mae: 0.61628 |  0:01:13s\n",
            "epoch 89 | loss: 602.63015| train_mae: 0.53611 | valid_mae: 0.55394 |  0:01:14s\n",
            "epoch 90 | loss: 382.23645| train_mae: 0.54945 | valid_mae: 0.48686 |  0:01:15s\n",
            "epoch 91 | loss: 541.49324| train_mae: 0.57865 | valid_mae: 0.59976 |  0:01:16s\n",
            "epoch 92 | loss: 378.44582| train_mae: 0.54862 | valid_mae: 0.48913 |  0:01:16s\n",
            "epoch 93 | loss: 381.18582| train_mae: 0.52631 | valid_mae: 0.73139 |  0:01:17s\n",
            "epoch 94 | loss: 372.98989| train_mae: 0.56091 | valid_mae: 0.50862 |  0:01:18s\n",
            "epoch 95 | loss: 263.87571| train_mae: 0.47417 | valid_mae: 0.49362 |  0:01:19s\n",
            "epoch 96 | loss: 489.6683| train_mae: 0.45129 | valid_mae: 0.36203 |  0:01:20s\n",
            "epoch 97 | loss: 684.48022| train_mae: 0.47758 | valid_mae: 0.96886 |  0:01:20s\n",
            "epoch 98 | loss: 522.38933| train_mae: 0.43201 | valid_mae: 0.74405 |  0:01:21s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-09-05 01:09:21,736] Trial 7 finished with value: 295.6062957763672 and parameters: {'n_d': 21, 'n_a': 22, 'n_steps': 4, 'gamma': 1.6573322436562603, 'lambda_sparse': 1.3272303102770108e-05, 'batch_size': 128, 'mask_type': 'entmax', 'emb': 5, 'momentum': 0.6666733081804214, 'learning_rate': 0.0001796862397250195, 'weight_decay': 1.7891350192962193e-06, 'scheduler_gamma': 0.9609154337169629, 'step_size': 8, 'virtual_batch_size': 64, 'optimizer_type': 'adamw', 'p': 0.24884785494113815}. Best is trial 6 with value: 0.8286593317985534.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 99 | loss: 295.6063| train_mae: 0.47877 | valid_mae: 0.74365 |  0:01:22s\n",
            "Stop training because you reached max_epochs = 100 with best_epoch = 96 and best_valid_mae = 0.36203\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 301.84535| train_mae: 20.7309 | valid_mae: 22.90903|  0:00:00s\n",
            "epoch 1  | loss: 130.78978| train_mae: 6.22152 | valid_mae: 6.41486 |  0:00:01s\n",
            "epoch 2  | loss: 10.55352| train_mae: 1.08863 | valid_mae: 1.03386 |  0:00:02s\n",
            "epoch 3  | loss: 2.89107 | train_mae: 0.42905 | valid_mae: 0.47112 |  0:00:03s\n",
            "epoch 4  | loss: 2.11554 | train_mae: 0.53821 | valid_mae: 0.58249 |  0:00:04s\n",
            "epoch 5  | loss: 2.81081 | train_mae: 0.64457 | valid_mae: 0.73951 |  0:00:05s\n",
            "epoch 6  | loss: 1.27613 | train_mae: 0.2773  | valid_mae: 0.38215 |  0:00:05s\n",
            "epoch 7  | loss: 1.19365 | train_mae: 0.16954 | valid_mae: 0.23272 |  0:00:06s\n",
            "epoch 8  | loss: 1.09008 | train_mae: 0.06229 | valid_mae: 0.07352 |  0:00:07s\n",
            "epoch 9  | loss: 1.00136 | train_mae: 0.05791 | valid_mae: 0.0717  |  0:00:08s\n",
            "epoch 10 | loss: 1.2974  | train_mae: 0.05375 | valid_mae: 0.06469 |  0:00:08s\n",
            "epoch 11 | loss: 1.15304 | train_mae: 0.05098 | valid_mae: 0.05538 |  0:00:09s\n",
            "epoch 12 | loss: 0.95045 | train_mae: 0.06043 | valid_mae: 0.05999 |  0:00:10s\n",
            "epoch 13 | loss: 0.91781 | train_mae: 0.06177 | valid_mae: 0.06408 |  0:00:10s\n",
            "epoch 14 | loss: 0.94951 | train_mae: 0.06453 | valid_mae: 0.07013 |  0:00:11s\n",
            "epoch 15 | loss: 0.81486 | train_mae: 0.05372 | valid_mae: 0.05664 |  0:00:12s\n",
            "epoch 16 | loss: 0.89196 | train_mae: 0.04393 | valid_mae: 0.04565 |  0:00:13s\n",
            "epoch 17 | loss: 0.9109  | train_mae: 0.08906 | valid_mae: 0.10537 |  0:00:14s\n",
            "epoch 18 | loss: 0.70091 | train_mae: 0.0563  | valid_mae: 0.06534 |  0:00:15s\n",
            "epoch 19 | loss: 0.71684 | train_mae: 0.03553 | valid_mae: 0.04531 |  0:00:16s\n",
            "epoch 20 | loss: 0.681   | train_mae: 0.029   | valid_mae: 0.03442 |  0:00:16s\n",
            "epoch 21 | loss: 0.84396 | train_mae: 0.0345  | valid_mae: 0.05044 |  0:00:17s\n",
            "epoch 22 | loss: 0.57074 | train_mae: 0.02979 | valid_mae: 0.03535 |  0:00:18s\n",
            "epoch 23 | loss: 0.61077 | train_mae: 0.03236 | valid_mae: 0.04406 |  0:00:19s\n",
            "epoch 24 | loss: 0.96418 | train_mae: 0.03303 | valid_mae: 0.0481  |  0:00:19s\n",
            "epoch 25 | loss: 0.438   | train_mae: 0.02692 | valid_mae: 0.03607 |  0:00:20s\n",
            "epoch 26 | loss: 0.42772 | train_mae: 0.02442 | valid_mae: 0.03559 |  0:00:21s\n",
            "epoch 27 | loss: 0.46609 | train_mae: 0.02086 | valid_mae: 0.03081 |  0:00:21s\n",
            "epoch 28 | loss: 0.52834 | train_mae: 0.02138 | valid_mae: 0.03341 |  0:00:22s\n",
            "epoch 29 | loss: 0.52509 | train_mae: 0.0216  | valid_mae: 0.02888 |  0:00:23s\n",
            "epoch 30 | loss: 0.45252 | train_mae: 0.02325 | valid_mae: 0.03149 |  0:00:24s\n",
            "epoch 31 | loss: 0.39385 | train_mae: 0.02248 | valid_mae: 0.02985 |  0:00:24s\n",
            "epoch 32 | loss: 0.46952 | train_mae: 0.02439 | valid_mae: 0.03627 |  0:00:25s\n",
            "epoch 33 | loss: 0.39079 | train_mae: 0.02191 | valid_mae: 0.03493 |  0:00:26s\n",
            "epoch 34 | loss: 0.42095 | train_mae: 0.02257 | valid_mae: 0.03595 |  0:00:27s\n",
            "epoch 35 | loss: 0.48958 | train_mae: 0.0276  | valid_mae: 0.04502 |  0:00:28s\n",
            "epoch 36 | loss: 0.35761 | train_mae: 0.02232 | valid_mae: 0.04216 |  0:00:29s\n",
            "epoch 37 | loss: 0.34217 | train_mae: 0.01868 | valid_mae: 0.03658 |  0:00:29s\n",
            "epoch 38 | loss: 0.35107 | train_mae: 0.0183  | valid_mae: 0.03038 |  0:00:30s\n",
            "epoch 39 | loss: 0.481   | train_mae: 0.02382 | valid_mae: 0.03472 |  0:00:31s\n",
            "epoch 40 | loss: 0.33685 | train_mae: 0.01851 | valid_mae: 0.03376 |  0:00:32s\n",
            "epoch 41 | loss: 0.34273 | train_mae: 0.01471 | valid_mae: 0.02955 |  0:00:32s\n",
            "epoch 42 | loss: 0.39544 | train_mae: 0.01331 | valid_mae: 0.0285  |  0:00:33s\n",
            "epoch 43 | loss: 0.27264 | train_mae: 0.01611 | valid_mae: 0.02988 |  0:00:34s\n",
            "epoch 44 | loss: 0.34634 | train_mae: 0.0157  | valid_mae: 0.02983 |  0:00:34s\n",
            "epoch 45 | loss: 0.3641  | train_mae: 0.01528 | valid_mae: 0.02983 |  0:00:35s\n",
            "epoch 46 | loss: 0.43092 | train_mae: 0.01476 | valid_mae: 0.03426 |  0:00:36s\n",
            "epoch 47 | loss: 0.30996 | train_mae: 0.01502 | valid_mae: 0.02962 |  0:00:37s\n",
            "epoch 48 | loss: 0.30014 | train_mae: 0.01318 | valid_mae: 0.03067 |  0:00:37s\n",
            "epoch 49 | loss: 0.34838 | train_mae: 0.01358 | valid_mae: 0.03166 |  0:00:38s\n",
            "epoch 50 | loss: 0.28732 | train_mae: 0.01495 | valid_mae: 0.03091 |  0:00:39s\n",
            "epoch 51 | loss: 0.31452 | train_mae: 0.01566 | valid_mae: 0.03179 |  0:00:40s\n",
            "epoch 52 | loss: 0.22075 | train_mae: 0.01257 | valid_mae: 0.02998 |  0:00:41s\n",
            "epoch 53 | loss: 0.21767 | train_mae: 0.01333 | valid_mae: 0.03127 |  0:00:42s\n",
            "epoch 54 | loss: 0.39944 | train_mae: 0.01363 | valid_mae: 0.03114 |  0:00:42s\n",
            "epoch 55 | loss: 0.3759  | train_mae: 0.01456 | valid_mae: 0.03057 |  0:00:43s\n",
            "epoch 56 | loss: 0.30293 | train_mae: 0.01783 | valid_mae: 0.03383 |  0:00:44s\n",
            "epoch 57 | loss: 0.33696 | train_mae: 0.0143  | valid_mae: 0.03216 |  0:00:45s\n",
            "epoch 58 | loss: 0.32179 | train_mae: 0.01508 | valid_mae: 0.03265 |  0:00:45s\n",
            "epoch 59 | loss: 0.3037  | train_mae: 0.01428 | valid_mae: 0.03146 |  0:00:46s\n",
            "epoch 60 | loss: 0.40641 | train_mae: 0.01443 | valid_mae: 0.03241 |  0:00:47s\n",
            "epoch 61 | loss: 0.26665 | train_mae: 0.01381 | valid_mae: 0.03101 |  0:00:47s\n",
            "epoch 62 | loss: 0.39866 | train_mae: 0.01585 | valid_mae: 0.03018 |  0:00:48s\n",
            "epoch 63 | loss: 0.28946 | train_mae: 0.01484 | valid_mae: 0.03082 |  0:00:49s\n",
            "epoch 64 | loss: 0.29095 | train_mae: 0.01583 | valid_mae: 0.03161 |  0:00:50s\n",
            "epoch 65 | loss: 0.3187  | train_mae: 0.01459 | valid_mae: 0.03204 |  0:00:50s\n",
            "epoch 66 | loss: 0.45254 | train_mae: 0.01319 | valid_mae: 0.031   |  0:00:51s\n",
            "epoch 67 | loss: 0.36039 | train_mae: 0.01438 | valid_mae: 0.03025 |  0:00:52s\n",
            "epoch 68 | loss: 0.26044 | train_mae: 0.01344 | valid_mae: 0.02964 |  0:00:53s\n",
            "epoch 69 | loss: 0.29425 | train_mae: 0.01191 | valid_mae: 0.0292  |  0:00:54s\n",
            "epoch 70 | loss: 0.22864 | train_mae: 0.01216 | valid_mae: 0.0292  |  0:00:55s\n",
            "epoch 71 | loss: 0.23719 | train_mae: 0.0123  | valid_mae: 0.02875 |  0:00:55s\n",
            "epoch 72 | loss: 0.30597 | train_mae: 0.01287 | valid_mae: 0.02785 |  0:00:56s\n",
            "epoch 73 | loss: 0.21042 | train_mae: 0.0145  | valid_mae: 0.02977 |  0:00:57s\n",
            "epoch 74 | loss: 0.38989 | train_mae: 0.01484 | valid_mae: 0.02911 |  0:00:58s\n",
            "epoch 75 | loss: 0.53572 | train_mae: 0.01217 | valid_mae: 0.02973 |  0:00:58s\n",
            "epoch 76 | loss: 0.32527 | train_mae: 0.01222 | valid_mae: 0.02709 |  0:00:59s\n",
            "epoch 77 | loss: 0.25052 | train_mae: 0.01314 | valid_mae: 0.02713 |  0:01:00s\n",
            "epoch 78 | loss: 0.33437 | train_mae: 0.01343 | valid_mae: 0.02732 |  0:01:00s\n",
            "epoch 79 | loss: 0.22223 | train_mae: 0.01298 | valid_mae: 0.02865 |  0:01:01s\n",
            "epoch 80 | loss: 0.18785 | train_mae: 0.0127  | valid_mae: 0.0275  |  0:01:02s\n",
            "epoch 81 | loss: 0.13864 | train_mae: 0.01267 | valid_mae: 0.0267  |  0:01:03s\n",
            "epoch 82 | loss: 0.1809  | train_mae: 0.01264 | valid_mae: 0.02516 |  0:01:03s\n",
            "epoch 83 | loss: 0.21107 | train_mae: 0.01197 | valid_mae: 0.02731 |  0:01:04s\n",
            "epoch 84 | loss: 0.13524 | train_mae: 0.01069 | valid_mae: 0.02839 |  0:01:05s\n",
            "epoch 85 | loss: 0.14332 | train_mae: 0.01162 | valid_mae: 0.02936 |  0:01:06s\n",
            "epoch 86 | loss: 0.1584  | train_mae: 0.0104  | valid_mae: 0.03056 |  0:01:07s\n",
            "epoch 87 | loss: 0.20968 | train_mae: 0.00959 | valid_mae: 0.0288  |  0:01:08s\n",
            "epoch 88 | loss: 0.20129 | train_mae: 0.00997 | valid_mae: 0.02816 |  0:01:09s\n",
            "epoch 89 | loss: 0.15609 | train_mae: 0.0119  | valid_mae: 0.02823 |  0:01:09s\n",
            "epoch 90 | loss: 0.30878 | train_mae: 0.01118 | valid_mae: 0.02827 |  0:01:10s\n",
            "epoch 91 | loss: 0.26758 | train_mae: 0.01059 | valid_mae: 0.0279  |  0:01:11s\n",
            "epoch 92 | loss: 0.19686 | train_mae: 0.01205 | valid_mae: 0.02831 |  0:01:11s\n",
            "epoch 93 | loss: 0.22994 | train_mae: 0.00989 | valid_mae: 0.03048 |  0:01:12s\n",
            "epoch 94 | loss: 0.26549 | train_mae: 0.0122  | valid_mae: 0.03192 |  0:01:13s\n",
            "epoch 95 | loss: 0.25644 | train_mae: 0.01655 | valid_mae: 0.03372 |  0:01:14s\n",
            "epoch 96 | loss: 0.24206 | train_mae: 0.01304 | valid_mae: 0.03182 |  0:01:14s\n",
            "epoch 97 | loss: 0.2055  | train_mae: 0.01074 | valid_mae: 0.02934 |  0:01:15s\n",
            "epoch 98 | loss: 0.20613 | train_mae: 0.01131 | valid_mae: 0.03023 |  0:01:16s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-09-05 01:10:41,581] Trial 8 finished with value: 0.17338448464870454 and parameters: {'n_d': 22, 'n_a': 27, 'n_steps': 3, 'gamma': 1.9430936802796075, 'lambda_sparse': 0.0001018153941786177, 'batch_size': 128, 'mask_type': 'sparsemax', 'emb': 21, 'momentum': 0.8666925907830847, 'learning_rate': 0.07664032683446262, 'weight_decay': 1.2803645806934816e-05, 'scheduler_gamma': 0.9887919389979766, 'step_size': 15, 'virtual_batch_size': 64, 'optimizer_type': 'rmsprop', 'p': 0.04097542417160189}. Best is trial 8 with value: 0.17338448464870454.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 99 | loss: 0.17338 | train_mae: 0.00999 | valid_mae: 0.03035 |  0:01:16s\n",
            "Stop training because you reached max_epochs = 100 with best_epoch = 82 and best_valid_mae = 0.02516\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 170.3207| train_mae: 1.67952 | valid_mae: 1.64251 |  0:00:01s\n",
            "epoch 1  | loss: 105.37569| train_mae: 1.17392 | valid_mae: 1.19496 |  0:00:02s\n",
            "epoch 2  | loss: 152.85537| train_mae: 1.24249 | valid_mae: 1.21251 |  0:00:03s\n",
            "epoch 3  | loss: 72.76108| train_mae: 0.88003 | valid_mae: 0.77078 |  0:00:04s\n",
            "epoch 4  | loss: 76.68399| train_mae: 0.78692 | valid_mae: 0.6903  |  0:00:05s\n",
            "epoch 5  | loss: 50.73853| train_mae: 0.96885 | valid_mae: 0.70678 |  0:00:06s\n",
            "epoch 6  | loss: 30.45313| train_mae: 0.73177 | valid_mae: 0.61506 |  0:00:07s\n",
            "epoch 7  | loss: 25.00281| train_mae: 0.72368 | valid_mae: 0.68801 |  0:00:08s\n",
            "epoch 8  | loss: 35.27752| train_mae: 0.69723 | valid_mae: 0.73312 |  0:00:09s\n",
            "epoch 9  | loss: 18.72653| train_mae: 0.78809 | valid_mae: 0.80033 |  0:00:10s\n",
            "epoch 10 | loss: 15.69623| train_mae: 0.88852 | valid_mae: 0.85789 |  0:00:11s\n",
            "epoch 11 | loss: 14.28177| train_mae: 0.96791 | valid_mae: 0.87747 |  0:00:13s\n",
            "epoch 12 | loss: 21.00469| train_mae: 0.47662 | valid_mae: 0.48664 |  0:00:14s\n",
            "epoch 13 | loss: 8.38291 | train_mae: 0.39095 | valid_mae: 0.34159 |  0:00:15s\n",
            "epoch 14 | loss: 8.39795 | train_mae: 0.19786 | valid_mae: 0.21457 |  0:00:16s\n",
            "epoch 15 | loss: 4.59167 | train_mae: 0.13432 | valid_mae: 0.1718  |  0:00:17s\n",
            "epoch 16 | loss: 3.51758 | train_mae: 0.10913 | valid_mae: 0.15319 |  0:00:18s\n",
            "epoch 17 | loss: 3.10134 | train_mae: 0.08939 | valid_mae: 0.12238 |  0:00:19s\n",
            "epoch 18 | loss: 3.21002 | train_mae: 0.08172 | valid_mae: 0.12023 |  0:00:20s\n",
            "epoch 19 | loss: 4.59358 | train_mae: 0.06041 | valid_mae: 0.06388 |  0:00:21s\n",
            "epoch 20 | loss: 1.97222 | train_mae: 0.05284 | valid_mae: 0.05926 |  0:00:22s\n",
            "epoch 21 | loss: 1.35523 | train_mae: 0.04341 | valid_mae: 0.05973 |  0:00:23s\n",
            "epoch 22 | loss: 1.28039 | train_mae: 0.04646 | valid_mae: 0.06895 |  0:00:24s\n",
            "epoch 23 | loss: 1.20242 | train_mae: 0.03783 | valid_mae: 0.0485  |  0:00:25s\n",
            "epoch 24 | loss: 2.16123 | train_mae: 0.03198 | valid_mae: 0.03548 |  0:00:27s\n",
            "epoch 25 | loss: 1.35543 | train_mae: 0.03136 | valid_mae: 0.04061 |  0:00:28s\n",
            "epoch 26 | loss: 1.07288 | train_mae: 0.03838 | valid_mae: 0.05258 |  0:00:28s\n",
            "epoch 27 | loss: 1.08963 | train_mae: 0.03193 | valid_mae: 0.04281 |  0:00:29s\n",
            "epoch 28 | loss: 1.16361 | train_mae: 0.03313 | valid_mae: 0.03979 |  0:00:30s\n",
            "epoch 29 | loss: 1.10795 | train_mae: 0.03056 | valid_mae: 0.03832 |  0:00:31s\n",
            "epoch 30 | loss: 1.09208 | train_mae: 0.03811 | valid_mae: 0.05156 |  0:00:32s\n",
            "epoch 31 | loss: 1.11262 | train_mae: 0.03134 | valid_mae: 0.04095 |  0:00:33s\n",
            "epoch 32 | loss: 1.48532 | train_mae: 0.0353  | valid_mae: 0.03869 |  0:00:34s\n",
            "epoch 33 | loss: 1.08452 | train_mae: 0.03719 | valid_mae: 0.04122 |  0:00:35s\n",
            "epoch 34 | loss: 1.18251 | train_mae: 0.03165 | valid_mae: 0.03571 |  0:00:36s\n",
            "epoch 35 | loss: 1.45108 | train_mae: 0.04916 | valid_mae: 0.04871 |  0:00:38s\n",
            "epoch 36 | loss: 1.14459 | train_mae: 0.03322 | valid_mae: 0.03708 |  0:00:39s\n",
            "epoch 37 | loss: 1.13069 | train_mae: 0.03387 | valid_mae: 0.03889 |  0:00:40s\n",
            "epoch 38 | loss: 1.07242 | train_mae: 0.03213 | valid_mae: 0.03583 |  0:00:41s\n",
            "epoch 39 | loss: 1.10029 | train_mae: 0.04091 | valid_mae: 0.04418 |  0:00:42s\n",
            "epoch 40 | loss: 1.26398 | train_mae: 0.03128 | valid_mae: 0.03446 |  0:00:43s\n",
            "epoch 41 | loss: 1.07889 | train_mae: 0.04367 | valid_mae: 0.04743 |  0:00:44s\n",
            "epoch 42 | loss: 1.06795 | train_mae: 0.02979 | valid_mae: 0.03295 |  0:00:45s\n",
            "epoch 43 | loss: 1.02523 | train_mae: 0.03713 | valid_mae: 0.04204 |  0:00:46s\n",
            "epoch 44 | loss: 1.16813 | train_mae: 0.04128 | valid_mae: 0.04672 |  0:00:47s\n",
            "epoch 45 | loss: 1.0668  | train_mae: 0.03989 | valid_mae: 0.04492 |  0:00:48s\n",
            "epoch 46 | loss: 1.07756 | train_mae: 0.0346  | valid_mae: 0.03814 |  0:00:49s\n",
            "epoch 47 | loss: 1.04354 | train_mae: 0.0361  | valid_mae: 0.03901 |  0:00:50s\n",
            "epoch 48 | loss: 1.07621 | train_mae: 0.0415  | valid_mae: 0.0446  |  0:00:52s\n",
            "epoch 49 | loss: 1.07462 | train_mae: 0.03676 | valid_mae: 0.0388  |  0:00:53s\n",
            "epoch 50 | loss: 1.06238 | train_mae: 0.04348 | valid_mae: 0.04594 |  0:00:54s\n",
            "epoch 51 | loss: 1.0425  | train_mae: 0.03303 | valid_mae: 0.03459 |  0:00:55s\n",
            "epoch 52 | loss: 1.07721 | train_mae: 0.0412  | valid_mae: 0.04436 |  0:00:56s\n",
            "epoch 53 | loss: 1.06809 | train_mae: 0.03895 | valid_mae: 0.04301 |  0:00:57s\n",
            "epoch 54 | loss: 1.08476 | train_mae: 0.03431 | valid_mae: 0.04061 |  0:00:58s\n",
            "epoch 55 | loss: 1.24261 | train_mae: 0.04078 | valid_mae: 0.04244 |  0:00:59s\n",
            "epoch 56 | loss: 1.06452 | train_mae: 0.03221 | valid_mae: 0.03688 |  0:01:00s\n",
            "epoch 57 | loss: 0.9961  | train_mae: 0.03917 | valid_mae: 0.04276 |  0:01:01s\n",
            "epoch 58 | loss: 0.98062 | train_mae: 0.03929 | valid_mae: 0.04252 |  0:01:02s\n",
            "epoch 59 | loss: 1.02144 | train_mae: 0.04017 | valid_mae: 0.04782 |  0:01:03s\n",
            "epoch 60 | loss: 1.05569 | train_mae: 0.03801 | valid_mae: 0.04255 |  0:01:04s\n",
            "epoch 61 | loss: 0.9922  | train_mae: 0.03662 | valid_mae: 0.03934 |  0:01:06s\n",
            "epoch 62 | loss: 1.02275 | train_mae: 0.0387  | valid_mae: 0.04305 |  0:01:07s\n",
            "epoch 63 | loss: 1.02427 | train_mae: 0.03687 | valid_mae: 0.04355 |  0:01:08s\n",
            "epoch 64 | loss: 1.08384 | train_mae: 0.03393 | valid_mae: 0.03821 |  0:01:09s\n",
            "epoch 65 | loss: 1.16724 | train_mae: 0.03817 | valid_mae: 0.04185 |  0:01:09s\n",
            "epoch 66 | loss: 1.0338  | train_mae: 0.03949 | valid_mae: 0.04357 |  0:01:10s\n",
            "epoch 67 | loss: 1.0664  | train_mae: 0.03737 | valid_mae: 0.04083 |  0:01:11s\n",
            "epoch 68 | loss: 1.00604 | train_mae: 0.03502 | valid_mae: 0.03917 |  0:01:12s\n",
            "epoch 69 | loss: 1.03485 | train_mae: 0.03498 | valid_mae: 0.03921 |  0:01:13s\n",
            "epoch 70 | loss: 1.01652 | train_mae: 0.03456 | valid_mae: 0.03911 |  0:01:15s\n",
            "epoch 71 | loss: 0.96961 | train_mae: 0.03858 | valid_mae: 0.04211 |  0:01:16s\n",
            "epoch 72 | loss: 1.02685 | train_mae: 0.03728 | valid_mae: 0.04219 |  0:01:17s\n",
            "epoch 73 | loss: 1.02375 | train_mae: 0.03497 | valid_mae: 0.0386  |  0:01:18s\n",
            "epoch 74 | loss: 0.98313 | train_mae: 0.03847 | valid_mae: 0.04103 |  0:01:19s\n",
            "epoch 75 | loss: 1.03187 | train_mae: 0.03671 | valid_mae: 0.04117 |  0:01:20s\n",
            "epoch 76 | loss: 0.96309 | train_mae: 0.03622 | valid_mae: 0.04067 |  0:01:21s\n",
            "epoch 77 | loss: 1.00952 | train_mae: 0.0346  | valid_mae: 0.03813 |  0:01:22s\n",
            "epoch 78 | loss: 1.03969 | train_mae: 0.03588 | valid_mae: 0.03848 |  0:01:23s\n",
            "epoch 79 | loss: 0.94461 | train_mae: 0.0378  | valid_mae: 0.04116 |  0:01:24s\n",
            "epoch 80 | loss: 0.97404 | train_mae: 0.03923 | valid_mae: 0.04332 |  0:01:25s\n",
            "epoch 81 | loss: 1.01499 | train_mae: 0.03831 | valid_mae: 0.04458 |  0:01:26s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-09-05 01:12:13,152] Trial 9 finished with value: 1.0298571109771728 and parameters: {'n_d': 17, 'n_a': 19, 'n_steps': 3, 'gamma': 1.765771269071631, 'lambda_sparse': 0.0009178215542077752, 'batch_size': 64, 'mask_type': 'sparsemax', 'emb': 14, 'momentum': 0.7224953320331812, 'learning_rate': 0.066726629784542, 'weight_decay': 1.0204317071180958e-06, 'scheduler_gamma': 0.9800477946200343, 'step_size': 11, 'virtual_batch_size': 32, 'optimizer_type': 'adamw', 'p': 0.12477354202914566}. Best is trial 8 with value: 0.17338448464870454.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 82 | loss: 1.02986 | train_mae: 0.03614 | valid_mae: 0.04182 |  0:01:27s\n",
            "\n",
            "Early stopping occurred at epoch 82 with best_epoch = 42 and best_valid_mae = 0.03295\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 296.77006| train_mae: 14.20568| valid_mae: 16.21036|  0:00:00s\n",
            "epoch 1  | loss: 153.75486| train_mae: 1.69966 | valid_mae: 1.97707 |  0:00:01s\n",
            "epoch 2  | loss: 59.9753 | train_mae: 1.25219 | valid_mae: 1.49456 |  0:00:02s\n",
            "epoch 3  | loss: 22.97031| train_mae: 0.20754 | valid_mae: 0.2514  |  0:00:03s\n",
            "epoch 4  | loss: 4.66358 | train_mae: 0.2476  | valid_mae: 0.22593 |  0:00:03s\n",
            "epoch 5  | loss: 2.64445 | train_mae: 0.1618  | valid_mae: 0.15225 |  0:00:04s\n",
            "epoch 6  | loss: 1.444   | train_mae: 0.11193 | valid_mae: 0.09545 |  0:00:05s\n",
            "epoch 7  | loss: 1.17657 | train_mae: 0.08978 | valid_mae: 0.08371 |  0:00:06s\n",
            "epoch 8  | loss: 0.98733 | train_mae: 0.07935 | valid_mae: 0.08053 |  0:00:07s\n",
            "epoch 9  | loss: 1.24287 | train_mae: 0.07115 | valid_mae: 0.07238 |  0:00:07s\n",
            "epoch 10 | loss: 1.05626 | train_mae: 0.07474 | valid_mae: 0.09186 |  0:00:08s\n",
            "epoch 11 | loss: 0.88906 | train_mae: 0.05853 | valid_mae: 0.06735 |  0:00:09s\n",
            "epoch 12 | loss: 0.9534  | train_mae: 0.06065 | valid_mae: 0.0644  |  0:00:10s\n",
            "epoch 13 | loss: 0.86117 | train_mae: 0.06283 | valid_mae: 0.06186 |  0:00:11s\n",
            "epoch 14 | loss: 0.78501 | train_mae: 0.05164 | valid_mae: 0.05077 |  0:00:12s\n",
            "epoch 15 | loss: 0.77245 | train_mae: 0.07466 | valid_mae: 0.08146 |  0:00:13s\n",
            "epoch 16 | loss: 0.96497 | train_mae: 0.06246 | valid_mae: 0.06917 |  0:00:14s\n",
            "epoch 17 | loss: 0.71894 | train_mae: 0.05768 | valid_mae: 0.06644 |  0:00:14s\n",
            "epoch 18 | loss: 0.63074 | train_mae: 0.11777 | valid_mae: 0.13394 |  0:00:15s\n",
            "epoch 19 | loss: 0.78408 | train_mae: 0.08964 | valid_mae: 0.09005 |  0:00:16s\n",
            "epoch 20 | loss: 0.70155 | train_mae: 0.1003  | valid_mae: 0.10588 |  0:00:17s\n",
            "epoch 21 | loss: 0.92356 | train_mae: 0.08614 | valid_mae: 0.09653 |  0:00:17s\n",
            "epoch 22 | loss: 0.55252 | train_mae: 0.06285 | valid_mae: 0.07871 |  0:00:18s\n",
            "epoch 23 | loss: 0.6405  | train_mae: 0.04988 | valid_mae: 0.06326 |  0:00:19s\n",
            "epoch 24 | loss: 0.52659 | train_mae: 0.04275 | valid_mae: 0.0552  |  0:00:20s\n",
            "epoch 25 | loss: 0.46306 | train_mae: 0.04191 | valid_mae: 0.04851 |  0:00:21s\n",
            "epoch 26 | loss: 0.49593 | train_mae: 0.04394 | valid_mae: 0.05059 |  0:00:22s\n",
            "epoch 27 | loss: 0.42379 | train_mae: 0.03575 | valid_mae: 0.04537 |  0:00:22s\n",
            "epoch 28 | loss: 0.52112 | train_mae: 0.03606 | valid_mae: 0.04567 |  0:00:23s\n",
            "epoch 29 | loss: 0.59931 | train_mae: 0.03503 | valid_mae: 0.04298 |  0:00:25s\n",
            "epoch 30 | loss: 0.46222 | train_mae: 0.02694 | valid_mae: 0.03443 |  0:00:26s\n",
            "epoch 31 | loss: 0.5264  | train_mae: 0.03033 | valid_mae: 0.0405  |  0:00:26s\n",
            "epoch 32 | loss: 0.47997 | train_mae: 0.02295 | valid_mae: 0.02995 |  0:00:27s\n",
            "epoch 33 | loss: 0.52424 | train_mae: 0.03203 | valid_mae: 0.04131 |  0:00:28s\n",
            "epoch 34 | loss: 0.80558 | train_mae: 0.03328 | valid_mae: 0.0424  |  0:00:29s\n",
            "epoch 35 | loss: 0.54069 | train_mae: 0.02557 | valid_mae: 0.03684 |  0:00:30s\n",
            "epoch 36 | loss: 0.41812 | train_mae: 0.02446 | valid_mae: 0.0343  |  0:00:30s\n",
            "epoch 37 | loss: 0.43571 | train_mae: 0.02469 | valid_mae: 0.03546 |  0:00:31s\n",
            "epoch 38 | loss: 0.35915 | train_mae: 0.02399 | valid_mae: 0.0386  |  0:00:32s\n",
            "epoch 39 | loss: 0.42388 | train_mae: 0.02266 | valid_mae: 0.03928 |  0:00:33s\n",
            "epoch 40 | loss: 0.55298 | train_mae: 0.02777 | valid_mae: 0.04557 |  0:00:33s\n",
            "epoch 41 | loss: 0.4777  | train_mae: 0.04301 | valid_mae: 0.05797 |  0:00:34s\n",
            "epoch 42 | loss: 0.3506  | train_mae: 0.03083 | valid_mae: 0.04842 |  0:00:35s\n",
            "epoch 43 | loss: 0.34103 | train_mae: 0.02698 | valid_mae: 0.04071 |  0:00:36s\n",
            "epoch 44 | loss: 0.35116 | train_mae: 0.0218  | valid_mae: 0.037   |  0:00:37s\n",
            "epoch 45 | loss: 0.39842 | train_mae: 0.02025 | valid_mae: 0.03549 |  0:00:38s\n",
            "epoch 46 | loss: 0.35008 | train_mae: 0.01847 | valid_mae: 0.03099 |  0:00:39s\n",
            "epoch 47 | loss: 0.42057 | train_mae: 0.01652 | valid_mae: 0.03184 |  0:00:40s\n",
            "epoch 48 | loss: 0.33786 | train_mae: 0.01706 | valid_mae: 0.03107 |  0:00:40s\n",
            "epoch 49 | loss: 0.35737 | train_mae: 0.01763 | valid_mae: 0.03061 |  0:00:41s\n",
            "epoch 50 | loss: 0.31613 | train_mae: 0.01665 | valid_mae: 0.03292 |  0:00:42s\n",
            "epoch 51 | loss: 0.33159 | train_mae: 0.01623 | valid_mae: 0.0326  |  0:00:43s\n",
            "epoch 52 | loss: 0.30625 | train_mae: 0.0145  | valid_mae: 0.03139 |  0:00:44s\n",
            "epoch 53 | loss: 0.26767 | train_mae: 0.01833 | valid_mae: 0.03093 |  0:00:44s\n",
            "epoch 54 | loss: 0.25435 | train_mae: 0.0137  | valid_mae: 0.02764 |  0:00:45s\n",
            "epoch 55 | loss: 0.22197 | train_mae: 0.01471 | valid_mae: 0.0283  |  0:00:46s\n",
            "epoch 56 | loss: 0.16658 | train_mae: 0.01371 | valid_mae: 0.02862 |  0:00:47s\n",
            "epoch 57 | loss: 0.22484 | train_mae: 0.01575 | valid_mae: 0.02739 |  0:00:47s\n",
            "epoch 58 | loss: 0.26518 | train_mae: 0.01369 | valid_mae: 0.02866 |  0:00:48s\n",
            "epoch 59 | loss: 0.47939 | train_mae: 0.01395 | valid_mae: 0.02862 |  0:00:49s\n",
            "epoch 60 | loss: 0.27192 | train_mae: 0.0144  | valid_mae: 0.02705 |  0:00:50s\n",
            "epoch 61 | loss: 0.15788 | train_mae: 0.01243 | valid_mae: 0.02577 |  0:00:51s\n",
            "epoch 62 | loss: 0.22912 | train_mae: 0.01413 | valid_mae: 0.02633 |  0:00:52s\n",
            "epoch 63 | loss: 0.16542 | train_mae: 0.01463 | valid_mae: 0.02861 |  0:00:53s\n",
            "epoch 64 | loss: 0.16239 | train_mae: 0.0126  | valid_mae: 0.02609 |  0:00:54s\n",
            "epoch 65 | loss: 0.2084  | train_mae: 0.01022 | valid_mae: 0.02407 |  0:00:55s\n",
            "epoch 66 | loss: 0.1427  | train_mae: 0.01335 | valid_mae: 0.0275  |  0:00:55s\n",
            "epoch 67 | loss: 0.14852 | train_mae: 0.00979 | valid_mae: 0.02444 |  0:00:56s\n",
            "epoch 68 | loss: 0.14103 | train_mae: 0.01143 | valid_mae: 0.02571 |  0:00:57s\n",
            "epoch 69 | loss: 0.16587 | train_mae: 0.01449 | valid_mae: 0.02784 |  0:00:58s\n",
            "epoch 70 | loss: 0.15285 | train_mae: 0.01105 | valid_mae: 0.02493 |  0:00:58s\n",
            "epoch 71 | loss: 0.219   | train_mae: 0.01317 | valid_mae: 0.02593 |  0:00:59s\n",
            "epoch 72 | loss: 0.1253  | train_mae: 0.01144 | valid_mae: 0.02525 |  0:01:00s\n",
            "epoch 73 | loss: 0.15521 | train_mae: 0.01214 | valid_mae: 0.02478 |  0:01:01s\n",
            "epoch 74 | loss: 0.19244 | train_mae: 0.01006 | valid_mae: 0.02522 |  0:01:01s\n",
            "epoch 75 | loss: 0.13823 | train_mae: 0.01038 | valid_mae: 0.02656 |  0:01:02s\n",
            "epoch 76 | loss: 0.11363 | train_mae: 0.01062 | valid_mae: 0.02671 |  0:01:03s\n",
            "epoch 77 | loss: 0.12429 | train_mae: 0.01146 | valid_mae: 0.02643 |  0:01:05s\n",
            "epoch 78 | loss: 0.13882 | train_mae: 0.0104  | valid_mae: 0.02589 |  0:01:05s\n",
            "epoch 79 | loss: 0.11672 | train_mae: 0.00987 | valid_mae: 0.0269  |  0:01:06s\n",
            "epoch 80 | loss: 0.08373 | train_mae: 0.00881 | valid_mae: 0.02617 |  0:01:07s\n",
            "epoch 81 | loss: 0.09664 | train_mae: 0.01013 | valid_mae: 0.02672 |  0:01:08s\n",
            "epoch 82 | loss: 0.09121 | train_mae: 0.01145 | valid_mae: 0.02749 |  0:01:08s\n",
            "epoch 83 | loss: 0.08122 | train_mae: 0.0111  | valid_mae: 0.02669 |  0:01:09s\n",
            "epoch 84 | loss: 0.09208 | train_mae: 0.0087  | valid_mae: 0.02473 |  0:01:10s\n",
            "epoch 85 | loss: 0.09472 | train_mae: 0.01443 | valid_mae: 0.02884 |  0:01:11s\n",
            "epoch 86 | loss: 0.11905 | train_mae: 0.00966 | valid_mae: 0.02586 |  0:01:11s\n",
            "epoch 87 | loss: 0.11821 | train_mae: 0.00927 | valid_mae: 0.02428 |  0:01:12s\n",
            "epoch 88 | loss: 0.19284 | train_mae: 0.00996 | valid_mae: 0.02579 |  0:01:13s\n",
            "epoch 89 | loss: 0.10188 | train_mae: 0.01002 | valid_mae: 0.0253  |  0:01:14s\n",
            "epoch 90 | loss: 0.14642 | train_mae: 0.01069 | valid_mae: 0.02539 |  0:01:15s\n",
            "epoch 91 | loss: 0.16876 | train_mae: 0.00977 | valid_mae: 0.02476 |  0:01:16s\n",
            "epoch 92 | loss: 0.13139 | train_mae: 0.01049 | valid_mae: 0.0253  |  0:01:17s\n",
            "epoch 93 | loss: 0.1417  | train_mae: 0.00971 | valid_mae: 0.02467 |  0:01:18s\n",
            "epoch 94 | loss: 0.15747 | train_mae: 0.00859 | valid_mae: 0.02589 |  0:01:19s\n",
            "epoch 95 | loss: 0.12384 | train_mae: 0.0091  | valid_mae: 0.02535 |  0:01:19s\n",
            "epoch 96 | loss: 0.10858 | train_mae: 0.01163 | valid_mae: 0.0264  |  0:01:20s\n",
            "epoch 97 | loss: 0.08326 | train_mae: 0.00959 | valid_mae: 0.02419 |  0:01:21s\n",
            "epoch 98 | loss: 0.12053 | train_mae: 0.00872 | valid_mae: 0.02355 |  0:01:22s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-09-05 01:13:40,177] Trial 10 finished with value: 0.10440763384103775 and parameters: {'n_d': 22, 'n_a': 31, 'n_steps': 4, 'gamma': 1.9818686728142358, 'lambda_sparse': 8.179311215836023e-05, 'batch_size': 128, 'mask_type': 'entmax', 'emb': 24, 'momentum': 0.8261522713376154, 'learning_rate': 0.010368419427095932, 'weight_decay': 2.2727937361429945e-05, 'scheduler_gamma': 0.9939961953896786, 'step_size': 15, 'virtual_batch_size': 64, 'optimizer_type': 'rmsprop', 'p': 0.0034981207125003855}. Best is trial 10 with value: 0.10440763384103775.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 99 | loss: 0.10441 | train_mae: 0.01495 | valid_mae: 0.02795 |  0:01:22s\n",
            "Stop training because you reached max_epochs = 100 with best_epoch = 98 and best_valid_mae = 0.02355\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 375.04474| train_mae: 8.62316 | valid_mae: 8.34004 |  0:00:00s\n",
            "epoch 1  | loss: 146.51579| train_mae: 5.15057 | valid_mae: 4.19407 |  0:00:01s\n",
            "epoch 2  | loss: 47.23432| train_mae: 2.02346 | valid_mae: 1.78595 |  0:00:02s\n",
            "epoch 3  | loss: 21.91952| train_mae: 1.35808 | valid_mae: 1.33913 |  0:00:03s\n",
            "epoch 4  | loss: 12.32793| train_mae: 0.88077 | valid_mae: 0.91865 |  0:00:04s\n",
            "epoch 5  | loss: 1.96154 | train_mae: 0.24169 | valid_mae: 0.30052 |  0:00:05s\n",
            "epoch 6  | loss: 1.55978 | train_mae: 0.11195 | valid_mae: 0.14786 |  0:00:06s\n",
            "epoch 7  | loss: 1.13579 | train_mae: 0.10236 | valid_mae: 0.10985 |  0:00:07s\n",
            "epoch 8  | loss: 1.21719 | train_mae: 0.07723 | valid_mae: 0.08561 |  0:00:08s\n",
            "epoch 9  | loss: 0.96016 | train_mae: 0.06033 | valid_mae: 0.06655 |  0:00:08s\n",
            "epoch 10 | loss: 1.17066 | train_mae: 0.06652 | valid_mae: 0.08048 |  0:00:09s\n",
            "epoch 11 | loss: 1.06098 | train_mae: 0.04953 | valid_mae: 0.08172 |  0:00:10s\n",
            "epoch 12 | loss: 0.87578 | train_mae: 0.04097 | valid_mae: 0.05112 |  0:00:11s\n",
            "epoch 13 | loss: 0.89623 | train_mae: 0.03798 | valid_mae: 0.04728 |  0:00:11s\n",
            "epoch 14 | loss: 0.90134 | train_mae: 0.05683 | valid_mae: 0.06337 |  0:00:12s\n",
            "epoch 15 | loss: 0.83297 | train_mae: 0.03997 | valid_mae: 0.04352 |  0:00:13s\n",
            "epoch 16 | loss: 0.75693 | train_mae: 0.06131 | valid_mae: 0.06115 |  0:00:14s\n",
            "epoch 17 | loss: 0.72121 | train_mae: 0.03055 | valid_mae: 0.03451 |  0:00:15s\n",
            "epoch 18 | loss: 0.58373 | train_mae: 0.04914 | valid_mae: 0.0496  |  0:00:16s\n",
            "epoch 19 | loss: 0.69292 | train_mae: 0.03747 | valid_mae: 0.04303 |  0:00:17s\n",
            "epoch 20 | loss: 0.54021 | train_mae: 0.03508 | valid_mae: 0.04114 |  0:00:18s\n",
            "epoch 21 | loss: 0.67401 | train_mae: 0.04578 | valid_mae: 0.05023 |  0:00:19s\n",
            "epoch 22 | loss: 0.50072 | train_mae: 0.03369 | valid_mae: 0.04629 |  0:00:19s\n",
            "epoch 23 | loss: 0.74594 | train_mae: 0.02633 | valid_mae: 0.04331 |  0:00:20s\n",
            "epoch 24 | loss: 0.52166 | train_mae: 0.0308  | valid_mae: 0.04254 |  0:00:21s\n",
            "epoch 25 | loss: 0.47166 | train_mae: 0.02857 | valid_mae: 0.03879 |  0:00:22s\n",
            "epoch 26 | loss: 0.56797 | train_mae: 0.02518 | valid_mae: 0.03755 |  0:00:22s\n",
            "epoch 27 | loss: 0.45581 | train_mae: 0.02236 | valid_mae: 0.03252 |  0:00:23s\n",
            "epoch 28 | loss: 0.29264 | train_mae: 0.02299 | valid_mae: 0.03283 |  0:00:24s\n",
            "epoch 29 | loss: 0.45013 | train_mae: 0.023   | valid_mae: 0.03178 |  0:00:25s\n",
            "epoch 30 | loss: 0.51007 | train_mae: 0.02259 | valid_mae: 0.03225 |  0:00:26s\n",
            "epoch 31 | loss: 0.39208 | train_mae: 0.01905 | valid_mae: 0.02871 |  0:00:26s\n",
            "epoch 32 | loss: 0.41455 | train_mae: 0.02408 | valid_mae: 0.03594 |  0:00:27s\n",
            "epoch 33 | loss: 1.26413 | train_mae: 0.0205  | valid_mae: 0.03281 |  0:00:28s\n",
            "epoch 34 | loss: 0.37348 | train_mae: 0.02092 | valid_mae: 0.02966 |  0:00:29s\n",
            "epoch 35 | loss: 0.41443 | train_mae: 0.02045 | valid_mae: 0.03236 |  0:00:30s\n",
            "epoch 36 | loss: 0.4837  | train_mae: 0.01676 | valid_mae: 0.02849 |  0:00:31s\n",
            "epoch 37 | loss: 0.24334 | train_mae: 0.0178  | valid_mae: 0.03211 |  0:00:32s\n",
            "epoch 38 | loss: 0.39981 | train_mae: 0.01522 | valid_mae: 0.0276  |  0:00:33s\n",
            "epoch 39 | loss: 0.34107 | train_mae: 0.01623 | valid_mae: 0.03135 |  0:00:33s\n",
            "epoch 40 | loss: 0.22808 | train_mae: 0.01745 | valid_mae: 0.03444 |  0:00:34s\n",
            "epoch 41 | loss: 0.37795 | train_mae: 0.02014 | valid_mae: 0.02935 |  0:00:35s\n",
            "epoch 42 | loss: 0.56151 | train_mae: 0.01882 | valid_mae: 0.0294  |  0:00:36s\n",
            "epoch 43 | loss: 0.23756 | train_mae: 0.02021 | valid_mae: 0.03095 |  0:00:36s\n",
            "epoch 44 | loss: 0.29757 | train_mae: 0.0181  | valid_mae: 0.03216 |  0:00:37s\n",
            "epoch 45 | loss: 0.25781 | train_mae: 0.0158  | valid_mae: 0.03454 |  0:00:38s\n",
            "epoch 46 | loss: 0.19321 | train_mae: 0.01821 | valid_mae: 0.04027 |  0:00:39s\n",
            "epoch 47 | loss: 0.28938 | train_mae: 0.01735 | valid_mae: 0.02899 |  0:00:39s\n",
            "epoch 48 | loss: 0.19093 | train_mae: 0.01753 | valid_mae: 0.0283  |  0:00:40s\n",
            "epoch 49 | loss: 0.28194 | train_mae: 0.01348 | valid_mae: 0.026   |  0:00:41s\n",
            "epoch 50 | loss: 0.3315  | train_mae: 0.012   | valid_mae: 0.02664 |  0:00:42s\n",
            "epoch 51 | loss: 0.22489 | train_mae: 0.01241 | valid_mae: 0.0265  |  0:00:43s\n",
            "epoch 52 | loss: 0.22774 | train_mae: 0.01145 | valid_mae: 0.0255  |  0:00:44s\n",
            "epoch 53 | loss: 0.41749 | train_mae: 0.01322 | valid_mae: 0.02582 |  0:00:45s\n",
            "epoch 54 | loss: 0.24239 | train_mae: 0.01334 | valid_mae: 0.02696 |  0:00:46s\n",
            "epoch 55 | loss: 0.20647 | train_mae: 0.01466 | valid_mae: 0.02536 |  0:00:46s\n",
            "epoch 56 | loss: 0.32185 | train_mae: 0.01615 | valid_mae: 0.0255  |  0:00:47s\n",
            "epoch 57 | loss: 0.16129 | train_mae: 0.01163 | valid_mae: 0.0255  |  0:00:48s\n",
            "epoch 58 | loss: 0.21296 | train_mae: 0.01125 | valid_mae: 0.02568 |  0:00:49s\n",
            "epoch 59 | loss: 0.25994 | train_mae: 0.01211 | valid_mae: 0.02557 |  0:00:49s\n",
            "epoch 60 | loss: 0.15566 | train_mae: 0.01318 | valid_mae: 0.0258  |  0:00:50s\n",
            "epoch 61 | loss: 0.20668 | train_mae: 0.01105 | valid_mae: 0.02714 |  0:00:51s\n",
            "epoch 62 | loss: 0.19536 | train_mae: 0.01225 | valid_mae: 0.02631 |  0:00:52s\n",
            "epoch 63 | loss: 0.17293 | train_mae: 0.01201 | valid_mae: 0.02598 |  0:00:52s\n",
            "epoch 64 | loss: 0.21221 | train_mae: 0.01023 | valid_mae: 0.02574 |  0:00:53s\n",
            "epoch 65 | loss: 0.17418 | train_mae: 0.01715 | valid_mae: 0.02646 |  0:00:54s\n",
            "epoch 66 | loss: 0.20688 | train_mae: 0.01116 | valid_mae: 0.02286 |  0:00:55s\n",
            "epoch 67 | loss: 0.15857 | train_mae: 0.01076 | valid_mae: 0.02274 |  0:00:56s\n",
            "epoch 68 | loss: 0.14553 | train_mae: 0.01052 | valid_mae: 0.02086 |  0:00:57s\n",
            "epoch 69 | loss: 0.14907 | train_mae: 0.00956 | valid_mae: 0.02278 |  0:00:58s\n",
            "epoch 70 | loss: 0.15016 | train_mae: 0.00848 | valid_mae: 0.02062 |  0:00:59s\n",
            "epoch 71 | loss: 0.11635 | train_mae: 0.0091  | valid_mae: 0.02312 |  0:01:00s\n",
            "epoch 72 | loss: 0.13426 | train_mae: 0.00772 | valid_mae: 0.02299 |  0:01:00s\n",
            "epoch 73 | loss: 0.11091 | train_mae: 0.00778 | valid_mae: 0.02632 |  0:01:01s\n",
            "epoch 74 | loss: 0.16912 | train_mae: 0.01357 | valid_mae: 0.02899 |  0:01:02s\n",
            "epoch 75 | loss: 0.25181 | train_mae: 0.01032 | valid_mae: 0.02503 |  0:01:03s\n",
            "epoch 76 | loss: 0.11577 | train_mae: 0.01293 | valid_mae: 0.02435 |  0:01:03s\n",
            "epoch 77 | loss: 0.13806 | train_mae: 0.00844 | valid_mae: 0.02178 |  0:01:04s\n",
            "epoch 78 | loss: 0.13232 | train_mae: 0.00957 | valid_mae: 0.02236 |  0:01:05s\n",
            "epoch 79 | loss: 0.11485 | train_mae: 0.01038 | valid_mae: 0.02294 |  0:01:06s\n",
            "epoch 80 | loss: 0.13208 | train_mae: 0.00831 | valid_mae: 0.0228  |  0:01:06s\n",
            "epoch 81 | loss: 0.08225 | train_mae: 0.00979 | valid_mae: 0.02249 |  0:01:07s\n",
            "epoch 82 | loss: 0.10031 | train_mae: 0.00673 | valid_mae: 0.02104 |  0:01:08s\n",
            "epoch 83 | loss: 0.2574  | train_mae: 0.00659 | valid_mae: 0.02086 |  0:01:09s\n",
            "epoch 84 | loss: 0.11617 | train_mae: 0.00856 | valid_mae: 0.02223 |  0:01:10s\n",
            "epoch 85 | loss: 0.19354 | train_mae: 0.00772 | valid_mae: 0.02172 |  0:01:11s\n",
            "epoch 86 | loss: 0.08348 | train_mae: 0.00589 | valid_mae: 0.02081 |  0:01:12s\n",
            "epoch 87 | loss: 0.06246 | train_mae: 0.00775 | valid_mae: 0.02214 |  0:01:13s\n",
            "epoch 88 | loss: 0.18829 | train_mae: 0.00657 | valid_mae: 0.02216 |  0:01:13s\n",
            "epoch 89 | loss: 0.05747 | train_mae: 0.00625 | valid_mae: 0.02269 |  0:01:14s\n",
            "epoch 90 | loss: 0.05801 | train_mae: 0.00691 | valid_mae: 0.02235 |  0:01:15s\n",
            "epoch 91 | loss: 0.0429  | train_mae: 0.00586 | valid_mae: 0.02208 |  0:01:16s\n",
            "epoch 92 | loss: 0.03598 | train_mae: 0.00633 | valid_mae: 0.02237 |  0:01:16s\n",
            "epoch 93 | loss: 0.0657  | train_mae: 0.00639 | valid_mae: 0.02248 |  0:01:17s\n",
            "epoch 94 | loss: 0.0453  | train_mae: 0.00615 | valid_mae: 0.02279 |  0:01:18s\n",
            "epoch 95 | loss: 0.08647 | train_mae: 0.00719 | valid_mae: 0.02307 |  0:01:19s\n",
            "epoch 96 | loss: 0.12661 | train_mae: 0.00616 | valid_mae: 0.02243 |  0:01:19s\n",
            "epoch 97 | loss: 0.09172 | train_mae: 0.00604 | valid_mae: 0.0227  |  0:01:20s\n",
            "epoch 98 | loss: 0.07296 | train_mae: 0.01216 | valid_mae: 0.02637 |  0:01:21s\n",
            "epoch 99 | loss: 0.04982 | train_mae: 0.00697 | valid_mae: 0.02302 |  0:01:22s\n",
            "Stop training because you reached max_epochs = 100 with best_epoch = 70 and best_valid_mae = 0.02062\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-09-05 01:15:06,343] Trial 11 finished with value: 0.04981649555265903 and parameters: {'n_d': 22, 'n_a': 32, 'n_steps': 4, 'gamma': 1.9960936946749759, 'lambda_sparse': 9.103081183863075e-05, 'batch_size': 128, 'mask_type': 'entmax', 'emb': 24, 'momentum': 0.8295284103047583, 'learning_rate': 0.010278433468993582, 'weight_decay': 2.1435996212114308e-05, 'scheduler_gamma': 0.9931143536252859, 'step_size': 15, 'virtual_batch_size': 64, 'optimizer_type': 'rmsprop', 'p': 0.008892842468268852}. Best is trial 11 with value: 0.04981649555265903.\n",
            "/usr/local/lib/python3.12/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 356.05891| train_mae: 12.42886| valid_mae: 12.64068|  0:00:00s\n",
            "epoch 1  | loss: 221.56197| train_mae: 3.67107 | valid_mae: 3.54936 |  0:00:01s\n",
            "epoch 2  | loss: 31.25741| train_mae: 0.78922 | valid_mae: 0.90969 |  0:00:02s\n",
            "epoch 3  | loss: 6.67568 | train_mae: 0.75163 | valid_mae: 0.77075 |  0:00:03s\n",
            "epoch 4  | loss: 3.13388 | train_mae: 0.14675 | valid_mae: 0.14351 |  0:00:03s\n",
            "epoch 5  | loss: 1.69318 | train_mae: 0.10769 | valid_mae: 0.09237 |  0:00:04s\n",
            "epoch 6  | loss: 1.37167 | train_mae: 0.04255 | valid_mae: 0.04482 |  0:00:05s\n",
            "epoch 7  | loss: 1.19236 | train_mae: 0.05587 | valid_mae: 0.05388 |  0:00:06s\n",
            "epoch 8  | loss: 1.14671 | train_mae: 0.0548  | valid_mae: 0.05047 |  0:00:06s\n",
            "epoch 9  | loss: 1.09274 | train_mae: 0.0719  | valid_mae: 0.07567 |  0:00:08s\n",
            "epoch 10 | loss: 0.85566 | train_mae: 0.04419 | valid_mae: 0.04683 |  0:00:09s\n",
            "epoch 11 | loss: 0.98483 | train_mae: 0.05832 | valid_mae: 0.07244 |  0:00:10s\n",
            "epoch 12 | loss: 0.93375 | train_mae: 0.03331 | valid_mae: 0.0516  |  0:00:11s\n",
            "epoch 13 | loss: 0.81961 | train_mae: 0.03242 | valid_mae: 0.04018 |  0:00:11s\n",
            "epoch 14 | loss: 0.98023 | train_mae: 0.04042 | valid_mae: 0.04087 |  0:00:12s\n",
            "epoch 15 | loss: 0.81256 | train_mae: 0.0349  | valid_mae: 0.03875 |  0:00:13s\n",
            "epoch 16 | loss: 0.80685 | train_mae: 0.0451  | valid_mae: 0.04938 |  0:00:14s\n",
            "epoch 17 | loss: 0.81641 | train_mae: 0.07545 | valid_mae: 0.08166 |  0:00:14s\n",
            "epoch 18 | loss: 0.7416  | train_mae: 0.08075 | valid_mae: 0.08439 |  0:00:15s\n",
            "epoch 19 | loss: 0.80644 | train_mae: 0.12909 | valid_mae: 0.13174 |  0:00:16s\n",
            "epoch 20 | loss: 1.00332 | train_mae: 0.15179 | valid_mae: 0.16132 |  0:00:17s\n",
            "epoch 21 | loss: 0.60375 | train_mae: 0.09275 | valid_mae: 0.09662 |  0:00:17s\n",
            "epoch 22 | loss: 0.50597 | train_mae: 0.1431  | valid_mae: 0.15286 |  0:00:18s\n",
            "epoch 23 | loss: 0.49893 | train_mae: 0.07828 | valid_mae: 0.08468 |  0:00:19s\n",
            "epoch 24 | loss: 0.7184  | train_mae: 0.04801 | valid_mae: 0.05369 |  0:00:20s\n",
            "epoch 25 | loss: 0.48244 | train_mae: 0.04728 | valid_mae: 0.05277 |  0:00:21s\n",
            "epoch 26 | loss: 0.59776 | train_mae: 0.03871 | valid_mae: 0.04574 |  0:00:22s\n",
            "epoch 27 | loss: 0.60369 | train_mae: 0.03376 | valid_mae: 0.04272 |  0:00:23s\n",
            "epoch 28 | loss: 0.45897 | train_mae: 0.0327  | valid_mae: 0.03813 |  0:00:24s\n",
            "epoch 29 | loss: 0.57304 | train_mae: 0.03245 | valid_mae: 0.03743 |  0:00:24s\n",
            "epoch 30 | loss: 0.44779 | train_mae: 0.03271 | valid_mae: 0.0398  |  0:00:25s\n",
            "epoch 31 | loss: 0.45065 | train_mae: 0.02778 | valid_mae: 0.03922 |  0:00:26s\n",
            "epoch 32 | loss: 0.37072 | train_mae: 0.02661 | valid_mae: 0.03687 |  0:00:27s\n",
            "epoch 33 | loss: 0.41224 | train_mae: 0.02202 | valid_mae: 0.03338 |  0:00:28s\n",
            "epoch 34 | loss: 0.44357 | train_mae: 0.02265 | valid_mae: 0.03134 |  0:00:28s\n",
            "epoch 35 | loss: 0.38439 | train_mae: 0.02024 | valid_mae: 0.03289 |  0:00:29s\n",
            "epoch 36 | loss: 0.47599 | train_mae: 0.02548 | valid_mae: 0.03786 |  0:00:30s\n",
            "epoch 37 | loss: 0.46242 | train_mae: 0.0226  | valid_mae: 0.03431 |  0:00:31s\n",
            "epoch 38 | loss: 0.36552 | train_mae: 0.02218 | valid_mae: 0.03475 |  0:00:31s\n",
            "epoch 39 | loss: 0.35003 | train_mae: 0.01939 | valid_mae: 0.03019 |  0:00:32s\n",
            "epoch 40 | loss: 0.25006 | train_mae: 0.01924 | valid_mae: 0.0305  |  0:00:33s\n",
            "epoch 41 | loss: 0.49182 | train_mae: 0.01882 | valid_mae: 0.03059 |  0:00:34s\n",
            "epoch 42 | loss: 0.28212 | train_mae: 0.01752 | valid_mae: 0.03219 |  0:00:35s\n",
            "epoch 43 | loss: 0.22361 | train_mae: 0.01829 | valid_mae: 0.03082 |  0:00:36s\n",
            "epoch 44 | loss: 0.34308 | train_mae: 0.01934 | valid_mae: 0.03131 |  0:00:37s\n",
            "epoch 45 | loss: 0.26862 | train_mae: 0.01845 | valid_mae: 0.02892 |  0:00:38s\n",
            "epoch 46 | loss: 0.55271 | train_mae: 0.01921 | valid_mae: 0.02968 |  0:00:38s\n",
            "epoch 47 | loss: 0.27469 | train_mae: 0.01705 | valid_mae: 0.02962 |  0:00:39s\n",
            "epoch 48 | loss: 0.24779 | train_mae: 0.01584 | valid_mae: 0.03163 |  0:00:40s\n",
            "epoch 49 | loss: 0.24401 | train_mae: 0.01616 | valid_mae: 0.031   |  0:00:41s\n",
            "epoch 50 | loss: 0.30916 | train_mae: 0.02506 | valid_mae: 0.0389  |  0:00:41s\n",
            "epoch 51 | loss: 0.19991 | train_mae: 0.04062 | valid_mae: 0.04846 |  0:00:42s\n",
            "epoch 52 | loss: 0.46598 | train_mae: 0.02813 | valid_mae: 0.03912 |  0:00:43s\n",
            "epoch 53 | loss: 0.17531 | train_mae: 0.02123 | valid_mae: 0.03478 |  0:00:44s\n",
            "epoch 54 | loss: 0.23202 | train_mae: 0.01726 | valid_mae: 0.03258 |  0:00:45s\n",
            "epoch 55 | loss: 0.20674 | train_mae: 0.01649 | valid_mae: 0.03266 |  0:00:45s\n",
            "epoch 56 | loss: 0.24027 | train_mae: 0.01612 | valid_mae: 0.03513 |  0:00:46s\n",
            "epoch 57 | loss: 0.15835 | train_mae: 0.01384 | valid_mae: 0.03186 |  0:00:47s\n",
            "epoch 58 | loss: 0.2043  | train_mae: 0.01319 | valid_mae: 0.02997 |  0:00:48s\n",
            "epoch 59 | loss: 0.26073 | train_mae: 0.0147  | valid_mae: 0.0301  |  0:00:50s\n",
            "epoch 60 | loss: 0.20407 | train_mae: 0.01499 | valid_mae: 0.03114 |  0:00:51s\n",
            "epoch 61 | loss: 0.41878 | train_mae: 0.01621 | valid_mae: 0.03087 |  0:00:51s\n",
            "epoch 62 | loss: 0.44379 | train_mae: 0.01499 | valid_mae: 0.02999 |  0:00:52s\n",
            "epoch 63 | loss: 0.29096 | train_mae: 0.0133  | valid_mae: 0.03009 |  0:00:53s\n",
            "epoch 64 | loss: 0.34348 | train_mae: 0.01586 | valid_mae: 0.03054 |  0:00:54s\n",
            "epoch 65 | loss: 0.36551 | train_mae: 0.01447 | valid_mae: 0.03166 |  0:00:55s\n",
            "epoch 66 | loss: 0.35514 | train_mae: 0.0139  | valid_mae: 0.03051 |  0:00:55s\n",
            "epoch 67 | loss: 0.35221 | train_mae: 0.01293 | valid_mae: 0.02712 |  0:00:56s\n",
            "epoch 68 | loss: 0.39633 | train_mae: 0.01404 | valid_mae: 0.02816 |  0:00:57s\n",
            "epoch 69 | loss: 0.37031 | train_mae: 0.01332 | valid_mae: 0.02679 |  0:00:58s\n",
            "epoch 70 | loss: 0.26374 | train_mae: 0.01241 | valid_mae: 0.02662 |  0:00:59s\n",
            "epoch 71 | loss: 0.51974 | train_mae: 0.01224 | valid_mae: 0.0264  |  0:01:00s\n",
            "epoch 72 | loss: 0.34678 | train_mae: 0.01198 | valid_mae: 0.02726 |  0:01:01s\n",
            "epoch 73 | loss: 0.18924 | train_mae: 0.01057 | valid_mae: 0.02575 |  0:01:02s\n",
            "epoch 74 | loss: 0.2013  | train_mae: 0.01164 | valid_mae: 0.02658 |  0:01:03s\n",
            "epoch 75 | loss: 0.22548 | train_mae: 0.01217 | valid_mae: 0.0274  |  0:01:03s\n",
            "epoch 76 | loss: 0.24717 | train_mae: 0.01415 | valid_mae: 0.02916 |  0:01:04s\n",
            "epoch 77 | loss: 0.52133 | train_mae: 0.01355 | valid_mae: 0.02793 |  0:01:05s\n",
            "epoch 78 | loss: 0.41531 | train_mae: 0.01522 | valid_mae: 0.03143 |  0:01:06s\n",
            "epoch 79 | loss: 0.24107 | train_mae: 0.01206 | valid_mae: 0.02868 |  0:01:07s\n",
            "epoch 80 | loss: 0.25899 | train_mae: 0.01888 | valid_mae: 0.03011 |  0:01:07s\n",
            "epoch 81 | loss: 0.28418 | train_mae: 0.01262 | valid_mae: 0.02834 |  0:01:08s\n",
            "epoch 82 | loss: 0.30775 | train_mae: 0.01123 | valid_mae: 0.02838 |  0:01:09s\n",
            "epoch 83 | loss: 0.18148 | train_mae: 0.01117 | valid_mae: 0.02843 |  0:01:10s\n",
            "epoch 84 | loss: 0.1685  | train_mae: 0.01095 | valid_mae: 0.02672 |  0:01:11s\n",
            "epoch 85 | loss: 0.12775 | train_mae: 0.01011 | valid_mae: 0.02699 |  0:01:11s\n",
            "epoch 86 | loss: 0.14122 | train_mae: 0.00881 | valid_mae: 0.02574 |  0:01:12s\n",
            "epoch 87 | loss: 0.22476 | train_mae: 0.01175 | valid_mae: 0.02698 |  0:01:13s\n",
            "epoch 88 | loss: 0.12606 | train_mae: 0.01074 | valid_mae: 0.027   |  0:01:14s\n",
            "epoch 89 | loss: 0.12381 | train_mae: 0.00929 | valid_mae: 0.0273  |  0:01:15s\n",
            "epoch 90 | loss: 0.09376 | train_mae: 0.01123 | valid_mae: 0.02857 |  0:01:16s\n",
            "epoch 91 | loss: 0.13372 | train_mae: 0.00959 | valid_mae: 0.02616 |  0:01:17s\n",
            "epoch 92 | loss: 0.20722 | train_mae: 0.00918 | valid_mae: 0.02563 |  0:01:18s\n",
            "epoch 93 | loss: 0.10863 | train_mae: 0.00875 | valid_mae: 0.02514 |  0:01:19s\n",
            "epoch 94 | loss: 0.12779 | train_mae: 0.00942 | valid_mae: 0.0264  |  0:01:19s\n",
            "epoch 95 | loss: 0.11441 | train_mae: 0.00875 | valid_mae: 0.02707 |  0:01:20s\n",
            "epoch 96 | loss: 0.07468 | train_mae: 0.00893 | valid_mae: 0.02561 |  0:01:21s\n",
            "epoch 97 | loss: 0.08873 | train_mae: 0.00926 | valid_mae: 0.02585 |  0:01:22s\n",
            "epoch 98 | loss: 0.11193 | train_mae: 0.00839 | valid_mae: 0.02554 |  0:01:23s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-09-05 01:16:33,233] Trial 12 finished with value: 0.15911171585321426 and parameters: {'n_d': 23, 'n_a': 32, 'n_steps': 4, 'gamma': 1.9993760086448702, 'lambda_sparse': 6.283229672309253e-05, 'batch_size': 128, 'mask_type': 'entmax', 'emb': 24, 'momentum': 0.7958551121670281, 'learning_rate': 0.011099306235219313, 'weight_decay': 3.961846274315658e-05, 'scheduler_gamma': 0.9948927457899323, 'step_size': 15, 'virtual_batch_size': 64, 'optimizer_type': 'rmsprop', 'p': 0.024502620886306475}. Best is trial 11 with value: 0.04981649555265903.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 99 | loss: 0.15911 | train_mae: 0.01046 | valid_mae: 0.0268  |  0:01:23s\n",
            "Stop training because you reached max_epochs = 100 with best_epoch = 93 and best_valid_mae = 0.02514\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 719.73303| train_mae: 7.33555 | valid_mae: 7.99719 |  0:00:01s\n",
            "epoch 1  | loss: 498.26496| train_mae: 3.56176 | valid_mae: 3.85835 |  0:00:01s\n",
            "epoch 2  | loss: 72.26274| train_mae: 0.82784 | valid_mae: 0.69908 |  0:00:02s\n",
            "epoch 3  | loss: 14.62044| train_mae: 0.93113 | valid_mae: 0.94188 |  0:00:03s\n",
            "epoch 4  | loss: 5.03512 | train_mae: 0.10259 | valid_mae: 0.10784 |  0:00:04s\n",
            "epoch 5  | loss: 2.42473 | train_mae: 0.13022 | valid_mae: 0.12827 |  0:00:05s\n",
            "epoch 6  | loss: 1.23536 | train_mae: 0.19045 | valid_mae: 0.21616 |  0:00:06s\n",
            "epoch 7  | loss: 1.61404 | train_mae: 0.05532 | valid_mae: 0.06054 |  0:00:06s\n",
            "epoch 8  | loss: 1.20047 | train_mae: 0.12087 | valid_mae: 0.13427 |  0:00:07s\n",
            "epoch 9  | loss: 1.38011 | train_mae: 0.06935 | valid_mae: 0.07224 |  0:00:08s\n",
            "epoch 10 | loss: 0.89786 | train_mae: 0.0445  | valid_mae: 0.04749 |  0:00:09s\n",
            "epoch 11 | loss: 0.84733 | train_mae: 0.06572 | valid_mae: 0.05799 |  0:00:10s\n",
            "epoch 12 | loss: 0.86345 | train_mae: 0.05692 | valid_mae: 0.0581  |  0:00:11s\n",
            "epoch 13 | loss: 0.81065 | train_mae: 0.04332 | valid_mae: 0.04982 |  0:00:12s\n",
            "epoch 14 | loss: 0.82598 | train_mae: 0.04124 | valid_mae: 0.0418  |  0:00:13s\n",
            "epoch 15 | loss: 1.27244 | train_mae: 0.05231 | valid_mae: 0.05183 |  0:00:14s\n",
            "epoch 16 | loss: 0.96821 | train_mae: 0.035   | valid_mae: 0.03859 |  0:00:15s\n",
            "epoch 17 | loss: 0.78023 | train_mae: 0.03832 | valid_mae: 0.04372 |  0:00:16s\n",
            "epoch 18 | loss: 1.01698 | train_mae: 0.04561 | valid_mae: 0.05327 |  0:00:16s\n",
            "epoch 19 | loss: 0.8764  | train_mae: 0.04128 | valid_mae: 0.04892 |  0:00:17s\n",
            "epoch 20 | loss: 0.73999 | train_mae: 0.03501 | valid_mae: 0.03954 |  0:00:18s\n",
            "epoch 21 | loss: 0.78558 | train_mae: 0.03209 | valid_mae: 0.03784 |  0:00:19s\n",
            "epoch 22 | loss: 0.62458 | train_mae: 0.02852 | valid_mae: 0.0359  |  0:00:20s\n",
            "epoch 23 | loss: 0.6705  | train_mae: 0.03311 | valid_mae: 0.03866 |  0:00:21s\n",
            "epoch 24 | loss: 0.74721 | train_mae: 0.0289  | valid_mae: 0.03561 |  0:00:21s\n",
            "epoch 25 | loss: 0.59714 | train_mae: 0.03104 | valid_mae: 0.03641 |  0:00:22s\n",
            "epoch 26 | loss: 0.95977 | train_mae: 0.03439 | valid_mae: 0.03727 |  0:00:23s\n",
            "epoch 27 | loss: 0.61198 | train_mae: 0.02829 | valid_mae: 0.03664 |  0:00:24s\n",
            "epoch 28 | loss: 0.55527 | train_mae: 0.02908 | valid_mae: 0.0359  |  0:00:25s\n",
            "epoch 29 | loss: 0.64805 | train_mae: 0.03098 | valid_mae: 0.04102 |  0:00:26s\n",
            "epoch 30 | loss: 1.04053 | train_mae: 0.03177 | valid_mae: 0.04202 |  0:00:27s\n",
            "epoch 31 | loss: 0.55262 | train_mae: 0.03113 | valid_mae: 0.03933 |  0:00:28s\n",
            "epoch 32 | loss: 0.67972 | train_mae: 0.02777 | valid_mae: 0.03497 |  0:00:29s\n",
            "epoch 33 | loss: 0.58231 | train_mae: 0.0257  | valid_mae: 0.03209 |  0:00:30s\n",
            "epoch 34 | loss: 0.8677  | train_mae: 0.02666 | valid_mae: 0.03181 |  0:00:31s\n",
            "epoch 35 | loss: 0.62423 | train_mae: 0.02617 | valid_mae: 0.03181 |  0:00:31s\n",
            "epoch 36 | loss: 0.56807 | train_mae: 0.02506 | valid_mae: 0.03185 |  0:00:32s\n",
            "epoch 37 | loss: 0.55546 | train_mae: 0.02449 | valid_mae: 0.03052 |  0:00:33s\n",
            "epoch 38 | loss: 0.44233 | train_mae: 0.02562 | valid_mae: 0.03113 |  0:00:34s\n",
            "epoch 39 | loss: 0.61638 | train_mae: 0.02401 | valid_mae: 0.02991 |  0:00:35s\n",
            "epoch 40 | loss: 0.53204 | train_mae: 0.02365 | valid_mae: 0.02889 |  0:00:36s\n",
            "epoch 41 | loss: 0.50976 | train_mae: 0.02934 | valid_mae: 0.03663 |  0:00:36s\n",
            "epoch 42 | loss: 0.42966 | train_mae: 0.027   | valid_mae: 0.03529 |  0:00:38s\n",
            "epoch 43 | loss: 0.50559 | train_mae: 0.02525 | valid_mae: 0.03335 |  0:00:39s\n",
            "epoch 44 | loss: 0.54675 | train_mae: 0.0289  | valid_mae: 0.03599 |  0:00:40s\n",
            "epoch 45 | loss: 0.59064 | train_mae: 0.02439 | valid_mae: 0.03287 |  0:00:41s\n",
            "epoch 46 | loss: 0.57721 | train_mae: 0.02751 | valid_mae: 0.03541 |  0:00:41s\n",
            "epoch 47 | loss: 0.69816 | train_mae: 0.02715 | valid_mae: 0.0307  |  0:00:42s\n",
            "epoch 48 | loss: 0.4578  | train_mae: 0.02506 | valid_mae: 0.03083 |  0:00:43s\n",
            "epoch 49 | loss: 0.41961 | train_mae: 0.02719 | valid_mae: 0.03492 |  0:00:44s\n",
            "epoch 50 | loss: 0.40608 | train_mae: 0.02635 | valid_mae: 0.03278 |  0:00:45s\n",
            "epoch 51 | loss: 0.40753 | train_mae: 0.02335 | valid_mae: 0.03147 |  0:00:46s\n",
            "epoch 52 | loss: 0.5194  | train_mae: 0.02394 | valid_mae: 0.0335  |  0:00:46s\n",
            "epoch 53 | loss: 0.35832 | train_mae: 0.02234 | valid_mae: 0.03227 |  0:00:47s\n",
            "epoch 54 | loss: 0.55591 | train_mae: 0.02267 | valid_mae: 0.03356 |  0:00:48s\n",
            "epoch 55 | loss: 0.44778 | train_mae: 0.02236 | valid_mae: 0.03253 |  0:00:49s\n",
            "epoch 56 | loss: 0.48466 | train_mae: 0.01973 | valid_mae: 0.03145 |  0:00:50s\n",
            "epoch 57 | loss: 0.58319 | train_mae: 0.02196 | valid_mae: 0.03242 |  0:00:51s\n",
            "epoch 58 | loss: 0.41321 | train_mae: 0.01927 | valid_mae: 0.03271 |  0:00:52s\n",
            "epoch 59 | loss: 0.5853  | train_mae: 0.0189  | valid_mae: 0.03251 |  0:00:53s\n",
            "epoch 60 | loss: 0.30454 | train_mae: 0.02247 | valid_mae: 0.03277 |  0:00:54s\n",
            "epoch 61 | loss: 0.38605 | train_mae: 0.02286 | valid_mae: 0.03264 |  0:00:55s\n",
            "epoch 62 | loss: 0.29287 | train_mae: 0.01959 | valid_mae: 0.03285 |  0:00:56s\n",
            "epoch 63 | loss: 0.32048 | train_mae: 0.02327 | valid_mae: 0.03508 |  0:00:56s\n",
            "epoch 64 | loss: 0.32453 | train_mae: 0.01797 | valid_mae: 0.03039 |  0:00:57s\n",
            "epoch 65 | loss: 0.47733 | train_mae: 0.01962 | valid_mae: 0.03403 |  0:00:58s\n",
            "epoch 66 | loss: 0.48239 | train_mae: 0.01756 | valid_mae: 0.03119 |  0:00:59s\n",
            "epoch 67 | loss: 0.39686 | train_mae: 0.01582 | valid_mae: 0.03034 |  0:01:00s\n",
            "epoch 68 | loss: 0.38083 | train_mae: 0.01646 | valid_mae: 0.03074 |  0:01:00s\n",
            "epoch 69 | loss: 0.43384 | train_mae: 0.01692 | valid_mae: 0.03373 |  0:01:01s\n",
            "epoch 70 | loss: 0.32636 | train_mae: 0.01598 | valid_mae: 0.03454 |  0:01:02s\n",
            "epoch 71 | loss: 0.2917  | train_mae: 0.01613 | valid_mae: 0.0374  |  0:01:03s\n",
            "epoch 72 | loss: 0.263   | train_mae: 0.01302 | valid_mae: 0.03206 |  0:01:04s\n",
            "epoch 73 | loss: 0.16635 | train_mae: 0.01406 | valid_mae: 0.03118 |  0:01:05s\n",
            "epoch 74 | loss: 0.27616 | train_mae: 0.01538 | valid_mae: 0.0307  |  0:01:06s\n",
            "epoch 75 | loss: 0.23362 | train_mae: 0.01448 | valid_mae: 0.02881 |  0:01:07s\n",
            "epoch 76 | loss: 0.26095 | train_mae: 0.01415 | valid_mae: 0.03042 |  0:01:08s\n",
            "epoch 77 | loss: 0.19287 | train_mae: 0.01473 | valid_mae: 0.02912 |  0:01:09s\n",
            "epoch 78 | loss: 0.1819  | train_mae: 0.01234 | valid_mae: 0.02538 |  0:01:10s\n",
            "epoch 79 | loss: 0.36247 | train_mae: 0.01326 | valid_mae: 0.0261  |  0:01:10s\n",
            "epoch 80 | loss: 0.31043 | train_mae: 0.01345 | valid_mae: 0.02632 |  0:01:11s\n",
            "epoch 81 | loss: 0.31356 | train_mae: 0.01292 | valid_mae: 0.02844 |  0:01:12s\n",
            "epoch 82 | loss: 0.25656 | train_mae: 0.01627 | valid_mae: 0.02817 |  0:01:13s\n",
            "epoch 83 | loss: 0.43182 | train_mae: 0.0167  | valid_mae: 0.02822 |  0:01:14s\n",
            "epoch 84 | loss: 0.26871 | train_mae: 0.02132 | valid_mae: 0.02839 |  0:01:15s\n",
            "epoch 85 | loss: 0.48736 | train_mae: 0.02115 | valid_mae: 0.02854 |  0:01:15s\n",
            "epoch 86 | loss: 0.23073 | train_mae: 0.01938 | valid_mae: 0.02714 |  0:01:17s\n",
            "epoch 87 | loss: 0.23579 | train_mae: 0.01678 | valid_mae: 0.02704 |  0:01:18s\n",
            "epoch 88 | loss: 0.26123 | train_mae: 0.01616 | valid_mae: 0.02804 |  0:01:19s\n",
            "epoch 89 | loss: 0.43675 | train_mae: 0.01529 | valid_mae: 0.02815 |  0:01:20s\n",
            "epoch 90 | loss: 0.8319  | train_mae: 0.01472 | valid_mae: 0.02602 |  0:01:20s\n",
            "epoch 91 | loss: 0.36254 | train_mae: 0.01368 | valid_mae: 0.02378 |  0:01:21s\n",
            "epoch 92 | loss: 0.28685 | train_mae: 0.01243 | valid_mae: 0.02287 |  0:01:22s\n",
            "epoch 93 | loss: 0.38215 | train_mae: 0.01131 | valid_mae: 0.02228 |  0:01:23s\n",
            "epoch 94 | loss: 0.19367 | train_mae: 0.01499 | valid_mae: 0.02532 |  0:01:24s\n",
            "epoch 95 | loss: 0.49389 | train_mae: 0.015   | valid_mae: 0.02461 |  0:01:25s\n",
            "epoch 96 | loss: 0.35733 | train_mae: 0.0164  | valid_mae: 0.026   |  0:01:25s\n",
            "epoch 97 | loss: 0.27539 | train_mae: 0.01332 | valid_mae: 0.02551 |  0:01:26s\n",
            "epoch 98 | loss: 0.33665 | train_mae: 0.01383 | valid_mae: 0.02675 |  0:01:27s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-09-05 01:18:05,372] Trial 13 finished with value: 0.2007708266377449 and parameters: {'n_d': 15, 'n_a': 31, 'n_steps': 5, 'gamma': 1.849876031740128, 'lambda_sparse': 1.205378531525404e-05, 'batch_size': 128, 'mask_type': 'entmax', 'emb': 24, 'momentum': 0.7876261076247327, 'learning_rate': 0.011313697125360532, 'weight_decay': 4.753958358289435e-05, 'scheduler_gamma': 0.9946018327202848, 'step_size': 14, 'virtual_batch_size': 64, 'optimizer_type': 'rmsprop', 'p': 0.0025724881481208168}. Best is trial 11 with value: 0.04981649555265903.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 99 | loss: 0.20077 | train_mae: 0.01303 | valid_mae: 0.02439 |  0:01:28s\n",
            "Stop training because you reached max_epochs = 100 with best_epoch = 93 and best_valid_mae = 0.02228\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 823.23301| train_mae: 13.26275| valid_mae: 11.53073|  0:00:00s\n",
            "epoch 1  | loss: 619.33762| train_mae: 4.65788 | valid_mae: 4.5595  |  0:00:01s\n",
            "epoch 2  | loss: 524.83375| train_mae: 2.32025 | valid_mae: 2.64406 |  0:00:02s\n",
            "epoch 3  | loss: 445.09335| train_mae: 2.07486 | valid_mae: 1.73619 |  0:00:03s\n",
            "epoch 4  | loss: 481.19699| train_mae: 1.81582 | valid_mae: 1.72943 |  0:00:03s\n",
            "epoch 5  | loss: 373.77147| train_mae: 1.83473 | valid_mae: 1.91194 |  0:00:04s\n",
            "epoch 6  | loss: 697.18685| train_mae: 1.43559 | valid_mae: 1.46117 |  0:00:05s\n",
            "epoch 7  | loss: 231.898 | train_mae: 1.27995 | valid_mae: 1.12417 |  0:00:06s\n",
            "epoch 8  | loss: 225.23381| train_mae: 1.05114 | valid_mae: 0.95215 |  0:00:07s\n",
            "epoch 9  | loss: 252.96555| train_mae: 1.03321 | valid_mae: 0.96087 |  0:00:07s\n",
            "epoch 10 | loss: 200.88942| train_mae: 1.10638 | valid_mae: 0.95076 |  0:00:08s\n",
            "epoch 11 | loss: 251.32823| train_mae: 1.11446 | valid_mae: 1.21146 |  0:00:09s\n",
            "epoch 12 | loss: 160.37394| train_mae: 1.13564 | valid_mae: 1.15586 |  0:00:10s\n",
            "epoch 13 | loss: 195.64697| train_mae: 1.18547 | valid_mae: 1.30452 |  0:00:11s\n",
            "epoch 14 | loss: 140.80032| train_mae: 1.10555 | valid_mae: 0.92881 |  0:00:12s\n",
            "epoch 15 | loss: 171.25377| train_mae: 1.10254 | valid_mae: 1.10695 |  0:00:13s\n",
            "epoch 16 | loss: 200.44358| train_mae: 1.00646 | valid_mae: 0.94129 |  0:00:14s\n",
            "epoch 17 | loss: 103.08548| train_mae: 0.96372 | valid_mae: 1.02937 |  0:00:15s\n",
            "epoch 18 | loss: 98.9981 | train_mae: 0.85334 | valid_mae: 0.98194 |  0:00:15s\n",
            "epoch 19 | loss: 114.8181| train_mae: 0.99594 | valid_mae: 1.10781 |  0:00:16s\n",
            "epoch 20 | loss: 87.31514| train_mae: 1.09795 | valid_mae: 1.18681 |  0:00:17s\n",
            "epoch 21 | loss: 100.1331| train_mae: 1.04993 | valid_mae: 0.95717 |  0:00:18s\n",
            "epoch 22 | loss: 98.55991| train_mae: 1.16854 | valid_mae: 1.36015 |  0:00:18s\n",
            "epoch 23 | loss: 95.98377| train_mae: 1.09233 | valid_mae: 1.2414  |  0:00:19s\n",
            "epoch 24 | loss: 169.08835| train_mae: 1.07146 | valid_mae: 1.03561 |  0:00:20s\n",
            "epoch 25 | loss: 55.98098| train_mae: 0.84281 | valid_mae: 0.81852 |  0:00:21s\n",
            "epoch 26 | loss: 45.77884| train_mae: 0.76335 | valid_mae: 0.7185  |  0:00:22s\n",
            "epoch 27 | loss: 47.74254| train_mae: 0.68647 | valid_mae: 0.64308 |  0:00:22s\n",
            "epoch 28 | loss: 166.27473| train_mae: 0.66376 | valid_mae: 0.60926 |  0:00:24s\n",
            "epoch 29 | loss: 55.98073| train_mae: 0.75344 | valid_mae: 0.67055 |  0:00:25s\n",
            "epoch 30 | loss: 54.33362| train_mae: 0.68937 | valid_mae: 0.67926 |  0:00:26s\n",
            "epoch 31 | loss: 44.0019 | train_mae: 2.62142 | valid_mae: 1.98371 |  0:00:26s\n",
            "epoch 32 | loss: 31.82132| train_mae: 2.47813 | valid_mae: 2.00757 |  0:00:27s\n",
            "epoch 33 | loss: 37.45953| train_mae: 2.42233 | valid_mae: 2.34052 |  0:00:28s\n",
            "epoch 34 | loss: 49.21881| train_mae: 1.43102 | valid_mae: 1.2432  |  0:00:29s\n",
            "epoch 35 | loss: 56.37186| train_mae: 0.779   | valid_mae: 0.94984 |  0:00:29s\n",
            "epoch 36 | loss: 38.93192| train_mae: 0.56752 | valid_mae: 0.61505 |  0:00:30s\n",
            "epoch 37 | loss: 34.86056| train_mae: 0.44477 | valid_mae: 0.54326 |  0:00:31s\n",
            "epoch 38 | loss: 26.25363| train_mae: 0.26018 | valid_mae: 0.23551 |  0:00:32s\n",
            "epoch 39 | loss: 30.98723| train_mae: 0.24804 | valid_mae: 0.21674 |  0:00:33s\n",
            "epoch 40 | loss: 20.91466| train_mae: 0.30065 | valid_mae: 0.25818 |  0:00:33s\n",
            "epoch 41 | loss: 75.82438| train_mae: 0.22449 | valid_mae: 0.19748 |  0:00:34s\n",
            "epoch 42 | loss: 24.01496| train_mae: 0.21207 | valid_mae: 0.16589 |  0:00:35s\n",
            "epoch 43 | loss: 20.94929| train_mae: 0.18683 | valid_mae: 0.16382 |  0:00:36s\n",
            "epoch 44 | loss: 20.89567| train_mae: 0.17031 | valid_mae: 0.15692 |  0:00:37s\n",
            "epoch 45 | loss: 15.17604| train_mae: 0.16779 | valid_mae: 0.1338  |  0:00:38s\n",
            "epoch 46 | loss: 19.90233| train_mae: 0.14118 | valid_mae: 0.11791 |  0:00:39s\n",
            "epoch 47 | loss: 21.156  | train_mae: 0.15717 | valid_mae: 0.10683 |  0:00:40s\n",
            "epoch 48 | loss: 16.71291| train_mae: 0.15636 | valid_mae: 0.10263 |  0:00:41s\n",
            "epoch 49 | loss: 12.34611| train_mae: 0.13481 | valid_mae: 0.09663 |  0:00:41s\n",
            "epoch 50 | loss: 12.27471| train_mae: 0.1305  | valid_mae: 0.09732 |  0:00:42s\n",
            "epoch 51 | loss: 13.49489| train_mae: 0.14254 | valid_mae: 0.10869 |  0:00:43s\n",
            "epoch 52 | loss: 12.62601| train_mae: 0.13719 | valid_mae: 0.12703 |  0:00:44s\n",
            "epoch 53 | loss: 13.35935| train_mae: 0.12302 | valid_mae: 0.09409 |  0:00:45s\n",
            "epoch 54 | loss: 8.32407 | train_mae: 0.10746 | valid_mae: 0.1062  |  0:00:45s\n",
            "epoch 55 | loss: 12.90123| train_mae: 0.10444 | valid_mae: 0.13819 |  0:00:46s\n",
            "epoch 56 | loss: 6.133   | train_mae: 0.09901 | valid_mae: 0.1018  |  0:00:47s\n",
            "epoch 57 | loss: 8.27313 | train_mae: 0.09417 | valid_mae: 0.09087 |  0:00:48s\n",
            "epoch 58 | loss: 8.01154 | train_mae: 0.0911  | valid_mae: 0.08478 |  0:00:49s\n",
            "epoch 59 | loss: 5.61922 | train_mae: 0.07392 | valid_mae: 0.07591 |  0:00:50s\n",
            "epoch 60 | loss: 7.45371 | train_mae: 0.07478 | valid_mae: 0.07259 |  0:00:51s\n",
            "epoch 61 | loss: 5.56137 | train_mae: 0.07844 | valid_mae: 0.06948 |  0:00:52s\n",
            "epoch 62 | loss: 3.90749 | train_mae: 0.07011 | valid_mae: 0.06167 |  0:00:53s\n",
            "epoch 63 | loss: 3.42319 | train_mae: 0.06709 | valid_mae: 0.0639  |  0:00:53s\n",
            "epoch 64 | loss: 3.63672 | train_mae: 0.0618  | valid_mae: 0.05552 |  0:00:54s\n",
            "epoch 65 | loss: 4.65504 | train_mae: 0.06534 | valid_mae: 0.05454 |  0:00:55s\n",
            "epoch 66 | loss: 3.43672 | train_mae: 0.06008 | valid_mae: 0.0573  |  0:00:56s\n",
            "epoch 67 | loss: 2.69168 | train_mae: 0.05752 | valid_mae: 0.05533 |  0:00:57s\n",
            "epoch 68 | loss: 2.21025 | train_mae: 0.05489 | valid_mae: 0.05019 |  0:00:57s\n",
            "epoch 69 | loss: 2.10003 | train_mae: 0.05667 | valid_mae: 0.05212 |  0:00:58s\n",
            "epoch 70 | loss: 2.00842 | train_mae: 0.0454  | valid_mae: 0.04705 |  0:00:59s\n",
            "epoch 71 | loss: 1.81544 | train_mae: 0.04379 | valid_mae: 0.04621 |  0:01:00s\n",
            "epoch 72 | loss: 1.5179  | train_mae: 0.03727 | valid_mae: 0.0414  |  0:01:01s\n",
            "epoch 73 | loss: 1.44758 | train_mae: 0.04211 | valid_mae: 0.04186 |  0:01:01s\n",
            "epoch 74 | loss: 1.24331 | train_mae: 0.04137 | valid_mae: 0.04182 |  0:01:02s\n",
            "epoch 75 | loss: 1.78086 | train_mae: 0.05679 | valid_mae: 0.0571  |  0:01:04s\n",
            "epoch 76 | loss: 1.21457 | train_mae: 0.04048 | valid_mae: 0.03557 |  0:01:05s\n",
            "epoch 77 | loss: 1.14352 | train_mae: 0.04708 | valid_mae: 0.04914 |  0:01:05s\n",
            "epoch 78 | loss: 1.3536  | train_mae: 0.03637 | valid_mae: 0.03549 |  0:01:06s\n",
            "epoch 79 | loss: 1.15012 | train_mae: 0.03847 | valid_mae: 0.04232 |  0:01:07s\n",
            "epoch 80 | loss: 1.05209 | train_mae: 0.03372 | valid_mae: 0.03675 |  0:01:08s\n",
            "epoch 81 | loss: 1.19871 | train_mae: 0.03425 | valid_mae: 0.03661 |  0:01:09s\n",
            "epoch 82 | loss: 1.10615 | train_mae: 0.03724 | valid_mae: 0.03967 |  0:01:09s\n",
            "epoch 83 | loss: 1.22039 | train_mae: 0.03152 | valid_mae: 0.03481 |  0:01:10s\n",
            "epoch 84 | loss: 1.03148 | train_mae: 0.03614 | valid_mae: 0.03865 |  0:01:11s\n",
            "epoch 85 | loss: 1.12649 | train_mae: 0.03194 | valid_mae: 0.03486 |  0:01:12s\n",
            "epoch 86 | loss: 0.99215 | train_mae: 0.03731 | valid_mae: 0.04008 |  0:01:12s\n",
            "epoch 87 | loss: 1.11097 | train_mae: 0.03571 | valid_mae: 0.03877 |  0:01:13s\n",
            "epoch 88 | loss: 1.15311 | train_mae: 0.04306 | valid_mae: 0.04564 |  0:01:14s\n",
            "epoch 89 | loss: 1.05702 | train_mae: 0.03508 | valid_mae: 0.0381  |  0:01:15s\n",
            "epoch 90 | loss: 1.086   | train_mae: 0.0336  | valid_mae: 0.03762 |  0:01:16s\n",
            "epoch 91 | loss: 0.96096 | train_mae: 0.03661 | valid_mae: 0.04211 |  0:01:17s\n",
            "epoch 92 | loss: 1.03403 | train_mae: 0.03417 | valid_mae: 0.03942 |  0:01:18s\n",
            "epoch 93 | loss: 1.00618 | train_mae: 0.03337 | valid_mae: 0.03959 |  0:01:19s\n",
            "epoch 94 | loss: 0.98087 | train_mae: 0.03718 | valid_mae: 0.04112 |  0:01:20s\n",
            "epoch 95 | loss: 0.94641 | train_mae: 0.03375 | valid_mae: 0.03995 |  0:01:20s\n",
            "epoch 96 | loss: 0.92018 | train_mae: 0.03713 | valid_mae: 0.04201 |  0:01:21s\n",
            "epoch 97 | loss: 1.10184 | train_mae: 0.03351 | valid_mae: 0.04027 |  0:01:22s\n",
            "epoch 98 | loss: 0.83829 | train_mae: 0.03525 | valid_mae: 0.04311 |  0:01:23s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-09-05 01:19:33,350] Trial 14 finished with value: 0.9304667711257935 and parameters: {'n_d': 25, 'n_a': 28, 'n_steps': 4, 'gamma': 1.8567165312031866, 'lambda_sparse': 0.00022304287461612143, 'batch_size': 128, 'mask_type': 'entmax', 'emb': 16, 'momentum': 0.8691797452553163, 'learning_rate': 0.008219963784443196, 'weight_decay': 1.662958391448081e-05, 'scheduler_gamma': 0.987428720158213, 'step_size': 13, 'virtual_batch_size': 64, 'optimizer_type': 'adam', 'p': 0.019094856022891144}. Best is trial 11 with value: 0.04981649555265903.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 99 | loss: 0.93047 | train_mae: 0.03102 | valid_mae: 0.04113 |  0:01:23s\n",
            "Stop training because you reached max_epochs = 100 with best_epoch = 83 and best_valid_mae = 0.03481\n",
            "Best hyperparameters for regression:  {'n_d': 22, 'n_a': 32, 'n_steps': 4, 'gamma': 1.9960936946749759, 'lambda_sparse': 9.103081183863075e-05, 'batch_size': 128, 'mask_type': 'entmax', 'emb': 24, 'momentum': 0.8295284103047583, 'learning_rate': 0.010278433468993582, 'weight_decay': 2.1435996212114308e-05, 'scheduler_gamma': 0.9931143536252859, 'step_size': 15, 'virtual_batch_size': 64, 'optimizer_type': 'rmsprop', 'p': 0.008892842468268852}\n",
            "Best mae:  0.04981649555265903\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_params = par\n",
        "n_d = best_params['n_d']; n_a = best_params['n_a']; n_steps = best_params['n_steps']\n",
        "gamma = best_params['gamma']; lambda_sparse = best_params['lambda_sparse']\n",
        "mask_type = best_params['mask_type']; batch_size = best_params['batch_size']\n",
        "emb = best_params['emb']; p = best_params['p']\n",
        "momentum = best_params['momentum']; learning_rate = best_params['learning_rate']\n",
        "weight_decay = best_params['weight_decay']\n",
        "scheduler_gamma = best_params['scheduler_gamma']; step_size = best_params['step_size']\n",
        "virtual_batch_size = best_params['virtual_batch_size']; optimizer_type = best_params['optimizer_type']\n",
        "\n",
        "# Optimizer config (misma lógica)\n",
        "optimizer_fn, optimizer_params = build_optimizer(optimizer_type, learning_rate, momentum, weight_decay)\n",
        "\n",
        "# Aumento y categóricas\n",
        "aug = RegressionSMOTE(p=p)\n",
        "cat_idxs = [i for i, f in enumerate(features) if f in CATEGORICAL_COLUMNS]\n",
        "cat_dims = [categorical_dims[f] for f in features if f in CATEGORICAL_COLUMNS]\n",
        "cat_emb_dim = [min(emb, (dim + 1)//2) for dim in cat_dims]\n",
        "\n",
        "clf = CustomTabNetRegressor(\n",
        "    cat_dims=cat_dims, cat_emb_dim=cat_emb_dim, cat_idxs=cat_idxs,\n",
        "    n_d=n_d, n_a=n_a, n_steps=n_steps, gamma=gamma, lambda_sparse=lambda_sparse,\n",
        "    mask_type=mask_type, optimizer_fn=optimizer_fn, optimizer_params=optimizer_params,\n",
        "    scheduler_params={\"gamma\": scheduler_gamma, \"step_size\": step_size},\n",
        "    scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
        "    momentum=momentum, verbose=True\n",
        ")\n",
        "\n",
        "clf.fit(\n",
        "    X_train=X_train, y_train=y_train[:,0:1],\n",
        "    eval_set=[(X_train, y_train[:,0:1]), (X_valid, y_valid[:,0:1])],\n",
        "    eval_name=['train', 'valid'], eval_metric=['mae'],\n",
        "    loss_fn=my_r2_score_fn,\n",
        "    max_epochs=200, patience=70,\n",
        "    batch_size=batch_size, virtual_batch_size=virtual_batch_size,\n",
        "    num_workers=1, drop_last=False, augmentations=aug,\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GLUMzpwssHm",
        "outputId": "8e8faae8-3848-47f0-e88c-c3d9409968d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 763.63651| train_mae: 19.09745| valid_mae: 19.47532|  0:00:00s\n",
            "epoch 1  | loss: 362.1544| train_mae: 6.9133  | valid_mae: 6.44513 |  0:00:01s\n",
            "epoch 2  | loss: 77.69032| train_mae: 7.46851 | valid_mae: 7.93065 |  0:00:02s\n",
            "epoch 3  | loss: 44.82242| train_mae: 2.65238 | valid_mae: 2.89799 |  0:00:03s\n",
            "epoch 4  | loss: 10.93726| train_mae: 0.86127 | valid_mae: 0.97705 |  0:00:04s\n",
            "epoch 5  | loss: 2.92119 | train_mae: 0.58636 | valid_mae: 0.61967 |  0:00:05s\n",
            "epoch 6  | loss: 1.4934  | train_mae: 0.16754 | valid_mae: 0.16477 |  0:00:06s\n",
            "epoch 7  | loss: 1.27268 | train_mae: 0.36138 | valid_mae: 0.37754 |  0:00:07s\n",
            "epoch 8  | loss: 1.46065 | train_mae: 0.10056 | valid_mae: 0.10141 |  0:00:07s\n",
            "epoch 9  | loss: 0.9357  | train_mae: 0.12024 | valid_mae: 0.14067 |  0:00:08s\n",
            "epoch 10 | loss: 0.81696 | train_mae: 0.09922 | valid_mae: 0.11409 |  0:00:09s\n",
            "epoch 11 | loss: 0.78948 | train_mae: 0.09124 | valid_mae: 0.09958 |  0:00:10s\n",
            "epoch 12 | loss: 1.00041 | train_mae: 0.09965 | valid_mae: 0.10427 |  0:00:10s\n",
            "epoch 13 | loss: 0.84248 | train_mae: 0.04343 | valid_mae: 0.04384 |  0:00:11s\n",
            "epoch 14 | loss: 0.83122 | train_mae: 0.04696 | valid_mae: 0.05089 |  0:00:12s\n",
            "epoch 15 | loss: 0.6233  | train_mae: 0.07145 | valid_mae: 0.09181 |  0:00:13s\n",
            "epoch 16 | loss: 0.65479 | train_mae: 0.05963 | valid_mae: 0.0667  |  0:00:14s\n",
            "epoch 17 | loss: 0.41225 | train_mae: 0.04812 | valid_mae: 0.06416 |  0:00:15s\n",
            "epoch 18 | loss: 0.77481 | train_mae: 0.03762 | valid_mae: 0.04435 |  0:00:16s\n",
            "epoch 19 | loss: 0.61288 | train_mae: 0.03271 | valid_mae: 0.0378  |  0:00:17s\n",
            "epoch 20 | loss: 0.69069 | train_mae: 0.03863 | valid_mae: 0.04842 |  0:00:18s\n",
            "epoch 21 | loss: 0.52508 | train_mae: 0.02831 | valid_mae: 0.03179 |  0:00:18s\n",
            "epoch 22 | loss: 0.40926 | train_mae: 0.02949 | valid_mae: 0.04477 |  0:00:19s\n",
            "epoch 23 | loss: 0.71225 | train_mae: 0.0268  | valid_mae: 0.0298  |  0:00:20s\n",
            "epoch 24 | loss: 0.42796 | train_mae: 0.02342 | valid_mae: 0.03827 |  0:00:21s\n",
            "epoch 25 | loss: 0.65316 | train_mae: 0.01809 | valid_mae: 0.03069 |  0:00:21s\n",
            "epoch 26 | loss: 0.30457 | train_mae: 0.01975 | valid_mae: 0.02744 |  0:00:22s\n",
            "epoch 27 | loss: 0.27513 | train_mae: 0.02003 | valid_mae: 0.03151 |  0:00:23s\n",
            "epoch 28 | loss: 0.26481 | train_mae: 0.02137 | valid_mae: 0.0337  |  0:00:24s\n",
            "epoch 29 | loss: 0.34148 | train_mae: 0.02082 | valid_mae: 0.02455 |  0:00:25s\n",
            "epoch 30 | loss: 0.29403 | train_mae: 0.01619 | valid_mae: 0.02563 |  0:00:25s\n",
            "epoch 31 | loss: 0.35247 | train_mae: 0.01421 | valid_mae: 0.02242 |  0:00:26s\n",
            "epoch 32 | loss: 0.2428  | train_mae: 0.01588 | valid_mae: 0.0377  |  0:00:27s\n",
            "epoch 33 | loss: 0.22777 | train_mae: 0.01428 | valid_mae: 0.02815 |  0:00:28s\n",
            "epoch 34 | loss: 0.38442 | train_mae: 0.0155  | valid_mae: 0.0275  |  0:00:29s\n",
            "epoch 35 | loss: 0.23167 | train_mae: 0.01239 | valid_mae: 0.02781 |  0:00:30s\n",
            "epoch 36 | loss: 0.17722 | train_mae: 0.01179 | valid_mae: 0.03019 |  0:00:31s\n",
            "epoch 37 | loss: 0.40476 | train_mae: 0.01876 | valid_mae: 0.03451 |  0:00:32s\n",
            "epoch 38 | loss: 0.19431 | train_mae: 0.01446 | valid_mae: 0.02863 |  0:00:32s\n",
            "epoch 39 | loss: 0.23424 | train_mae: 0.01271 | valid_mae: 0.02605 |  0:00:33s\n",
            "epoch 40 | loss: 0.20882 | train_mae: 0.01268 | valid_mae: 0.02653 |  0:00:34s\n",
            "epoch 41 | loss: 0.19975 | train_mae: 0.01492 | valid_mae: 0.02417 |  0:00:35s\n",
            "epoch 42 | loss: 0.16118 | train_mae: 0.01498 | valid_mae: 0.03568 |  0:00:36s\n",
            "epoch 43 | loss: 0.16342 | train_mae: 0.01322 | valid_mae: 0.02677 |  0:00:36s\n",
            "epoch 44 | loss: 0.20627 | train_mae: 0.01008 | valid_mae: 0.02179 |  0:00:37s\n",
            "epoch 45 | loss: 0.12403 | train_mae: 0.01302 | valid_mae: 0.01921 |  0:00:38s\n",
            "epoch 46 | loss: 0.18526 | train_mae: 0.00932 | valid_mae: 0.02074 |  0:00:39s\n",
            "epoch 47 | loss: 0.17668 | train_mae: 0.01107 | valid_mae: 0.0322  |  0:00:39s\n",
            "epoch 48 | loss: 0.15952 | train_mae: 0.01044 | valid_mae: 0.01938 |  0:00:40s\n",
            "epoch 49 | loss: 0.15091 | train_mae: 0.0116  | valid_mae: 0.01777 |  0:00:42s\n",
            "epoch 50 | loss: 0.16909 | train_mae: 0.01128 | valid_mae: 0.01975 |  0:00:43s\n",
            "epoch 51 | loss: 0.26405 | train_mae: 0.01423 | valid_mae: 0.02029 |  0:00:43s\n",
            "epoch 52 | loss: 0.19836 | train_mae: 0.00986 | valid_mae: 0.01871 |  0:00:44s\n",
            "epoch 53 | loss: 0.1448  | train_mae: 0.01059 | valid_mae: 0.02024 |  0:00:45s\n",
            "epoch 54 | loss: 0.11173 | train_mae: 0.00907 | valid_mae: 0.02065 |  0:00:46s\n",
            "epoch 55 | loss: 0.15661 | train_mae: 0.01084 | valid_mae: 0.0186  |  0:00:47s\n",
            "epoch 56 | loss: 0.14735 | train_mae: 0.01637 | valid_mae: 0.02835 |  0:00:47s\n",
            "epoch 57 | loss: 0.1066  | train_mae: 0.00846 | valid_mae: 0.01832 |  0:00:48s\n",
            "epoch 58 | loss: 0.10581 | train_mae: 0.00729 | valid_mae: 0.02008 |  0:00:49s\n",
            "epoch 59 | loss: 0.11948 | train_mae: 0.00836 | valid_mae: 0.01934 |  0:00:50s\n",
            "epoch 60 | loss: 0.07718 | train_mae: 0.00851 | valid_mae: 0.02044 |  0:00:50s\n",
            "epoch 61 | loss: 0.30893 | train_mae: 0.00782 | valid_mae: 0.01656 |  0:00:51s\n",
            "epoch 62 | loss: 0.061   | train_mae: 0.00969 | valid_mae: 0.01793 |  0:00:52s\n",
            "epoch 63 | loss: 0.0827  | train_mae: 0.00616 | valid_mae: 0.01996 |  0:00:53s\n",
            "epoch 64 | loss: 0.04535 | train_mae: 0.00629 | valid_mae: 0.01942 |  0:00:54s\n",
            "epoch 65 | loss: 0.22952 | train_mae: 0.0078  | valid_mae: 0.0178  |  0:00:55s\n",
            "epoch 66 | loss: 0.06615 | train_mae: 0.00601 | valid_mae: 0.01936 |  0:00:56s\n",
            "epoch 67 | loss: 0.08    | train_mae: 0.00561 | valid_mae: 0.01793 |  0:00:57s\n",
            "epoch 68 | loss: 0.05673 | train_mae: 0.00502 | valid_mae: 0.01902 |  0:00:58s\n",
            "epoch 69 | loss: 0.10014 | train_mae: 0.00872 | valid_mae: 0.02735 |  0:00:58s\n",
            "epoch 70 | loss: 0.12948 | train_mae: 0.00964 | valid_mae: 0.01965 |  0:00:59s\n",
            "epoch 71 | loss: 0.05812 | train_mae: 0.00685 | valid_mae: 0.01887 |  0:01:00s\n",
            "epoch 72 | loss: 0.13869 | train_mae: 0.00597 | valid_mae: 0.01973 |  0:01:01s\n",
            "epoch 73 | loss: 0.07667 | train_mae: 0.00849 | valid_mae: 0.01835 |  0:01:01s\n",
            "epoch 74 | loss: 0.08111 | train_mae: 0.00552 | valid_mae: 0.01798 |  0:01:02s\n",
            "epoch 75 | loss: 0.02946 | train_mae: 0.00523 | valid_mae: 0.01934 |  0:01:03s\n",
            "epoch 76 | loss: 0.10723 | train_mae: 0.006   | valid_mae: 0.01794 |  0:01:04s\n",
            "epoch 77 | loss: 0.10796 | train_mae: 0.00563 | valid_mae: 0.02002 |  0:01:04s\n",
            "epoch 78 | loss: 0.07145 | train_mae: 0.00864 | valid_mae: 0.02026 |  0:01:05s\n",
            "epoch 79 | loss: 0.16449 | train_mae: 0.00983 | valid_mae: 0.02474 |  0:01:06s\n",
            "epoch 80 | loss: 0.08496 | train_mae: 0.00756 | valid_mae: 0.01997 |  0:01:07s\n",
            "epoch 81 | loss: 0.05575 | train_mae: 0.00826 | valid_mae: 0.02385 |  0:01:08s\n",
            "epoch 82 | loss: 0.11755 | train_mae: 0.00548 | valid_mae: 0.02246 |  0:01:09s\n",
            "epoch 83 | loss: 0.04308 | train_mae: 0.01337 | valid_mae: 0.02662 |  0:01:10s\n",
            "epoch 84 | loss: 0.04979 | train_mae: 0.00679 | valid_mae: 0.02133 |  0:01:11s\n",
            "epoch 85 | loss: 0.15538 | train_mae: 0.01067 | valid_mae: 0.02441 |  0:01:11s\n",
            "epoch 86 | loss: 0.09455 | train_mae: 0.00781 | valid_mae: 0.02006 |  0:01:12s\n",
            "epoch 87 | loss: 0.17434 | train_mae: 0.00758 | valid_mae: 0.02009 |  0:01:13s\n",
            "epoch 88 | loss: 0.09492 | train_mae: 0.00731 | valid_mae: 0.02112 |  0:01:14s\n",
            "epoch 89 | loss: 0.04956 | train_mae: 0.00661 | valid_mae: 0.02125 |  0:01:14s\n",
            "epoch 90 | loss: 0.0468  | train_mae: 0.0065  | valid_mae: 0.01944 |  0:01:15s\n",
            "epoch 91 | loss: 0.04353 | train_mae: 0.00758 | valid_mae: 0.02485 |  0:01:16s\n",
            "epoch 92 | loss: 0.04889 | train_mae: 0.00498 | valid_mae: 0.02254 |  0:01:17s\n",
            "epoch 93 | loss: 0.04226 | train_mae: 0.00581 | valid_mae: 0.02036 |  0:01:18s\n",
            "epoch 94 | loss: 0.0656  | train_mae: 0.00736 | valid_mae: 0.02106 |  0:01:18s\n",
            "epoch 95 | loss: 0.07093 | train_mae: 0.00647 | valid_mae: 0.02024 |  0:01:19s\n",
            "epoch 96 | loss: 0.057   | train_mae: 0.00647 | valid_mae: 0.02424 |  0:01:20s\n",
            "epoch 97 | loss: 0.04259 | train_mae: 0.00503 | valid_mae: 0.02296 |  0:01:21s\n",
            "epoch 98 | loss: 0.03637 | train_mae: 0.00529 | valid_mae: 0.02018 |  0:01:22s\n",
            "epoch 99 | loss: 0.01768 | train_mae: 0.00452 | valid_mae: 0.01972 |  0:01:23s\n",
            "epoch 100| loss: 0.04205 | train_mae: 0.00463 | valid_mae: 0.02009 |  0:01:24s\n",
            "epoch 101| loss: 0.05948 | train_mae: 0.00587 | valid_mae: 0.02193 |  0:01:25s\n",
            "epoch 102| loss: 0.06107 | train_mae: 0.00912 | valid_mae: 0.02726 |  0:01:25s\n",
            "epoch 103| loss: 0.03453 | train_mae: 0.00768 | valid_mae: 0.02152 |  0:01:26s\n",
            "epoch 104| loss: 0.03666 | train_mae: 0.00422 | valid_mae: 0.01979 |  0:01:27s\n",
            "epoch 105| loss: 0.04511 | train_mae: 0.0044  | valid_mae: 0.02197 |  0:01:28s\n",
            "epoch 106| loss: 0.08732 | train_mae: 0.00677 | valid_mae: 0.02317 |  0:01:28s\n",
            "epoch 107| loss: 0.07187 | train_mae: 0.00677 | valid_mae: 0.02245 |  0:01:29s\n",
            "epoch 108| loss: 0.0414  | train_mae: 0.00525 | valid_mae: 0.02221 |  0:01:30s\n",
            "epoch 109| loss: 0.02404 | train_mae: 0.00552 | valid_mae: 0.02232 |  0:01:31s\n",
            "epoch 110| loss: 0.03638 | train_mae: 0.0048  | valid_mae: 0.02195 |  0:01:31s\n",
            "epoch 111| loss: 0.07067 | train_mae: 0.00518 | valid_mae: 0.02164 |  0:01:32s\n",
            "epoch 112| loss: 0.04321 | train_mae: 0.00478 | valid_mae: 0.0223  |  0:01:34s\n",
            "epoch 113| loss: 0.0421  | train_mae: 0.00601 | valid_mae: 0.02442 |  0:01:35s\n",
            "epoch 114| loss: 0.06552 | train_mae: 0.00558 | valid_mae: 0.02178 |  0:01:35s\n",
            "epoch 115| loss: 0.03574 | train_mae: 0.0076  | valid_mae: 0.02285 |  0:01:36s\n",
            "epoch 116| loss: 0.04113 | train_mae: 0.00665 | valid_mae: 0.02186 |  0:01:37s\n",
            "epoch 117| loss: 0.05958 | train_mae: 0.00682 | valid_mae: 0.02247 |  0:01:38s\n",
            "epoch 118| loss: 0.05673 | train_mae: 0.00612 | valid_mae: 0.02094 |  0:01:38s\n",
            "epoch 119| loss: 0.03315 | train_mae: 0.00458 | valid_mae: 0.0216  |  0:01:39s\n",
            "epoch 120| loss: 0.04199 | train_mae: 0.00557 | valid_mae: 0.02211 |  0:01:40s\n",
            "epoch 121| loss: 0.04738 | train_mae: 0.00549 | valid_mae: 0.02481 |  0:01:41s\n",
            "epoch 122| loss: 0.0339  | train_mae: 0.00609 | valid_mae: 0.02269 |  0:01:42s\n",
            "epoch 123| loss: 0.03722 | train_mae: 0.00483 | valid_mae: 0.02276 |  0:01:42s\n",
            "epoch 124| loss: 0.04967 | train_mae: 0.00632 | valid_mae: 0.0238  |  0:01:43s\n",
            "epoch 125| loss: 0.02955 | train_mae: 0.00527 | valid_mae: 0.02062 |  0:01:44s\n",
            "epoch 126| loss: 0.02481 | train_mae: 0.00855 | valid_mae: 0.02585 |  0:01:45s\n",
            "epoch 127| loss: 0.04156 | train_mae: 0.00534 | valid_mae: 0.02411 |  0:01:46s\n",
            "epoch 128| loss: 0.02029 | train_mae: 0.00599 | valid_mae: 0.02314 |  0:01:47s\n",
            "epoch 129| loss: 0.0258  | train_mae: 0.00594 | valid_mae: 0.02173 |  0:01:48s\n",
            "epoch 130| loss: 0.01741 | train_mae: 0.00695 | valid_mae: 0.02266 |  0:01:49s\n",
            "epoch 131| loss: 0.03715 | train_mae: 0.0046  | valid_mae: 0.0227  |  0:01:49s\n",
            "\n",
            "Early stopping occurred at epoch 131 with best_epoch = 61 and best_valid_mae = 0.01656\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=clf.predict(X_test)\n",
        "y_pred_ = scaler.inverse_transform(y_pred_)\n",
        "y_test_ = scaler.inverse_transform(y_test)\n",
        "# Plot 2\n",
        "r2_1 = r2_score(y_test, y_pred)\n",
        "print(f\" Test  -> R2={r2_1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49vwjYP97UpK",
        "outputId": "5b310d70-c834-4287-aa76-a0f076f89e6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Test  -> R2=0.3872\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "idx_500 = pick_new_indices(n_new=500, seed=123)\n",
        "X_500 = X[idx_500]; y_500 = y[idx_500]\n",
        "\n",
        "# Particiona los 500 nuevos: train/valid/test\n",
        "splits_500 = split_subset(X_500, y_500, df_labels=None, n_sub=X_500.shape[0], test_size=0.20, seed=123)\n",
        "X500_tr, X500_va, X500_te = splits_500[\"X_train\"], splits_500[\"X_valid\"], splits_500[\"X_test\"]\n",
        "y500_tr, y500_va, y500_te = splits_500[\"y_train\"], splits_500[\"y_valid\"], splits_500[\"y_test\"]\n",
        "\n",
        "model_init_kwargs = dict(\n",
        "    cat_dims=cat_dims,\n",
        "    cat_emb_dim=cat_emb_dim,\n",
        "    cat_idxs=cat_idxs,\n",
        "    n_d=n_d, n_a=n_a, n_steps=n_steps,\n",
        "    gamma=gamma, lambda_sparse=lambda_sparse,\n",
        "    mask_type=mask_type,\n",
        "    optimizer_fn=optimizer_fn,\n",
        "    optimizer_params=optimizer_params,\n",
        "    scheduler_params={\"gamma\": scheduler_gamma, \"step_size\": step_size},\n",
        "    scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
        "    momentum=momentum,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "results = run_three_training_strategies(\n",
        "    clf_base=clf,\n",
        "    model_init_kwargs=model_init_kwargs,\n",
        "    X_train_old=X_train, y_train_old=y_train[:,0:1],\n",
        "    X_test_old=X_test,  y_test_old=y_test[:,0:1],   # scaler de Fase 1\n",
        "    X_tr_new=X500_tr,   y_tr_new=y500_tr[:,0:1],\n",
        "    X_va_new=X500_va,   y_va_new=y500_va[:,0:1],\n",
        "    X_te_new=X500_te,   y_te_new=y500_te[:,0:1],  # scaler de Fase 2\n",
        "    batch_size=batch_size, virtual_batch_size=virtual_batch_size, aug=aug\n",
        ")\n",
        "\n",
        "print(\"\\n==== RESUMEN R² ====\")\n",
        "for k, v in results.items():\n",
        "    print(k, \"->\", {m: round(s, 4) for m, s in v.items() if m.startswith(\"R2_\")})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJ8qvtlNYuMA",
        "outputId": "927fb882-8389-4d07-a942-9b7ec8fdbc4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Originales (conservados): (166323, 312) (166323, 1)\n",
            "Subset de 500: (500, 312) (500, 1)\n",
            "Train/Valid/Test: (320, 312) (80, 312) (100, 312)\n",
            "Distribución clases subset: Counter({np.int64(2): 167, np.int64(0): 167, np.int64(1): 166})\n",
            "epoch 0  | loss: 613.21956| train_inc_mae: 9.71795 | valid_new_mae: 11.12282|  0:00:00s\n",
            "epoch 1  | loss: 89.91247| train_inc_mae: 3.28997 | valid_new_mae: 2.85211 |  0:00:01s\n",
            "epoch 2  | loss: 9.99063 | train_inc_mae: 0.53228 | valid_new_mae: 0.46861 |  0:00:02s\n",
            "epoch 3  | loss: 1.63203 | train_inc_mae: 0.46675 | valid_new_mae: 0.41983 |  0:00:03s\n",
            "epoch 4  | loss: 1.51299 | train_inc_mae: 0.23188 | valid_new_mae: 0.21494 |  0:00:04s\n",
            "epoch 5  | loss: 1.49229 | train_inc_mae: 0.12032 | valid_new_mae: 0.10224 |  0:00:05s\n",
            "epoch 6  | loss: 1.08564 | train_inc_mae: 0.11613 | valid_new_mae: 0.10851 |  0:00:07s\n",
            "epoch 7  | loss: 1.17925 | train_inc_mae: 0.12669 | valid_new_mae: 0.11157 |  0:00:08s\n",
            "epoch 8  | loss: 1.07953 | train_inc_mae: 0.09194 | valid_new_mae: 0.07461 |  0:00:09s\n",
            "epoch 9  | loss: 1.0248  | train_inc_mae: 0.1004  | valid_new_mae: 0.08278 |  0:00:10s\n",
            "epoch 10 | loss: 0.9256  | train_inc_mae: 0.05493 | valid_new_mae: 0.04237 |  0:00:11s\n",
            "epoch 11 | loss: 1.06056 | train_inc_mae: 0.03711 | valid_new_mae: 0.02141 |  0:00:12s\n",
            "epoch 12 | loss: 0.9585  | train_inc_mae: 0.03693 | valid_new_mae: 0.0236  |  0:00:13s\n",
            "epoch 13 | loss: 0.74668 | train_inc_mae: 0.03898 | valid_new_mae: 0.03102 |  0:00:14s\n",
            "epoch 14 | loss: 0.91238 | train_inc_mae: 0.03277 | valid_new_mae: 0.02357 |  0:00:14s\n",
            "epoch 15 | loss: 0.99974 | train_inc_mae: 0.06038 | valid_new_mae: 0.05116 |  0:00:15s\n",
            "epoch 16 | loss: 0.74236 | train_inc_mae: 0.0253  | valid_new_mae: 0.01748 |  0:00:16s\n",
            "epoch 17 | loss: 1.38807 | train_inc_mae: 0.02905 | valid_new_mae: 0.02859 |  0:00:17s\n",
            "epoch 18 | loss: 0.55124 | train_inc_mae: 0.02083 | valid_new_mae: 0.01406 |  0:00:18s\n",
            "epoch 19 | loss: 0.66246 | train_inc_mae: 0.01974 | valid_new_mae: 0.01539 |  0:00:20s\n",
            "epoch 20 | loss: 0.74891 | train_inc_mae: 0.02463 | valid_new_mae: 0.01993 |  0:00:21s\n",
            "epoch 21 | loss: 0.48007 | train_inc_mae: 0.02173 | valid_new_mae: 0.01891 |  0:00:22s\n",
            "epoch 22 | loss: 0.56784 | train_inc_mae: 0.02373 | valid_new_mae: 0.01897 |  0:00:23s\n",
            "epoch 23 | loss: 0.41169 | train_inc_mae: 0.02731 | valid_new_mae: 0.01889 |  0:00:24s\n",
            "epoch 24 | loss: 0.37681 | train_inc_mae: 0.01888 | valid_new_mae: 0.01171 |  0:00:25s\n",
            "epoch 25 | loss: 0.55156 | train_inc_mae: 0.01911 | valid_new_mae: 0.01337 |  0:00:26s\n",
            "epoch 26 | loss: 0.41708 | train_inc_mae: 0.01888 | valid_new_mae: 0.01369 |  0:00:26s\n",
            "epoch 27 | loss: 0.98862 | train_inc_mae: 0.02372 | valid_new_mae: 0.02173 |  0:00:27s\n",
            "epoch 28 | loss: 0.48094 | train_inc_mae: 0.01914 | valid_new_mae: 0.01639 |  0:00:28s\n",
            "epoch 29 | loss: 0.42259 | train_inc_mae: 0.01647 | valid_new_mae: 0.01009 |  0:00:29s\n",
            "epoch 30 | loss: 0.32666 | train_inc_mae: 0.01772 | valid_new_mae: 0.00849 |  0:00:30s\n",
            "epoch 31 | loss: 0.39241 | train_inc_mae: 0.01387 | valid_new_mae: 0.00919 |  0:00:31s\n",
            "epoch 32 | loss: 0.43679 | train_inc_mae: 0.01471 | valid_new_mae: 0.0135  |  0:00:33s\n",
            "epoch 33 | loss: 0.40744 | train_inc_mae: 0.01376 | valid_new_mae: 0.01134 |  0:00:34s\n",
            "epoch 34 | loss: 0.74743 | train_inc_mae: 0.01933 | valid_new_mae: 0.01298 |  0:00:35s\n",
            "epoch 35 | loss: 0.49282 | train_inc_mae: 0.0155  | valid_new_mae: 0.00722 |  0:00:36s\n",
            "epoch 36 | loss: 0.76939 | train_inc_mae: 0.01908 | valid_new_mae: 0.01232 |  0:00:37s\n",
            "epoch 37 | loss: 0.77066 | train_inc_mae: 0.014   | valid_new_mae: 0.00827 |  0:00:37s\n",
            "epoch 38 | loss: 0.43286 | train_inc_mae: 0.01669 | valid_new_mae: 0.00894 |  0:00:38s\n",
            "epoch 39 | loss: 0.21647 | train_inc_mae: 0.01291 | valid_new_mae: 0.00806 |  0:00:39s\n",
            "epoch 40 | loss: 0.18574 | train_inc_mae: 0.01238 | valid_new_mae: 0.00736 |  0:00:40s\n",
            "epoch 41 | loss: 0.24476 | train_inc_mae: 0.01249 | valid_new_mae: 0.00775 |  0:00:41s\n",
            "epoch 42 | loss: 0.14513 | train_inc_mae: 0.01207 | valid_new_mae: 0.00954 |  0:00:42s\n",
            "epoch 43 | loss: 0.23489 | train_inc_mae: 0.01504 | valid_new_mae: 0.00663 |  0:00:43s\n",
            "epoch 44 | loss: 0.18658 | train_inc_mae: 0.01406 | valid_new_mae: 0.01519 |  0:00:44s\n",
            "epoch 45 | loss: 0.19391 | train_inc_mae: 0.01131 | valid_new_mae: 0.0062  |  0:00:45s\n",
            "epoch 46 | loss: 0.22153 | train_inc_mae: 0.01038 | valid_new_mae: 0.00703 |  0:00:47s\n",
            "epoch 47 | loss: 0.47414 | train_inc_mae: 0.01209 | valid_new_mae: 0.00592 |  0:00:48s\n",
            "epoch 48 | loss: 0.15198 | train_inc_mae: 0.01294 | valid_new_mae: 0.00867 |  0:00:49s\n",
            "epoch 49 | loss: 0.19073 | train_inc_mae: 0.01448 | valid_new_mae: 0.01451 |  0:00:49s\n",
            "epoch 50 | loss: 0.22709 | train_inc_mae: 0.01183 | valid_new_mae: 0.00975 |  0:00:50s\n",
            "epoch 51 | loss: 0.27605 | train_inc_mae: 0.0166  | valid_new_mae: 0.01319 |  0:00:51s\n",
            "epoch 52 | loss: 0.163   | train_inc_mae: 0.0117  | valid_new_mae: 0.00703 |  0:00:52s\n",
            "epoch 53 | loss: 0.1687  | train_inc_mae: 0.01377 | valid_new_mae: 0.01223 |  0:00:53s\n",
            "epoch 54 | loss: 0.15992 | train_inc_mae: 0.01396 | valid_new_mae: 0.00838 |  0:00:54s\n",
            "epoch 55 | loss: 0.17078 | train_inc_mae: 0.013   | valid_new_mae: 0.00795 |  0:00:55s\n",
            "epoch 56 | loss: 0.17427 | train_inc_mae: 0.01341 | valid_new_mae: 0.00909 |  0:00:56s\n",
            "epoch 57 | loss: 0.1408  | train_inc_mae: 0.01105 | valid_new_mae: 0.00714 |  0:00:57s\n",
            "epoch 58 | loss: 0.15988 | train_inc_mae: 0.01049 | valid_new_mae: 0.0058  |  0:00:58s\n",
            "epoch 59 | loss: 0.16104 | train_inc_mae: 0.01211 | valid_new_mae: 0.00792 |  0:01:00s\n",
            "epoch 60 | loss: 0.1385  | train_inc_mae: 0.01201 | valid_new_mae: 0.00431 |  0:01:00s\n",
            "epoch 61 | loss: 0.105   | train_inc_mae: 0.01048 | valid_new_mae: 0.00544 |  0:01:01s\n",
            "epoch 62 | loss: 0.0708  | train_inc_mae: 0.01334 | valid_new_mae: 0.00847 |  0:01:02s\n",
            "epoch 63 | loss: 0.11222 | train_inc_mae: 0.01234 | valid_new_mae: 0.00551 |  0:01:03s\n",
            "epoch 64 | loss: 0.08154 | train_inc_mae: 0.01089 | valid_new_mae: 0.00835 |  0:01:04s\n",
            "epoch 65 | loss: 0.09676 | train_inc_mae: 0.01054 | valid_new_mae: 0.00886 |  0:01:05s\n",
            "epoch 66 | loss: 0.08688 | train_inc_mae: 0.01106 | valid_new_mae: 0.00781 |  0:01:06s\n",
            "epoch 67 | loss: 0.07014 | train_inc_mae: 0.0111  | valid_new_mae: 0.00797 |  0:01:07s\n",
            "epoch 68 | loss: 0.14144 | train_inc_mae: 0.00916 | valid_new_mae: 0.0047  |  0:01:08s\n",
            "epoch 69 | loss: 0.12123 | train_inc_mae: 0.01191 | valid_new_mae: 0.00951 |  0:01:09s\n",
            "epoch 70 | loss: 0.11781 | train_inc_mae: 0.00969 | valid_new_mae: 0.00687 |  0:01:10s\n",
            "epoch 71 | loss: 0.14031 | train_inc_mae: 0.01415 | valid_new_mae: 0.01057 |  0:01:11s\n",
            "epoch 72 | loss: 0.1264  | train_inc_mae: 0.04751 | valid_new_mae: 0.04699 |  0:01:13s\n",
            "epoch 73 | loss: 0.14802 | train_inc_mae: 0.01366 | valid_new_mae: 0.01201 |  0:01:14s\n",
            "epoch 74 | loss: 0.10127 | train_inc_mae: 0.00892 | valid_new_mae: 0.00805 |  0:01:14s\n",
            "epoch 75 | loss: 0.10769 | train_inc_mae: 0.00911 | valid_new_mae: 0.00537 |  0:01:15s\n",
            "epoch 76 | loss: 0.0981  | train_inc_mae: 0.0286  | valid_new_mae: 0.01818 |  0:01:16s\n",
            "epoch 77 | loss: 0.10304 | train_inc_mae: 0.01123 | valid_new_mae: 0.00636 |  0:01:17s\n",
            "epoch 78 | loss: 0.17908 | train_inc_mae: 0.01205 | valid_new_mae: 0.00702 |  0:01:18s\n",
            "epoch 79 | loss: 0.13684 | train_inc_mae: 0.01262 | valid_new_mae: 0.00664 |  0:01:19s\n",
            "epoch 80 | loss: 0.10542 | train_inc_mae: 0.01318 | valid_new_mae: 0.00933 |  0:01:20s\n",
            "epoch 81 | loss: 0.09721 | train_inc_mae: 0.01063 | valid_new_mae: 0.00677 |  0:01:21s\n",
            "epoch 82 | loss: 0.08707 | train_inc_mae: 0.01026 | valid_new_mae: 0.0087  |  0:01:22s\n",
            "epoch 83 | loss: 0.04795 | train_inc_mae: 0.009   | valid_new_mae: 0.0079  |  0:01:23s\n",
            "epoch 84 | loss: 0.08233 | train_inc_mae: 0.00932 | valid_new_mae: 0.00689 |  0:01:24s\n",
            "epoch 85 | loss: 0.05279 | train_inc_mae: 0.01194 | valid_new_mae: 0.00845 |  0:01:25s\n",
            "epoch 86 | loss: 0.07604 | train_inc_mae: 0.00973 | valid_new_mae: 0.00948 |  0:01:26s\n",
            "epoch 87 | loss: 0.057   | train_inc_mae: 0.01148 | valid_new_mae: 0.00525 |  0:01:27s\n",
            "epoch 88 | loss: 0.08101 | train_inc_mae: 0.01007 | valid_new_mae: 0.00763 |  0:01:28s\n",
            "epoch 89 | loss: 0.08105 | train_inc_mae: 0.01134 | valid_new_mae: 0.00567 |  0:01:29s\n",
            "epoch 90 | loss: 0.08286 | train_inc_mae: 0.00924 | valid_new_mae: 0.00577 |  0:01:30s\n",
            "epoch 91 | loss: 0.10293 | train_inc_mae: 0.011   | valid_new_mae: 0.00663 |  0:01:31s\n",
            "epoch 92 | loss: 0.05492 | train_inc_mae: 0.01006 | valid_new_mae: 0.00702 |  0:01:32s\n",
            "epoch 93 | loss: 0.07308 | train_inc_mae: 0.00833 | valid_new_mae: 0.00518 |  0:01:33s\n",
            "epoch 94 | loss: 0.04679 | train_inc_mae: 0.01061 | valid_new_mae: 0.00576 |  0:01:34s\n",
            "epoch 95 | loss: 0.07722 | train_inc_mae: 0.00996 | valid_new_mae: 0.00685 |  0:01:35s\n",
            "epoch 96 | loss: 0.08128 | train_inc_mae: 0.00772 | valid_new_mae: 0.00593 |  0:01:36s\n",
            "epoch 97 | loss: 0.0792  | train_inc_mae: 0.01128 | valid_new_mae: 0.00523 |  0:01:37s\n",
            "epoch 98 | loss: 0.07669 | train_inc_mae: 0.00971 | valid_new_mae: 0.00992 |  0:01:38s\n",
            "epoch 99 | loss: 0.09117 | train_inc_mae: 0.01292 | valid_new_mae: 0.01056 |  0:01:39s\n",
            "epoch 100| loss: 0.10531 | train_inc_mae: 0.0104  | valid_new_mae: 0.00842 |  0:01:40s\n",
            "epoch 101| loss: 0.26047 | train_inc_mae: 0.01582 | valid_new_mae: 0.00702 |  0:01:41s\n",
            "epoch 102| loss: 0.1549  | train_inc_mae: 0.01009 | valid_new_mae: 0.00526 |  0:01:42s\n",
            "epoch 103| loss: 0.1292  | train_inc_mae: 0.01358 | valid_new_mae: 0.00816 |  0:01:44s\n",
            "epoch 104| loss: 0.09493 | train_inc_mae: 0.01346 | valid_new_mae: 0.00694 |  0:01:45s\n",
            "epoch 105| loss: 0.086   | train_inc_mae: 0.01064 | valid_new_mae: 0.00888 |  0:01:46s\n",
            "epoch 106| loss: 0.11916 | train_inc_mae: 0.0142  | valid_new_mae: 0.00856 |  0:01:47s\n",
            "epoch 107| loss: 0.05061 | train_inc_mae: 0.01341 | valid_new_mae: 0.00556 |  0:01:48s\n",
            "epoch 108| loss: 0.06381 | train_inc_mae: 0.01315 | valid_new_mae: 0.00763 |  0:01:48s\n",
            "epoch 109| loss: 0.04642 | train_inc_mae: 0.00968 | valid_new_mae: 0.00849 |  0:01:50s\n",
            "epoch 110| loss: 0.13185 | train_inc_mae: 0.01379 | valid_new_mae: 0.00624 |  0:01:51s\n",
            "epoch 111| loss: 0.07571 | train_inc_mae: 0.01055 | valid_new_mae: 0.00655 |  0:01:52s\n",
            "epoch 112| loss: 0.11995 | train_inc_mae: 0.01047 | valid_new_mae: 0.00532 |  0:01:53s\n",
            "epoch 113| loss: 0.04146 | train_inc_mae: 0.00809 | valid_new_mae: 0.00679 |  0:01:54s\n",
            "epoch 114| loss: 0.07384 | train_inc_mae: 0.00995 | valid_new_mae: 0.00518 |  0:01:55s\n",
            "epoch 115| loss: 0.0378  | train_inc_mae: 0.00873 | valid_new_mae: 0.00536 |  0:01:56s\n",
            "epoch 116| loss: 0.02815 | train_inc_mae: 0.00613 | valid_new_mae: 0.0061  |  0:01:57s\n",
            "epoch 117| loss: 0.03875 | train_inc_mae: 0.00923 | valid_new_mae: 0.00522 |  0:01:58s\n",
            "epoch 118| loss: 0.06901 | train_inc_mae: 0.0081  | valid_new_mae: 0.0056  |  0:01:59s\n",
            "epoch 119| loss: 0.0906  | train_inc_mae: 0.00739 | valid_new_mae: 0.00593 |  0:02:00s\n",
            "epoch 120| loss: 0.07436 | train_inc_mae: 0.006   | valid_new_mae: 0.00548 |  0:02:01s\n",
            "epoch 121| loss: 0.07045 | train_inc_mae: 0.01298 | valid_new_mae: 0.00642 |  0:02:02s\n",
            "epoch 122| loss: 0.04649 | train_inc_mae: 0.01029 | valid_new_mae: 0.00598 |  0:02:03s\n",
            "epoch 123| loss: 0.04347 | train_inc_mae: 0.00959 | valid_new_mae: 0.00603 |  0:02:05s\n",
            "epoch 124| loss: 0.07443 | train_inc_mae: 0.01196 | valid_new_mae: 0.01102 |  0:02:06s\n",
            "epoch 125| loss: 0.09126 | train_inc_mae: 0.01001 | valid_new_mae: 0.00543 |  0:02:07s\n",
            "epoch 126| loss: 0.0631  | train_inc_mae: 0.01126 | valid_new_mae: 0.00589 |  0:02:08s\n",
            "epoch 127| loss: 0.08281 | train_inc_mae: 0.00927 | valid_new_mae: 0.0058  |  0:02:09s\n",
            "epoch 128| loss: 0.0777  | train_inc_mae: 0.00681 | valid_new_mae: 0.00606 |  0:02:10s\n",
            "epoch 129| loss: 0.03553 | train_inc_mae: 0.00603 | valid_new_mae: 0.00684 |  0:02:10s\n",
            "epoch 130| loss: 0.04516 | train_inc_mae: 0.00819 | valid_new_mae: 0.00708 |  0:02:11s\n",
            "\n",
            "Early stopping occurred at epoch 130 with best_epoch = 60 and best_valid_new_mae = 0.00431\n",
            "\n",
            "== Desempeño: Fine-tuning incremental ==\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test viejo (FT incremental): R2=0.1122\n",
            "Test nuevo (FT incremental): R2=-0.0299\n",
            "epoch 0  | loss: 1674.94182| train_new_mae: 32.04255| valid_new_mae: 30.77536|  0:00:00s\n",
            "epoch 1  | loss: 1118.39608| train_new_mae: 19.47298| valid_new_mae: 22.34271|  0:00:01s\n",
            "epoch 2  | loss: 616.9921| train_new_mae: 13.46709| valid_new_mae: 13.85922|  0:00:02s\n",
            "epoch 3  | loss: 166.62719| train_new_mae: 10.88064| valid_new_mae: 12.81067|  0:00:03s\n",
            "epoch 4  | loss: 62.58223| train_new_mae: 4.89827 | valid_new_mae: 5.04225 |  0:00:04s\n",
            "epoch 5  | loss: 32.77687| train_new_mae: 1.55363 | valid_new_mae: 1.58671 |  0:00:04s\n",
            "epoch 6  | loss: 15.80835| train_new_mae: 0.87866 | valid_new_mae: 0.75586 |  0:00:05s\n",
            "epoch 7  | loss: 4.64856 | train_new_mae: 0.43415 | valid_new_mae: 0.45816 |  0:00:06s\n",
            "epoch 8  | loss: 6.78723 | train_new_mae: 0.29237 | valid_new_mae: 0.20643 |  0:00:06s\n",
            "epoch 9  | loss: 4.30166 | train_new_mae: 0.14949 | valid_new_mae: 0.12547 |  0:00:07s\n",
            "epoch 10 | loss: 1.53454 | train_new_mae: 0.15061 | valid_new_mae: 0.13337 |  0:00:08s\n",
            "epoch 11 | loss: 4.08511 | train_new_mae: 0.207   | valid_new_mae: 0.14096 |  0:00:08s\n",
            "epoch 12 | loss: 6.44478 | train_new_mae: 0.29214 | valid_new_mae: 0.30963 |  0:00:09s\n",
            "epoch 13 | loss: 1.26091 | train_new_mae: 0.13321 | valid_new_mae: 0.15158 |  0:00:09s\n",
            "epoch 14 | loss: 1.43701 | train_new_mae: 0.08342 | valid_new_mae: 0.08825 |  0:00:10s\n",
            "epoch 15 | loss: 1.56094 | train_new_mae: 0.06715 | valid_new_mae: 0.05755 |  0:00:11s\n",
            "epoch 16 | loss: 0.93883 | train_new_mae: 0.06759 | valid_new_mae: 0.05512 |  0:00:11s\n",
            "epoch 17 | loss: 1.27265 | train_new_mae: 0.05709 | valid_new_mae: 0.03634 |  0:00:12s\n",
            "epoch 18 | loss: 1.27165 | train_new_mae: 0.08456 | valid_new_mae: 0.08651 |  0:00:13s\n",
            "epoch 19 | loss: 1.05641 | train_new_mae: 0.05636 | valid_new_mae: 0.05141 |  0:00:14s\n",
            "epoch 20 | loss: 1.53778 | train_new_mae: 0.16561 | valid_new_mae: 0.19101 |  0:00:15s\n",
            "epoch 21 | loss: 1.08668 | train_new_mae: 0.11582 | valid_new_mae: 0.12243 |  0:00:15s\n",
            "epoch 22 | loss: 1.11302 | train_new_mae: 0.07752 | valid_new_mae: 0.08462 |  0:00:16s\n",
            "epoch 23 | loss: 0.96302 | train_new_mae: 0.03697 | valid_new_mae: 0.02352 |  0:00:17s\n",
            "epoch 24 | loss: 2.74313 | train_new_mae: 0.09171 | valid_new_mae: 0.08846 |  0:00:17s\n",
            "epoch 25 | loss: 1.04423 | train_new_mae: 0.14529 | valid_new_mae: 0.15089 |  0:00:18s\n",
            "epoch 26 | loss: 0.95539 | train_new_mae: 0.11364 | valid_new_mae: 0.13535 |  0:00:19s\n",
            "epoch 27 | loss: 0.9678  | train_new_mae: 0.05098 | valid_new_mae: 0.04239 |  0:00:19s\n",
            "epoch 28 | loss: 0.84155 | train_new_mae: 0.04395 | valid_new_mae: 0.03286 |  0:00:20s\n",
            "epoch 29 | loss: 0.91359 | train_new_mae: 0.04661 | valid_new_mae: 0.03821 |  0:00:21s\n",
            "epoch 30 | loss: 0.49704 | train_new_mae: 0.09805 | valid_new_mae: 0.08803 |  0:00:21s\n",
            "epoch 31 | loss: 0.35228 | train_new_mae: 0.04631 | valid_new_mae: 0.0346  |  0:00:22s\n",
            "epoch 32 | loss: 2.16899 | train_new_mae: 0.02452 | valid_new_mae: 0.01374 |  0:00:23s\n",
            "epoch 33 | loss: 0.86587 | train_new_mae: 0.02847 | valid_new_mae: 0.0157  |  0:00:23s\n",
            "epoch 34 | loss: 0.85985 | train_new_mae: 0.02486 | valid_new_mae: 0.01605 |  0:00:24s\n",
            "epoch 35 | loss: 1.29504 | train_new_mae: 0.03218 | valid_new_mae: 0.02268 |  0:00:25s\n",
            "epoch 36 | loss: 0.81094 | train_new_mae: 0.02078 | valid_new_mae: 0.02193 |  0:00:25s\n",
            "epoch 37 | loss: 0.72361 | train_new_mae: 0.02597 | valid_new_mae: 0.02409 |  0:00:26s\n",
            "epoch 38 | loss: 0.8846  | train_new_mae: 0.02922 | valid_new_mae: 0.02338 |  0:00:27s\n",
            "epoch 39 | loss: 1.26206 | train_new_mae: 0.03515 | valid_new_mae: 0.03546 |  0:00:28s\n",
            "epoch 40 | loss: 0.66912 | train_new_mae: 0.02148 | valid_new_mae: 0.01804 |  0:00:29s\n",
            "epoch 41 | loss: 0.50096 | train_new_mae: 0.02844 | valid_new_mae: 0.02147 |  0:00:29s\n",
            "epoch 42 | loss: 3.18541 | train_new_mae: 0.01748 | valid_new_mae: 0.0115  |  0:00:30s\n",
            "epoch 43 | loss: 0.49174 | train_new_mae: 0.01593 | valid_new_mae: 0.01347 |  0:00:31s\n",
            "epoch 44 | loss: 0.33618 | train_new_mae: 0.02361 | valid_new_mae: 0.02357 |  0:00:31s\n",
            "epoch 45 | loss: 3.63906 | train_new_mae: 0.01906 | valid_new_mae: 0.02189 |  0:00:32s\n",
            "epoch 46 | loss: 2.58239 | train_new_mae: 0.01683 | valid_new_mae: 0.01614 |  0:00:33s\n",
            "epoch 47 | loss: 0.79778 | train_new_mae: 0.01603 | valid_new_mae: 0.00998 |  0:00:33s\n",
            "epoch 48 | loss: 2.23746 | train_new_mae: 0.01677 | valid_new_mae: 0.01067 |  0:00:34s\n",
            "epoch 49 | loss: 0.42226 | train_new_mae: 0.01539 | valid_new_mae: 0.01455 |  0:00:35s\n",
            "epoch 50 | loss: 0.46859 | train_new_mae: 0.01535 | valid_new_mae: 0.0149  |  0:00:35s\n",
            "epoch 51 | loss: 0.2768  | train_new_mae: 0.0172  | valid_new_mae: 0.01137 |  0:00:36s\n",
            "epoch 52 | loss: 0.4336  | train_new_mae: 0.01626 | valid_new_mae: 0.01042 |  0:00:36s\n",
            "epoch 53 | loss: 0.3971  | train_new_mae: 0.01596 | valid_new_mae: 0.01036 |  0:00:37s\n",
            "epoch 54 | loss: 0.37372 | train_new_mae: 0.01613 | valid_new_mae: 0.0115  |  0:00:38s\n",
            "epoch 55 | loss: 0.37755 | train_new_mae: 0.01375 | valid_new_mae: 0.01009 |  0:00:38s\n",
            "epoch 56 | loss: 0.66376 | train_new_mae: 0.01407 | valid_new_mae: 0.01205 |  0:00:39s\n",
            "epoch 57 | loss: 0.92031 | train_new_mae: 0.01785 | valid_new_mae: 0.01898 |  0:00:40s\n",
            "epoch 58 | loss: 0.23252 | train_new_mae: 0.0151  | valid_new_mae: 0.02022 |  0:00:41s\n",
            "epoch 59 | loss: 0.20224 | train_new_mae: 0.01648 | valid_new_mae: 0.01328 |  0:00:42s\n",
            "epoch 60 | loss: 0.19348 | train_new_mae: 0.01392 | valid_new_mae: 0.00985 |  0:00:42s\n",
            "epoch 61 | loss: 0.31995 | train_new_mae: 0.0162  | valid_new_mae: 0.01319 |  0:00:43s\n",
            "epoch 62 | loss: 0.22981 | train_new_mae: 0.01552 | valid_new_mae: 0.00974 |  0:00:44s\n",
            "epoch 63 | loss: 0.21088 | train_new_mae: 0.01614 | valid_new_mae: 0.01155 |  0:00:44s\n",
            "epoch 64 | loss: 0.64656 | train_new_mae: 0.012   | valid_new_mae: 0.01049 |  0:00:45s\n",
            "epoch 65 | loss: 0.7203  | train_new_mae: 0.01199 | valid_new_mae: 0.01038 |  0:00:46s\n",
            "epoch 66 | loss: 0.15899 | train_new_mae: 0.01364 | valid_new_mae: 0.00817 |  0:00:46s\n",
            "epoch 67 | loss: 0.28797 | train_new_mae: 0.01295 | valid_new_mae: 0.00967 |  0:00:47s\n",
            "epoch 68 | loss: 0.30867 | train_new_mae: 0.01509 | valid_new_mae: 0.0102  |  0:00:47s\n",
            "epoch 69 | loss: 0.19052 | train_new_mae: 0.01545 | valid_new_mae: 0.01225 |  0:00:48s\n",
            "epoch 70 | loss: 0.22439 | train_new_mae: 0.01174 | valid_new_mae: 0.00819 |  0:00:49s\n",
            "epoch 71 | loss: 1.01613 | train_new_mae: 0.01304 | valid_new_mae: 0.00953 |  0:00:49s\n",
            "epoch 72 | loss: 0.18438 | train_new_mae: 0.01163 | valid_new_mae: 0.01165 |  0:00:50s\n",
            "epoch 73 | loss: 0.8765  | train_new_mae: 0.01285 | valid_new_mae: 0.01116 |  0:00:51s\n",
            "epoch 74 | loss: 0.10978 | train_new_mae: 0.01116 | valid_new_mae: 0.00841 |  0:00:51s\n",
            "epoch 75 | loss: 0.14007 | train_new_mae: 0.01052 | valid_new_mae: 0.00889 |  0:00:52s\n",
            "epoch 76 | loss: 0.2175  | train_new_mae: 0.0094  | valid_new_mae: 0.00902 |  0:00:53s\n",
            "epoch 77 | loss: 0.26002 | train_new_mae: 0.00988 | valid_new_mae: 0.00876 |  0:00:54s\n",
            "epoch 78 | loss: 0.10305 | train_new_mae: 0.0099  | valid_new_mae: 0.00861 |  0:00:55s\n",
            "epoch 79 | loss: 0.19699 | train_new_mae: 0.00913 | valid_new_mae: 0.0078  |  0:00:55s\n",
            "epoch 80 | loss: 0.59704 | train_new_mae: 0.01029 | valid_new_mae: 0.01099 |  0:00:56s\n",
            "epoch 81 | loss: 0.25179 | train_new_mae: 0.01247 | valid_new_mae: 0.01418 |  0:00:57s\n",
            "epoch 82 | loss: 0.35687 | train_new_mae: 0.00955 | valid_new_mae: 0.01401 |  0:00:57s\n",
            "epoch 83 | loss: 0.10329 | train_new_mae: 0.01064 | valid_new_mae: 0.01112 |  0:00:58s\n",
            "epoch 84 | loss: 0.11252 | train_new_mae: 0.01142 | valid_new_mae: 0.01455 |  0:00:59s\n",
            "epoch 85 | loss: 0.13995 | train_new_mae: 0.01212 | valid_new_mae: 0.01225 |  0:00:59s\n",
            "epoch 86 | loss: 0.64349 | train_new_mae: 0.01167 | valid_new_mae: 0.00989 |  0:01:00s\n",
            "epoch 87 | loss: 0.1164  | train_new_mae: 0.01113 | valid_new_mae: 0.01255 |  0:01:01s\n",
            "epoch 88 | loss: 0.20367 | train_new_mae: 0.01415 | valid_new_mae: 0.01504 |  0:01:01s\n",
            "epoch 89 | loss: 0.12719 | train_new_mae: 0.01076 | valid_new_mae: 0.00927 |  0:01:02s\n",
            "epoch 90 | loss: 0.112   | train_new_mae: 0.01084 | valid_new_mae: 0.00907 |  0:01:02s\n",
            "epoch 91 | loss: 0.13345 | train_new_mae: 0.01022 | valid_new_mae: 0.00849 |  0:01:03s\n",
            "epoch 92 | loss: 0.24429 | train_new_mae: 0.0101  | valid_new_mae: 0.0111  |  0:01:04s\n",
            "epoch 93 | loss: 0.10937 | train_new_mae: 0.00793 | valid_new_mae: 0.00968 |  0:01:04s\n",
            "epoch 94 | loss: 0.16698 | train_new_mae: 0.009   | valid_new_mae: 0.01319 |  0:01:05s\n",
            "epoch 95 | loss: 0.12711 | train_new_mae: 0.00953 | valid_new_mae: 0.0107  |  0:01:06s\n",
            "epoch 96 | loss: 0.18019 | train_new_mae: 0.00897 | valid_new_mae: 0.01139 |  0:01:07s\n",
            "epoch 97 | loss: 0.18699 | train_new_mae: 0.00767 | valid_new_mae: 0.00936 |  0:01:08s\n",
            "epoch 98 | loss: 0.10221 | train_new_mae: 0.00748 | valid_new_mae: 0.0082  |  0:01:08s\n",
            "epoch 99 | loss: 0.11478 | train_new_mae: 0.00791 | valid_new_mae: 0.00986 |  0:01:09s\n",
            "epoch 100| loss: 0.19288 | train_new_mae: 0.00863 | valid_new_mae: 0.0119  |  0:01:10s\n",
            "epoch 101| loss: 0.13586 | train_new_mae: 0.00748 | valid_new_mae: 0.01093 |  0:01:10s\n",
            "epoch 102| loss: 0.2726  | train_new_mae: 0.00745 | valid_new_mae: 0.01214 |  0:01:11s\n",
            "epoch 103| loss: 0.10431 | train_new_mae: 0.00739 | valid_new_mae: 0.0122  |  0:01:12s\n",
            "epoch 104| loss: 0.15771 | train_new_mae: 0.00869 | valid_new_mae: 0.01103 |  0:01:12s\n",
            "epoch 105| loss: 0.12196 | train_new_mae: 0.00825 | valid_new_mae: 0.00975 |  0:01:13s\n",
            "epoch 106| loss: 0.13443 | train_new_mae: 0.00851 | valid_new_mae: 0.00923 |  0:01:13s\n",
            "epoch 107| loss: 0.13411 | train_new_mae: 0.00814 | valid_new_mae: 0.01001 |  0:01:14s\n",
            "epoch 108| loss: 0.13643 | train_new_mae: 0.0096  | valid_new_mae: 0.00785 |  0:01:15s\n",
            "epoch 109| loss: 0.37268 | train_new_mae: 0.01031 | valid_new_mae: 0.00886 |  0:01:15s\n",
            "epoch 110| loss: 0.23399 | train_new_mae: 0.01137 | valid_new_mae: 0.00969 |  0:01:16s\n",
            "epoch 111| loss: 0.22275 | train_new_mae: 0.00964 | valid_new_mae: 0.00872 |  0:01:17s\n",
            "epoch 112| loss: 0.19426 | train_new_mae: 0.01165 | valid_new_mae: 0.00955 |  0:01:17s\n",
            "epoch 113| loss: 0.07474 | train_new_mae: 0.00893 | valid_new_mae: 0.00969 |  0:01:18s\n",
            "epoch 114| loss: 0.3267  | train_new_mae: 0.00919 | valid_new_mae: 0.01012 |  0:01:19s\n",
            "epoch 115| loss: 0.0784  | train_new_mae: 0.00837 | valid_new_mae: 0.0085  |  0:01:20s\n",
            "epoch 116| loss: 0.09455 | train_new_mae: 0.01076 | valid_new_mae: 0.0087  |  0:01:21s\n",
            "epoch 117| loss: 0.32264 | train_new_mae: 0.00889 | valid_new_mae: 0.00783 |  0:01:21s\n",
            "epoch 118| loss: 0.11212 | train_new_mae: 0.0073  | valid_new_mae: 0.00774 |  0:01:22s\n",
            "epoch 119| loss: 0.06254 | train_new_mae: 0.00889 | valid_new_mae: 0.00733 |  0:01:23s\n",
            "epoch 120| loss: 0.06805 | train_new_mae: 0.00983 | valid_new_mae: 0.01435 |  0:01:23s\n",
            "epoch 121| loss: 0.07255 | train_new_mae: 0.00764 | valid_new_mae: 0.00918 |  0:01:24s\n",
            "epoch 122| loss: 0.11495 | train_new_mae: 0.00809 | valid_new_mae: 0.00826 |  0:01:25s\n",
            "epoch 123| loss: 0.14574 | train_new_mae: 0.00916 | valid_new_mae: 0.00974 |  0:01:25s\n",
            "epoch 124| loss: 0.05618 | train_new_mae: 0.0076  | valid_new_mae: 0.00849 |  0:01:26s\n",
            "epoch 125| loss: 0.06693 | train_new_mae: 0.0084  | valid_new_mae: 0.00825 |  0:01:27s\n",
            "epoch 126| loss: 0.34422 | train_new_mae: 0.01438 | valid_new_mae: 0.00759 |  0:01:27s\n",
            "epoch 127| loss: 0.34283 | train_new_mae: 0.00836 | valid_new_mae: 0.00834 |  0:01:28s\n",
            "epoch 128| loss: 0.10132 | train_new_mae: 0.00707 | valid_new_mae: 0.00822 |  0:01:28s\n",
            "epoch 129| loss: 0.10106 | train_new_mae: 0.00727 | valid_new_mae: 0.00837 |  0:01:29s\n",
            "epoch 130| loss: 0.04831 | train_new_mae: 0.00734 | valid_new_mae: 0.00769 |  0:01:30s\n",
            "epoch 131| loss: 0.05574 | train_new_mae: 0.00726 | valid_new_mae: 0.00763 |  0:01:30s\n",
            "epoch 132| loss: 0.21355 | train_new_mae: 0.01178 | valid_new_mae: 0.00892 |  0:01:31s\n",
            "epoch 133| loss: 0.06576 | train_new_mae: 0.00726 | valid_new_mae: 0.00792 |  0:01:32s\n",
            "epoch 134| loss: 0.10323 | train_new_mae: 0.00732 | valid_new_mae: 0.00882 |  0:01:33s\n",
            "epoch 135| loss: 0.09591 | train_new_mae: 0.01119 | valid_new_mae: 0.01101 |  0:01:34s\n",
            "epoch 136| loss: 0.16766 | train_new_mae: 0.01525 | valid_new_mae: 0.01197 |  0:01:34s\n",
            "epoch 137| loss: 0.15436 | train_new_mae: 0.00862 | valid_new_mae: 0.00896 |  0:01:35s\n",
            "epoch 138| loss: 0.30517 | train_new_mae: 0.00995 | valid_new_mae: 0.00762 |  0:01:36s\n",
            "epoch 139| loss: 0.4211  | train_new_mae: 0.00923 | valid_new_mae: 0.00812 |  0:01:36s\n",
            "epoch 140| loss: 0.30072 | train_new_mae: 0.0098  | valid_new_mae: 0.00911 |  0:01:37s\n",
            "epoch 141| loss: 0.47047 | train_new_mae: 0.01175 | valid_new_mae: 0.01206 |  0:01:38s\n",
            "epoch 142| loss: 0.47119 | train_new_mae: 0.00893 | valid_new_mae: 0.00866 |  0:01:38s\n",
            "epoch 143| loss: 0.27624 | train_new_mae: 0.00965 | valid_new_mae: 0.00904 |  0:01:39s\n",
            "epoch 144| loss: 0.27809 | train_new_mae: 0.00978 | valid_new_mae: 0.00917 |  0:01:40s\n",
            "epoch 145| loss: 0.34857 | train_new_mae: 0.01145 | valid_new_mae: 0.0102  |  0:01:40s\n",
            "epoch 146| loss: 0.43892 | train_new_mae: 0.01107 | valid_new_mae: 0.01046 |  0:01:41s\n",
            "epoch 147| loss: 0.26464 | train_new_mae: 0.00906 | valid_new_mae: 0.00856 |  0:01:42s\n",
            "epoch 148| loss: 0.30207 | train_new_mae: 0.00948 | valid_new_mae: 0.00833 |  0:01:42s\n",
            "epoch 149| loss: 0.43056 | train_new_mae: 0.00979 | valid_new_mae: 0.00955 |  0:01:43s\n",
            "epoch 150| loss: 0.41167 | train_new_mae: 0.01103 | valid_new_mae: 0.01078 |  0:01:43s\n",
            "epoch 151| loss: 0.38347 | train_new_mae: 0.01036 | valid_new_mae: 0.0095  |  0:01:44s\n",
            "epoch 152| loss: 0.36768 | train_new_mae: 0.00936 | valid_new_mae: 0.00871 |  0:01:45s\n",
            "epoch 153| loss: 0.38195 | train_new_mae: 0.00937 | valid_new_mae: 0.00805 |  0:01:46s\n",
            "epoch 154| loss: 0.3769  | train_new_mae: 0.00971 | valid_new_mae: 0.00925 |  0:01:47s\n",
            "epoch 155| loss: 0.36601 | train_new_mae: 0.0129  | valid_new_mae: 0.01194 |  0:01:48s\n",
            "epoch 156| loss: 0.63731 | train_new_mae: 0.00993 | valid_new_mae: 0.00815 |  0:01:48s\n",
            "epoch 157| loss: 0.30589 | train_new_mae: 0.00907 | valid_new_mae: 0.00749 |  0:01:49s\n",
            "epoch 158| loss: 0.51396 | train_new_mae: 0.00915 | valid_new_mae: 0.00868 |  0:01:49s\n",
            "epoch 159| loss: 0.33572 | train_new_mae: 0.00831 | valid_new_mae: 0.00737 |  0:01:50s\n",
            "epoch 160| loss: 0.52251 | train_new_mae: 0.01315 | valid_new_mae: 0.01145 |  0:01:51s\n",
            "epoch 161| loss: 0.45085 | train_new_mae: 0.01314 | valid_new_mae: 0.01074 |  0:01:51s\n",
            "epoch 162| loss: 0.39566 | train_new_mae: 0.01042 | valid_new_mae: 0.00817 |  0:01:52s\n",
            "epoch 163| loss: 0.33192 | train_new_mae: 0.01067 | valid_new_mae: 0.00714 |  0:01:53s\n",
            "epoch 164| loss: 0.42693 | train_new_mae: 0.00942 | valid_new_mae: 0.00734 |  0:01:53s\n",
            "epoch 165| loss: 0.38564 | train_new_mae: 0.00994 | valid_new_mae: 0.00905 |  0:01:54s\n",
            "epoch 166| loss: 0.37337 | train_new_mae: 0.00827 | valid_new_mae: 0.00863 |  0:01:55s\n",
            "epoch 167| loss: 0.39671 | train_new_mae: 0.01216 | valid_new_mae: 0.01203 |  0:01:55s\n",
            "epoch 168| loss: 0.32363 | train_new_mae: 0.0115  | valid_new_mae: 0.011   |  0:01:56s\n",
            "epoch 169| loss: 0.31241 | train_new_mae: 0.00896 | valid_new_mae: 0.01178 |  0:01:57s\n",
            "epoch 170| loss: 0.34661 | train_new_mae: 0.00882 | valid_new_mae: 0.00886 |  0:01:57s\n",
            "epoch 171| loss: 0.32183 | train_new_mae: 0.01012 | valid_new_mae: 0.00861 |  0:01:58s\n",
            "epoch 172| loss: 0.46445 | train_new_mae: 0.00957 | valid_new_mae: 0.00796 |  0:01:59s\n",
            "epoch 173| loss: 0.3552  | train_new_mae: 0.00873 | valid_new_mae: 0.00766 |  0:02:00s\n",
            "epoch 174| loss: 0.53545 | train_new_mae: 0.01244 | valid_new_mae: 0.01433 |  0:02:01s\n",
            "epoch 175| loss: 0.33662 | train_new_mae: 0.00881 | valid_new_mae: 0.0093  |  0:02:01s\n",
            "epoch 176| loss: 0.34735 | train_new_mae: 0.01207 | valid_new_mae: 0.01265 |  0:02:02s\n",
            "epoch 177| loss: 0.31087 | train_new_mae: 0.01018 | valid_new_mae: 0.01311 |  0:02:03s\n",
            "epoch 178| loss: 0.34182 | train_new_mae: 0.00855 | valid_new_mae: 0.00874 |  0:02:03s\n",
            "epoch 179| loss: 0.36655 | train_new_mae: 0.00913 | valid_new_mae: 0.0118  |  0:02:04s\n",
            "epoch 180| loss: 0.35997 | train_new_mae: 0.00665 | valid_new_mae: 0.00977 |  0:02:04s\n",
            "epoch 181| loss: 0.35934 | train_new_mae: 0.00673 | valid_new_mae: 0.0109  |  0:02:05s\n",
            "epoch 182| loss: 0.08633 | train_new_mae: 0.00624 | valid_new_mae: 0.0122  |  0:02:06s\n",
            "epoch 183| loss: 0.43067 | train_new_mae: 0.00849 | valid_new_mae: 0.01348 |  0:02:06s\n",
            "epoch 184| loss: 0.58184 | train_new_mae: 0.00916 | valid_new_mae: 0.00989 |  0:02:07s\n",
            "epoch 185| loss: 0.18201 | train_new_mae: 0.00813 | valid_new_mae: 0.01014 |  0:02:08s\n",
            "epoch 186| loss: 0.2824  | train_new_mae: 0.00871 | valid_new_mae: 0.01182 |  0:02:08s\n",
            "epoch 187| loss: 0.15933 | train_new_mae: 0.01114 | valid_new_mae: 0.013   |  0:02:09s\n",
            "epoch 188| loss: 0.14907 | train_new_mae: 0.00954 | valid_new_mae: 0.01354 |  0:02:10s\n",
            "epoch 189| loss: 0.36018 | train_new_mae: 0.00752 | valid_new_mae: 0.01295 |  0:02:10s\n",
            "epoch 190| loss: 0.22788 | train_new_mae: 0.00829 | valid_new_mae: 0.01737 |  0:02:11s\n",
            "epoch 191| loss: 0.50014 | train_new_mae: 0.01083 | valid_new_mae: 0.00976 |  0:02:12s\n",
            "epoch 192| loss: 0.29837 | train_new_mae: 0.01096 | valid_new_mae: 0.01086 |  0:02:13s\n",
            "epoch 193| loss: 0.16772 | train_new_mae: 0.00954 | valid_new_mae: 0.01373 |  0:02:14s\n",
            "epoch 194| loss: 0.27918 | train_new_mae: 0.00999 | valid_new_mae: 0.01526 |  0:02:14s\n",
            "epoch 195| loss: 0.17922 | train_new_mae: 0.00706 | valid_new_mae: 0.01382 |  0:02:15s\n",
            "epoch 196| loss: 0.7881  | train_new_mae: 0.00736 | valid_new_mae: 0.01157 |  0:02:16s\n",
            "epoch 197| loss: 0.29753 | train_new_mae: 0.00709 | valid_new_mae: 0.01013 |  0:02:16s\n",
            "epoch 198| loss: 0.27761 | train_new_mae: 0.00801 | valid_new_mae: 0.01309 |  0:02:17s\n",
            "epoch 199| loss: 0.14528 | train_new_mae: 0.00941 | valid_new_mae: 0.01576 |  0:02:17s\n",
            "Stop training because you reached max_epochs = 200 with best_epoch = 163 and best_valid_new_mae = 0.00714\n",
            "\n",
            "== Desempeño: Fine-tuning NO incremental (solo nuevos) ==\n",
            "Test viejo (FT no incremental): R2=-0.0838\n",
            "Test nuevo (FT no incremental): R2=0.2830\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "/usr/local/lib/python3.12/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 613.21956| train_cum_mae: 9.71795 | valid_new_mae: 11.12282|  0:00:00s\n",
            "epoch 1  | loss: 89.91247| train_cum_mae: 3.28997 | valid_new_mae: 2.85211 |  0:00:01s\n",
            "epoch 2  | loss: 9.99063 | train_cum_mae: 0.53228 | valid_new_mae: 0.46861 |  0:00:03s\n",
            "epoch 3  | loss: 1.63203 | train_cum_mae: 0.46675 | valid_new_mae: 0.41983 |  0:00:04s\n",
            "epoch 4  | loss: 1.51299 | train_cum_mae: 0.23188 | valid_new_mae: 0.21494 |  0:00:05s\n",
            "epoch 5  | loss: 1.49229 | train_cum_mae: 0.12032 | valid_new_mae: 0.10224 |  0:00:06s\n",
            "epoch 6  | loss: 1.08564 | train_cum_mae: 0.11613 | valid_new_mae: 0.10851 |  0:00:07s\n",
            "epoch 7  | loss: 1.17925 | train_cum_mae: 0.12669 | valid_new_mae: 0.11157 |  0:00:08s\n",
            "epoch 8  | loss: 1.07953 | train_cum_mae: 0.09194 | valid_new_mae: 0.07461 |  0:00:09s\n",
            "epoch 9  | loss: 1.0248  | train_cum_mae: 0.1004  | valid_new_mae: 0.08278 |  0:00:10s\n",
            "epoch 10 | loss: 0.9256  | train_cum_mae: 0.05493 | valid_new_mae: 0.04237 |  0:00:11s\n",
            "epoch 11 | loss: 1.06056 | train_cum_mae: 0.03711 | valid_new_mae: 0.02141 |  0:00:12s\n",
            "epoch 12 | loss: 0.9585  | train_cum_mae: 0.03693 | valid_new_mae: 0.0236  |  0:00:13s\n",
            "epoch 13 | loss: 0.74668 | train_cum_mae: 0.03898 | valid_new_mae: 0.03102 |  0:00:14s\n",
            "epoch 14 | loss: 0.91238 | train_cum_mae: 0.03277 | valid_new_mae: 0.02357 |  0:00:15s\n",
            "epoch 15 | loss: 0.99974 | train_cum_mae: 0.06038 | valid_new_mae: 0.05116 |  0:00:16s\n",
            "epoch 16 | loss: 0.74236 | train_cum_mae: 0.0253  | valid_new_mae: 0.01748 |  0:00:18s\n",
            "epoch 17 | loss: 1.38807 | train_cum_mae: 0.02905 | valid_new_mae: 0.02859 |  0:00:18s\n",
            "epoch 18 | loss: 0.55124 | train_cum_mae: 0.02083 | valid_new_mae: 0.01406 |  0:00:19s\n",
            "epoch 19 | loss: 0.66246 | train_cum_mae: 0.01974 | valid_new_mae: 0.01539 |  0:00:20s\n",
            "epoch 20 | loss: 0.74891 | train_cum_mae: 0.02463 | valid_new_mae: 0.01993 |  0:00:21s\n",
            "epoch 21 | loss: 0.48007 | train_cum_mae: 0.02173 | valid_new_mae: 0.01891 |  0:00:22s\n",
            "epoch 22 | loss: 0.56784 | train_cum_mae: 0.02373 | valid_new_mae: 0.01897 |  0:00:23s\n",
            "epoch 23 | loss: 0.41169 | train_cum_mae: 0.02731 | valid_new_mae: 0.01889 |  0:00:24s\n",
            "epoch 24 | loss: 0.37681 | train_cum_mae: 0.01888 | valid_new_mae: 0.01171 |  0:00:25s\n",
            "epoch 25 | loss: 0.55156 | train_cum_mae: 0.01911 | valid_new_mae: 0.01337 |  0:00:26s\n",
            "epoch 26 | loss: 0.41708 | train_cum_mae: 0.01888 | valid_new_mae: 0.01369 |  0:00:27s\n",
            "epoch 27 | loss: 0.98862 | train_cum_mae: 0.02372 | valid_new_mae: 0.02173 |  0:00:28s\n",
            "epoch 28 | loss: 0.48094 | train_cum_mae: 0.01914 | valid_new_mae: 0.01639 |  0:00:30s\n",
            "epoch 29 | loss: 0.42259 | train_cum_mae: 0.01647 | valid_new_mae: 0.01009 |  0:00:31s\n",
            "epoch 30 | loss: 0.32666 | train_cum_mae: 0.01772 | valid_new_mae: 0.00849 |  0:00:32s\n",
            "epoch 31 | loss: 0.39241 | train_cum_mae: 0.01387 | valid_new_mae: 0.00919 |  0:00:33s\n",
            "epoch 32 | loss: 0.43679 | train_cum_mae: 0.01471 | valid_new_mae: 0.0135  |  0:00:34s\n",
            "epoch 33 | loss: 0.40744 | train_cum_mae: 0.01376 | valid_new_mae: 0.01134 |  0:00:35s\n",
            "epoch 34 | loss: 0.74743 | train_cum_mae: 0.01933 | valid_new_mae: 0.01298 |  0:00:36s\n",
            "epoch 35 | loss: 0.49282 | train_cum_mae: 0.0155  | valid_new_mae: 0.00722 |  0:00:37s\n",
            "epoch 36 | loss: 0.76939 | train_cum_mae: 0.01908 | valid_new_mae: 0.01232 |  0:00:37s\n",
            "epoch 37 | loss: 0.77066 | train_cum_mae: 0.014   | valid_new_mae: 0.00827 |  0:00:38s\n",
            "epoch 38 | loss: 0.43286 | train_cum_mae: 0.01669 | valid_new_mae: 0.00894 |  0:00:39s\n",
            "epoch 39 | loss: 0.21647 | train_cum_mae: 0.01291 | valid_new_mae: 0.00806 |  0:00:40s\n",
            "epoch 40 | loss: 0.18574 | train_cum_mae: 0.01238 | valid_new_mae: 0.00736 |  0:00:42s\n",
            "epoch 41 | loss: 0.24476 | train_cum_mae: 0.01249 | valid_new_mae: 0.00775 |  0:00:43s\n",
            "epoch 42 | loss: 0.14513 | train_cum_mae: 0.01207 | valid_new_mae: 0.00954 |  0:00:44s\n",
            "epoch 43 | loss: 0.23489 | train_cum_mae: 0.01504 | valid_new_mae: 0.00663 |  0:00:45s\n",
            "epoch 44 | loss: 0.18658 | train_cum_mae: 0.01406 | valid_new_mae: 0.01519 |  0:00:46s\n",
            "epoch 45 | loss: 0.19391 | train_cum_mae: 0.01131 | valid_new_mae: 0.0062  |  0:00:47s\n",
            "epoch 46 | loss: 0.22153 | train_cum_mae: 0.01038 | valid_new_mae: 0.00703 |  0:00:48s\n",
            "epoch 47 | loss: 0.47414 | train_cum_mae: 0.01209 | valid_new_mae: 0.00592 |  0:00:49s\n",
            "epoch 48 | loss: 0.15198 | train_cum_mae: 0.01294 | valid_new_mae: 0.00867 |  0:00:50s\n",
            "epoch 49 | loss: 0.19073 | train_cum_mae: 0.01448 | valid_new_mae: 0.01451 |  0:00:51s\n",
            "epoch 50 | loss: 0.22709 | train_cum_mae: 0.01183 | valid_new_mae: 0.00975 |  0:00:52s\n",
            "epoch 51 | loss: 0.27605 | train_cum_mae: 0.0166  | valid_new_mae: 0.01319 |  0:00:53s\n",
            "epoch 52 | loss: 0.163   | train_cum_mae: 0.0117  | valid_new_mae: 0.00703 |  0:00:54s\n",
            "epoch 53 | loss: 0.1687  | train_cum_mae: 0.01377 | valid_new_mae: 0.01223 |  0:00:55s\n",
            "epoch 54 | loss: 0.15992 | train_cum_mae: 0.01396 | valid_new_mae: 0.00838 |  0:00:56s\n",
            "epoch 55 | loss: 0.17078 | train_cum_mae: 0.013   | valid_new_mae: 0.00795 |  0:00:57s\n",
            "epoch 56 | loss: 0.17427 | train_cum_mae: 0.01341 | valid_new_mae: 0.00909 |  0:00:58s\n",
            "epoch 57 | loss: 0.1408  | train_cum_mae: 0.01105 | valid_new_mae: 0.00714 |  0:00:59s\n",
            "epoch 58 | loss: 0.15988 | train_cum_mae: 0.01049 | valid_new_mae: 0.0058  |  0:01:00s\n",
            "epoch 59 | loss: 0.16104 | train_cum_mae: 0.01211 | valid_new_mae: 0.00792 |  0:01:01s\n",
            "epoch 60 | loss: 0.1385  | train_cum_mae: 0.01201 | valid_new_mae: 0.00431 |  0:01:02s\n",
            "epoch 61 | loss: 0.105   | train_cum_mae: 0.01048 | valid_new_mae: 0.00544 |  0:01:03s\n",
            "epoch 62 | loss: 0.0708  | train_cum_mae: 0.01334 | valid_new_mae: 0.00847 |  0:01:04s\n",
            "epoch 63 | loss: 0.11222 | train_cum_mae: 0.01234 | valid_new_mae: 0.00551 |  0:01:05s\n",
            "epoch 64 | loss: 0.08154 | train_cum_mae: 0.01089 | valid_new_mae: 0.00835 |  0:01:06s\n",
            "epoch 65 | loss: 0.09676 | train_cum_mae: 0.01054 | valid_new_mae: 0.00886 |  0:01:07s\n",
            "epoch 66 | loss: 0.08688 | train_cum_mae: 0.01106 | valid_new_mae: 0.00781 |  0:01:08s\n",
            "epoch 67 | loss: 0.07014 | train_cum_mae: 0.0111  | valid_new_mae: 0.00797 |  0:01:10s\n",
            "epoch 68 | loss: 0.14144 | train_cum_mae: 0.00916 | valid_new_mae: 0.0047  |  0:01:10s\n",
            "epoch 69 | loss: 0.12123 | train_cum_mae: 0.01191 | valid_new_mae: 0.00951 |  0:01:11s\n",
            "epoch 70 | loss: 0.11781 | train_cum_mae: 0.00969 | valid_new_mae: 0.00687 |  0:01:12s\n",
            "epoch 71 | loss: 0.14031 | train_cum_mae: 0.01415 | valid_new_mae: 0.01057 |  0:01:13s\n",
            "epoch 72 | loss: 0.1264  | train_cum_mae: 0.04751 | valid_new_mae: 0.04699 |  0:01:14s\n",
            "epoch 73 | loss: 0.14802 | train_cum_mae: 0.01366 | valid_new_mae: 0.01201 |  0:01:15s\n",
            "epoch 74 | loss: 0.10127 | train_cum_mae: 0.00892 | valid_new_mae: 0.00805 |  0:01:16s\n",
            "epoch 75 | loss: 0.10769 | train_cum_mae: 0.00911 | valid_new_mae: 0.00537 |  0:01:17s\n",
            "epoch 76 | loss: 0.0981  | train_cum_mae: 0.0286  | valid_new_mae: 0.01818 |  0:01:18s\n",
            "epoch 77 | loss: 0.10304 | train_cum_mae: 0.01123 | valid_new_mae: 0.00636 |  0:01:19s\n",
            "epoch 78 | loss: 0.17908 | train_cum_mae: 0.01205 | valid_new_mae: 0.00702 |  0:01:20s\n",
            "epoch 79 | loss: 0.13684 | train_cum_mae: 0.01262 | valid_new_mae: 0.00664 |  0:01:21s\n",
            "epoch 80 | loss: 0.10542 | train_cum_mae: 0.01318 | valid_new_mae: 0.00933 |  0:01:23s\n",
            "epoch 81 | loss: 0.09721 | train_cum_mae: 0.01063 | valid_new_mae: 0.00677 |  0:01:24s\n",
            "epoch 82 | loss: 0.08707 | train_cum_mae: 0.01026 | valid_new_mae: 0.0087  |  0:01:25s\n",
            "epoch 83 | loss: 0.04795 | train_cum_mae: 0.009   | valid_new_mae: 0.0079  |  0:01:26s\n",
            "epoch 84 | loss: 0.08233 | train_cum_mae: 0.00932 | valid_new_mae: 0.00689 |  0:01:27s\n",
            "epoch 85 | loss: 0.05279 | train_cum_mae: 0.01194 | valid_new_mae: 0.00845 |  0:01:27s\n",
            "epoch 86 | loss: 0.07604 | train_cum_mae: 0.00973 | valid_new_mae: 0.00948 |  0:01:28s\n",
            "epoch 87 | loss: 0.057   | train_cum_mae: 0.01148 | valid_new_mae: 0.00525 |  0:01:29s\n",
            "epoch 88 | loss: 0.08101 | train_cum_mae: 0.01007 | valid_new_mae: 0.00763 |  0:01:30s\n",
            "epoch 89 | loss: 0.08105 | train_cum_mae: 0.01134 | valid_new_mae: 0.00567 |  0:01:31s\n",
            "epoch 90 | loss: 0.08286 | train_cum_mae: 0.00924 | valid_new_mae: 0.00577 |  0:01:32s\n",
            "epoch 91 | loss: 0.10293 | train_cum_mae: 0.011   | valid_new_mae: 0.00663 |  0:01:33s\n",
            "epoch 92 | loss: 0.05492 | train_cum_mae: 0.01006 | valid_new_mae: 0.00702 |  0:01:35s\n",
            "epoch 93 | loss: 0.07308 | train_cum_mae: 0.00833 | valid_new_mae: 0.00518 |  0:01:36s\n",
            "epoch 94 | loss: 0.04679 | train_cum_mae: 0.01061 | valid_new_mae: 0.00576 |  0:01:37s\n",
            "epoch 95 | loss: 0.07722 | train_cum_mae: 0.00996 | valid_new_mae: 0.00685 |  0:01:38s\n",
            "epoch 96 | loss: 0.08128 | train_cum_mae: 0.00772 | valid_new_mae: 0.00593 |  0:01:39s\n",
            "epoch 97 | loss: 0.0792  | train_cum_mae: 0.01128 | valid_new_mae: 0.00523 |  0:01:40s\n",
            "epoch 98 | loss: 0.07669 | train_cum_mae: 0.00971 | valid_new_mae: 0.00992 |  0:01:41s\n",
            "epoch 99 | loss: 0.09117 | train_cum_mae: 0.01292 | valid_new_mae: 0.01056 |  0:01:42s\n",
            "epoch 100| loss: 0.10531 | train_cum_mae: 0.0104  | valid_new_mae: 0.00842 |  0:01:43s\n",
            "epoch 101| loss: 0.26047 | train_cum_mae: 0.01582 | valid_new_mae: 0.00702 |  0:01:44s\n",
            "epoch 102| loss: 0.1549  | train_cum_mae: 0.01009 | valid_new_mae: 0.00526 |  0:01:44s\n",
            "epoch 103| loss: 0.1292  | train_cum_mae: 0.01358 | valid_new_mae: 0.00816 |  0:01:45s\n",
            "epoch 104| loss: 0.09493 | train_cum_mae: 0.01346 | valid_new_mae: 0.00694 |  0:01:47s\n",
            "epoch 105| loss: 0.086   | train_cum_mae: 0.01064 | valid_new_mae: 0.00888 |  0:01:48s\n",
            "epoch 106| loss: 0.11916 | train_cum_mae: 0.0142  | valid_new_mae: 0.00856 |  0:01:49s\n",
            "epoch 107| loss: 0.05061 | train_cum_mae: 0.01341 | valid_new_mae: 0.00556 |  0:01:50s\n",
            "epoch 108| loss: 0.06381 | train_cum_mae: 0.01315 | valid_new_mae: 0.00763 |  0:01:51s\n",
            "epoch 109| loss: 0.04642 | train_cum_mae: 0.00968 | valid_new_mae: 0.00849 |  0:01:52s\n",
            "epoch 110| loss: 0.13185 | train_cum_mae: 0.01379 | valid_new_mae: 0.00624 |  0:01:53s\n",
            "epoch 111| loss: 0.07571 | train_cum_mae: 0.01055 | valid_new_mae: 0.00655 |  0:01:54s\n",
            "epoch 112| loss: 0.11995 | train_cum_mae: 0.01047 | valid_new_mae: 0.00532 |  0:01:55s\n",
            "epoch 113| loss: 0.04146 | train_cum_mae: 0.00809 | valid_new_mae: 0.00679 |  0:01:56s\n",
            "epoch 114| loss: 0.07384 | train_cum_mae: 0.00995 | valid_new_mae: 0.00518 |  0:01:57s\n",
            "epoch 115| loss: 0.0378  | train_cum_mae: 0.00873 | valid_new_mae: 0.00536 |  0:01:58s\n",
            "epoch 116| loss: 0.02815 | train_cum_mae: 0.00613 | valid_new_mae: 0.0061  |  0:01:59s\n",
            "epoch 117| loss: 0.03875 | train_cum_mae: 0.00923 | valid_new_mae: 0.00522 |  0:02:00s\n",
            "epoch 118| loss: 0.06901 | train_cum_mae: 0.0081  | valid_new_mae: 0.0056  |  0:02:01s\n",
            "epoch 119| loss: 0.0906  | train_cum_mae: 0.00739 | valid_new_mae: 0.00593 |  0:02:02s\n",
            "epoch 120| loss: 0.07436 | train_cum_mae: 0.006   | valid_new_mae: 0.00548 |  0:02:03s\n",
            "epoch 121| loss: 0.07045 | train_cum_mae: 0.01298 | valid_new_mae: 0.00642 |  0:02:04s\n",
            "epoch 122| loss: 0.04649 | train_cum_mae: 0.01029 | valid_new_mae: 0.00598 |  0:02:05s\n",
            "epoch 123| loss: 0.04347 | train_cum_mae: 0.00959 | valid_new_mae: 0.00603 |  0:02:06s\n",
            "epoch 124| loss: 0.07443 | train_cum_mae: 0.01196 | valid_new_mae: 0.01102 |  0:02:07s\n",
            "epoch 125| loss: 0.09126 | train_cum_mae: 0.01001 | valid_new_mae: 0.00543 |  0:02:08s\n",
            "epoch 126| loss: 0.0631  | train_cum_mae: 0.01126 | valid_new_mae: 0.00589 |  0:02:09s\n",
            "epoch 127| loss: 0.08281 | train_cum_mae: 0.00927 | valid_new_mae: 0.0058  |  0:02:10s\n",
            "epoch 128| loss: 0.0777  | train_cum_mae: 0.00681 | valid_new_mae: 0.00606 |  0:02:11s\n",
            "epoch 129| loss: 0.03553 | train_cum_mae: 0.00603 | valid_new_mae: 0.00684 |  0:02:12s\n",
            "epoch 130| loss: 0.04516 | train_cum_mae: 0.00819 | valid_new_mae: 0.00708 |  0:02:13s\n",
            "\n",
            "Early stopping occurred at epoch 130 with best_epoch = 60 and best_valid_new_mae = 0.00431\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== Desempeño: Desde cero (old+new) ==\n",
            "Test viejo (desde cero): R2=0.1122\n",
            "Test nuevo (desde cero): R2=-0.0299\n",
            "\n",
            "==== RESUMEN R² ====\n",
            "fine_tune_incremental -> {'R2_old_test': 0.1122, 'R2_new_test': -0.0299}\n",
            "fine_tune_only_new -> {'R2_old_test': -0.0838, 'R2_new_test': 0.283}\n",
            "from_scratch -> {'R2_old_test': 0.1122, 'R2_new_test': -0.0299}\n"
          ]
        }
      ]
    }
  ]
}