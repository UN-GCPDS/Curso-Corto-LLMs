{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UN-GCPDS/Curso-Corto-LLMs/blob/main/2.Entrenamiento_Tabnet/Entrenamiento_Tabnet_Parte_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Logo UNAL CHEC](https://github.com/UN-GCPDS/curso_IA_CHEC/blob/main/logo_unal_chec.jpg?raw=1)\n",
        "\n",
        "# **Entrenamiento modelo Tabnet**\n",
        "\n",
        "## **Descripción**\n",
        "\n",
        "Entrenamiento de modelo Tabnet bajo diversas condiciones.\n",
        "\n",
        "### **Profesor - Sesión 1:** Andrés Marino Álvarez Meza y Diego Armando Pérez Rosero"
      ],
      "metadata": {
        "id": "mFZXuItQprV2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Datos\n",
        "\n",
        "**TabNet para criticidad en redes de media tensión — Planteamiento y datos (Regresión)**\n",
        "\n",
        "Sea el conjunto de datos\n",
        "\n",
        "$$\n",
        "\\mathbf{X}\\in\\mathbb{R}^{N\\times M},\\qquad\n",
        "\\mathbf{y}\\in\\mathbb{R}^{N}.\n",
        "$$\n",
        "\n",
        "Cada fila de $\\mathbf{X}$ representa un evento o periodo entre 2019 y 2024 y contiene las características de los elementos asociados al equipo que operó. El vector $\\mathbf{y}$ almacena el valor continuo del indicador a modelar (SAIDI o SAIFI) para ese mismo evento/periodo.\n",
        "\n",
        "Definimos\n",
        "\n",
        "$$\n",
        "\\mathcal{F}:\\mathcal{X}\\subseteq\\mathbb{R}^{M}\\to\\mathbb{R},\\qquad\n",
        "\\hat{y}=\\mathcal{F}(\\mathbf{x})\n",
        "=\n",
        "\\bigl(\\,\\breve{f}_{L}\\circ \\breve{f}_{L-1}\\circ \\cdots \\circ \\breve{f}_{1}\\,\\bigr)(\\mathbf{x}),\n",
        "$$\n",
        "\n",
        "donde $\\breve{f}_{l}(\\cdot)$ denota el $l$-ésimo bloque del modelo ($l\\in\\{1,\\dots,L\\}$) y $\\circ$ es el operador de composición.\n",
        "\n",
        "En caso multisalida para $(\\text{SAIDI},\\text{SAIFI})$, se toma $\\mathcal{F}:\\mathbb{R}^{M}\\to\\mathbb{R}^{2}$ y $\\mathbf{y}\\in\\mathbb{R}^{N\\times 2}$.\n",
        "![Logo UNAL CHEC](https://raw.githubusercontent.com/Daprosero/Deep-Convolutional-Generative-Adversarial-Network/refs/heads/master/Mercados%20CHEC.png)"
      ],
      "metadata": {
        "id": "NHmuwRJcqrHN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9h3KDG32hY8a",
        "outputId": "7fe57d57-a03b-466f-f37b-3211e3418dee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openTSNE\n",
            "  Downloading openTSNE-1.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.12/dist-packages (from openTSNE) (2.0.2)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.12/dist-packages (from openTSNE) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from openTSNE) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.20->openTSNE) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.20->openTSNE) (3.6.0)\n",
            "Downloading openTSNE-1.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openTSNE\n",
            "Successfully installed openTSNE-1.0.2\n",
            "Collecting pytorch-tabnet\n",
            "  Downloading pytorch_tabnet-4.1.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting optuna\n",
            "  Downloading optuna-4.5.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from pytorch-tabnet) (2.0.2)\n",
            "Requirement already satisfied: scikit_learn>0.21 in /usr/local/lib/python3.12/dist-packages (from pytorch-tabnet) (1.6.1)\n",
            "Requirement already satisfied: scipy>1.4 in /usr/local/lib/python3.12/dist-packages (from pytorch-tabnet) (1.16.1)\n",
            "Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.12/dist-packages (from pytorch-tabnet) (2.8.0+cu126)\n",
            "Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.12/dist-packages (from pytorch-tabnet) (4.67.1)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (1.16.5)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.43)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (4.15.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (3.6.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (3.19.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.3->pytorch-tabnet) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.3->pytorch-tabnet) (3.0.2)\n",
            "Downloading pytorch_tabnet-4.1.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.5/44.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading optuna-4.5.0-py3-none-any.whl (400 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.9/400.9 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, optuna, pytorch-tabnet\n",
            "Successfully installed colorlog-6.9.0 optuna-4.5.0 pytorch-tabnet-4.1.0\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "/usr/local/lib/python3.12/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1o_fZIhk6ErrtrM3eVZPF9s2qj8l4FoqS\n",
            "From (redirected): https://drive.google.com/uc?id=1o_fZIhk6ErrtrM3eVZPF9s2qj8l4FoqS&confirm=t&uuid=51994f01-b627-4259-91f9-e57c659cf3cd\n",
            "To: /content/SuperEventos_Criticidad_AguasAbajo_CODEs.zip\n",
            "100% 214M/214M [00:01<00:00, 170MB/s]\n",
            "/usr/local/lib/python3.12/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1lBrseLoEmr6-VwNSCHOp2zuc4sKKrkbQ\n",
            "From (redirected): https://drive.google.com/uc?id=1lBrseLoEmr6-VwNSCHOp2zuc4sKKrkbQ&confirm=t&uuid=175d9ab4-0f82-4414-acb7-ee1b27760d5a\n",
            "To: /content/model.zip\n",
            "100% 109M/109M [00:01<00:00, 104MB/s]  \n",
            "/usr/local/lib/python3.12/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=16VIuHLgPGpX4J723Wd48UAPhHivLuUaH\n",
            "From (redirected): https://drive.google.com/uc?id=16VIuHLgPGpX4J723Wd48UAPhHivLuUaH&confirm=t&uuid=11b41cd8-a6cc-4c46-90ef-c69945a5a000\n",
            "To: /content/Data_CHEC.zip\n",
            "100% 336M/336M [00:01<00:00, 233MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/cudf/utils/gpu_utils.py:75: UserWarning: Failed to dlopen libcuda.so.1\n",
            "  warnings.warn(str(e))\n"
          ]
        }
      ],
      "source": [
        "#@title Librerías\n",
        "# Instalación de paquetes necesarios\n",
        "!pip install -q gdown\n",
        "!pip install openTSNE\n",
        "!pip install pytorch-tabnet optuna\n",
        "!pip install wget --quiet\n",
        "\n",
        "# Importación de librerías necesarias\n",
        "import optuna\n",
        "import warnings\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.special import softmax\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler, QuantileTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, accuracy_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from pytorch_tabnet.tab_model import TabNetRegressor, TabNetClassifier\n",
        "from pytorch_tabnet.augmentations import RegressionSMOTE\n",
        "from google.colab import drive\n",
        "import tensorflow as tf\n",
        "import tensorflow_probability as tfp\n",
        "import os\n",
        "from pathlib import Path\n",
        "import math\n",
        "import wget\n",
        "!gdown --id 1o_fZIhk6ErrtrM3eVZPF9s2qj8l4FoqS -O SuperEventos_Criticidad_AguasAbajo_CODEs.zip\n",
        "!gdown --id 1lBrseLoEmr6-VwNSCHOp2zuc4sKKrkbQ -O model.zip\n",
        "!gdown --id 16VIuHLgPGpX4J723Wd48UAPhHivLuUaH -O Data_CHEC.zip\n",
        "\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_path = \"SuperEventos_Criticidad_AguasAbajo_CODEs.zip\"\n",
        "extract_dir = \"CHEC\"\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)\n",
        "\n",
        "zip_path = \"model.zip\"\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)\n",
        "\n",
        "zip_path = \"Data_CHEC.zip\"\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)\n",
        "\n",
        "# Supresión de warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"pandas\")\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "# Función auxiliar para etiquetas\n",
        "def get_labels(x: pd.Series) -> pd.Series:\n",
        "    labels, _ = pd.factorize(x)\n",
        "    return pd.Series(labels, name=x.name, index=x.index)\n",
        "\n",
        "# Definición de funciones personalizadas de pérdida\n",
        "def my_mse_loss_fn(y_pred, y_true):\n",
        "    mse_loss = (y_true - y_pred) ** 2\n",
        "    return torch.mean(mse_loss)\n",
        "import re\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_var_band(\n",
        "    df,\n",
        "    var_token,\n",
        "    row_index=0,\n",
        "    hours_back=24,\n",
        "    col_patterns=None,\n",
        "    display_name=None,\n",
        "    units=None,\n",
        "    event_label=\"evento reportado\",\n",
        "):\n",
        "    \"\"\"\n",
        "    Grafica una variable climática en una franja de horas hacia atrás.\n",
        "\n",
        "    Parámetros\n",
        "    ----------\n",
        "    df : pd.DataFrame\n",
        "        Contiene columnas por hora para la variable elegida.\n",
        "        Ejemplos de nombres soportados automáticamente:\n",
        "        - 'h0-<var>', 'h1-<var>', ..., 'h24-<var>'\n",
        "        - '<var>_h0', '<var>_h1', ...\n",
        "        con separadores '_' o '-'.\n",
        "\n",
        "    var_token : str\n",
        "        Nombre base de la variable en los nombres de columna (p.ej. 'wind_gust_spd',\n",
        "        'air_temp', 'precip'). Debe coincidir con lo que aparece en las columnas.\n",
        "\n",
        "    row_index : int\n",
        "        Fila (evento) a graficar.\n",
        "\n",
        "    hours_back : int\n",
        "        Cuántas horas hacia atrás mostrar.\n",
        "\n",
        "    col_patterns : list[str] | None\n",
        "        Lista de regex opcionales para detectar columnas por hora.\n",
        "        Si None, se generan automáticamente a partir de var_token.\n",
        "\n",
        "    display_name : str | None\n",
        "        Etiqueta legible para el eje Y (p.ej. 'Ráfaga de viento').\n",
        "        Si None, se usa var_token.\n",
        "\n",
        "    units : str | None\n",
        "        Unidades para concatenar en la etiqueta Y (p.ej. 'm/s', '°C', 'mm').\n",
        "\n",
        "    event_label : str\n",
        "        Texto para la flecha en la hora 0.\n",
        "    \"\"\"\n",
        "    # --- 1) Preparar patrones de columnas ---\n",
        "    if col_patterns is None:\n",
        "        # Permitir '_' o '-' (o espacio) entre partes del var_token\n",
        "        parts = re.split(r'[_\\-\\s]+', var_token.strip())\n",
        "        # Construimos un regex que tolere '_' o '-' entre partes\n",
        "        # ej: 'wind[_-]?gust[_-]?spd'\n",
        "        var_regex = r'[_-]?'.join(map(re.escape, parts))\n",
        "\n",
        "        col_patterns = [\n",
        "            rf'^h(\\d{{1,2}})[-_]?{var_regex}$',   # h0-<var>  o  h0_<var>\n",
        "            rf'^{var_regex}[-_]?h(\\d{{1,2}})$',   # <var>-h0  o  <var>_h0\n",
        "        ]\n",
        "\n",
        "    # --- 2) Detectar columnas y mapear a hora ---\n",
        "    hour_to_col = {}\n",
        "    for c in df.columns:\n",
        "        for pat in col_patterns:\n",
        "            m = re.match(pat, str(c), flags=re.IGNORECASE)\n",
        "            if m:\n",
        "                h = int(m.group(1))\n",
        "                hour_to_col[h] = c\n",
        "                break\n",
        "\n",
        "    if not hour_to_col:\n",
        "        raise ValueError(\n",
        "            f\"No se encontraron columnas con horas para la variable '{var_token}'.\\n\"\n",
        "            f\"Prueba ajustando 'var_token' o pasando 'col_patterns' personalizados.\"\n",
        "        )\n",
        "\n",
        "    # --- 3) Construir serie horas [0..hours_back] si existen, orden ascendente ---\n",
        "    hours = [h for h in sorted(hour_to_col.keys()) if 0 <= h <= hours_back]\n",
        "    vals = np.array(\n",
        "        [pd.to_numeric(df.loc[df.index[row_index], hour_to_col[h]], errors='coerce') for h in hours],\n",
        "        dtype=float\n",
        "    )\n",
        "\n",
        "    # --- 4) Graficar ---\n",
        "    fig, ax = plt.subplots(figsize=(10, 5))\n",
        "\n",
        "    # línea y puntos\n",
        "    ax.plot(hours, vals, marker='o')\n",
        "\n",
        "    # invertir eje X para que se vea 24 -> 0\n",
        "    ax.set_xlim(hours_back, 0)\n",
        "\n",
        "    # franja sombreada\n",
        "    ymin = np.nanmin(vals) if np.isfinite(np.nanmin(vals)) else 0.0\n",
        "    ymax = np.nanmax(vals) if np.isfinite(np.nanmax(vals)) else 1.0\n",
        "    pad  = 0.05 * (ymax - ymin if ymax > ymin else 1.0)\n",
        "    ax.set_ylim(ymin - pad, ymax + pad)\n",
        "    ax.axvspan(0, hours_back, alpha=0.15)\n",
        "\n",
        "    # flecha y etiqueta en hora 0\n",
        "    y0 = vals[hours.index(0)] if 0 in hours else np.nan\n",
        "    if not np.isfinite(y0):\n",
        "        y0 = np.nanmedian(vals) if np.isfinite(np.nanmedian(vals)) else (ymin + ymax) / 2.0\n",
        "\n",
        "    ax.annotate(\n",
        "        event_label,\n",
        "        xy=(0, y0),\n",
        "        xytext=(max(2, min(4, hours_back*0.15)), y0 + (ymax - y0)*0.15),\n",
        "        arrowprops=dict(arrowstyle=\"->\", lw=1),\n",
        "        ha='left', va='bottom'\n",
        "    )\n",
        "\n",
        "    # etiquetas\n",
        "    ylab = display_name if display_name else var_token\n",
        "    if units:\n",
        "        ylab = f\"{ylab} [{units}]\"\n",
        "    ax.set_xlabel(\"Horas antes del evento\")\n",
        "    ax.set_ylabel(ylab)\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "    # ticks principales (24, 18, 12, 6, 0) si corresponde\n",
        "    xticks = [h for h in [hours_back, 18, 12, 6, 0] if 0 <= h <= hours_back]\n",
        "    ax.set_xticks(xticks)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# --- Ejemplo de uso:\n",
        "# plot_wind_gust_band(df=tu_dataframe, row_index=0, hours_back=24)\n",
        "\n",
        "def my_rmse_loss_fn(y_pred, y_true):\n",
        "    mse_loss = (y_true - y_pred) ** 2\n",
        "    mean_mse_loss = torch.mean(mse_loss)\n",
        "    rmse_loss = torch.sqrt(mean_mse_loss)\n",
        "    return rmse_loss\n",
        "\n",
        "def my_mae_loss_fn(y_pred, y_true):\n",
        "    mae_loss = torch.abs(y_true - y_pred)\n",
        "    return torch.mean(mae_loss)\n",
        "\n",
        "def my_mape_loss_fn(y_pred, y_true):\n",
        "    mape_loss = torch.abs((y_true - y_pred) / y_true) * 100\n",
        "    return torch.mean(mape_loss)\n",
        "\n",
        "def my_r2_score_fn(y_pred, y_true):\n",
        "    total_variance = torch.var(y_true, unbiased=False)\n",
        "    unexplained_variance = torch.mean((y_true - y_pred) ** 2)\n",
        "    r2_score = 1 - (unexplained_variance / total_variance)\n",
        "    return 1-r2_score\n",
        "\n",
        "# Etapa 0: imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "# ==== Librerías ====\n",
        "import numpy as np\n",
        "import cupy as cp\n",
        "import xgboost as xgb\n",
        "\n",
        "from cuml.ensemble import RandomForestRegressor as cuRF\n",
        "from cuml.metrics import r2_score as r2_gpu\n",
        "\n",
        "# Si quieres comparar con CPU para sanity-check:\n",
        "from sklearn.metrics import r2_score as r2_cpu\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "# ==== Utilidades ====\n",
        "def to_cpu(a):\n",
        "    \"\"\"Convierte CuPy -> NumPy si aplica.\"\"\"\n",
        "    try:\n",
        "        if isinstance(a, cp.ndarray):\n",
        "            return cp.asnumpy(a)\n",
        "    except Exception:\n",
        "        pass\n",
        "    return a\n",
        "\n",
        "def metrics_gpu(y_true_cp, y_pred_cp):\n",
        "    \"\"\"MAE, RMSE, R2 calculados en GPU (CuPy).\"\"\"\n",
        "    y_true_cp = cp.asarray(y_true_cp)\n",
        "    y_pred_cp = cp.asarray(y_pred_cp)\n",
        "    mae  = float(cp.mean(cp.abs(y_true_cp - y_pred_cp)))\n",
        "    rmse = float(cp.sqrt(cp.mean((y_true_cp - y_pred_cp)**2)))\n",
        "    ssr  = float(cp.sum((y_true_cp - y_pred_cp)**2))\n",
        "    sst  = float(cp.sum((y_true_cp - cp.mean(y_true_cp))**2))\n",
        "    r2   = 1.0 - ssr / sst if sst > 0 else np.nan\n",
        "    return mae, rmse, r2\n",
        "\n",
        "def permutation_importance_rf_gpu(model, X_val_cp, y_val_cp, n_repeats=3, max_feats=None, random_state=42):\n",
        "    \"\"\"\n",
        "    Permutation importance en GPU para RF cuML.\n",
        "    Devuelve importancia por feature (drop medio de R2 en valid).\n",
        "    Si max_feats no es None, calcula solo para las primeras max_feats columnas (para acelerar).\n",
        "    \"\"\"\n",
        "    rs = cp.random.RandomState(random_state)\n",
        "    X_val_cp = cp.asarray(X_val_cp)\n",
        "    y_val_cp = cp.asarray(y_val_cp)\n",
        "\n",
        "    # R2 base\n",
        "    y_pred_base = model.predict(X_val_cp)\n",
        "    _, _, r2_base = metrics_gpu(y_val_cp, y_pred_base)\n",
        "\n",
        "    n, d = X_val_cp.shape\n",
        "    d_eval = d if max_feats is None else int(min(max_feats, d))\n",
        "    importances = cp.zeros(d, dtype=cp.float32)\n",
        "\n",
        "    for j in range(d_eval):\n",
        "        drops = []\n",
        "        for _ in range(n_repeats):\n",
        "            Xp = X_val_cp.copy()\n",
        "            idx = rs.permutation(n)\n",
        "            Xp[:, j] = Xp[idx, j]  # permutar solo la columna j\n",
        "            y_pred_p = model.predict(Xp)\n",
        "            _, _, r2_p = metrics_gpu(y_val_cp, y_pred_p)\n",
        "            drops.append(r2_base - r2_p)\n",
        "        importances[j] = cp.mean(cp.asarray(drops))\n",
        "\n",
        "    return importances  # CuPy array\n",
        "def regression_metrics(y_true, y_pred):\n",
        "    mae  = float(np.mean(np.abs(y_true - y_pred)))\n",
        "    rmse = float(np.sqrt(np.mean((y_true - y_pred)**2)))\n",
        "    ss_res = float(np.sum((y_true - y_pred)**2))\n",
        "    ss_tot = float(np.sum((y_true - np.mean(y_true))**2))\n",
        "    r2 = 1 - ss_res/ss_tot if ss_tot > 0 else np.nan\n",
        "    return mae, rmse, r2\n",
        "class CustomTabNetRegressor(TabNetRegressor):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(CustomTabNetRegressor, self).__init__(*args, **kwargs)\n",
        "\n",
        "    def forward(self, X):\n",
        "        output, M_loss = self.network(X)\n",
        "        output = torch.relu(output)\n",
        "        return output, M_loss\n",
        "\n",
        "    def predict(self, X):\n",
        "        device = next(self.network.parameters()).device\n",
        "        if not isinstance(X, torch.Tensor):\n",
        "            X = torch.tensor(X, dtype=torch.float32)\n",
        "        X = X.to(device)\n",
        "        with torch.no_grad():\n",
        "            output, _ = self.forward(X)\n",
        "        return output.cpu().numpy()\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.spatial import cKDTree\n",
        "from tqdm import tqdm\n",
        "from ast import literal_eval\n",
        "from pandas.api.types import is_numeric_dtype\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "def make_strat_labels(y_vals, n_bins=3, min_per_class=2):\n",
        "    \"\"\"\n",
        "    Genera etiquetas para estratificar a partir de un objetivo continuo.\n",
        "    Reduce bins si no hay suficientes muestras por clase.\n",
        "    \"\"\"\n",
        "    y1d = y_vals.reshape(-1)\n",
        "    for bins in range(n_bins, 1, -1):\n",
        "        pct = np.linspace(0, 100, bins + 1)[1:-1]\n",
        "        cuts = np.percentile(y1d, pct)\n",
        "        if np.any(np.diff(cuts) <= 0):\n",
        "            continue\n",
        "        labels = np.digitize(y1d, bins=cuts).astype(int)\n",
        "        counts = Counter(labels)\n",
        "        if all(c >= min_per_class for c in counts.values()) and len(counts) > 1:\n",
        "            return labels\n",
        "    return None\n",
        "\n",
        "def stratify_from_df_or_y(df_labels, idx, y_subset, col='NIVEL_C'):\n",
        "    \"\"\"Intenta usar df[col] como etiqueta; si falla, usa percentiles en y_subset.\"\"\"\n",
        "    try:\n",
        "        ycat_full = df_labels.loc[:, col].values.astype(int)\n",
        "        ycat = ycat_full[idx]\n",
        "        c10 = Counter(ycat)\n",
        "        if all(v >= 2 for v in c10.values()) and len(c10) > 1:\n",
        "            return ycat\n",
        "    except Exception:\n",
        "        pass\n",
        "    return make_strat_labels(y_subset[:,0], n_bins=3, min_per_class=2)\n",
        "\n",
        "def split_subset(X, y, df_labels=None, n_sub=1000, test_size=0.20, seed=42):\n",
        "    \"\"\"\n",
        "    1) Toma un subset aleatorio de tamaño n_sub.\n",
        "    2) Escala y (MinMax) sobre el subset.\n",
        "    3) Split train/test con estratificación si es viable.\n",
        "    4) Split train/valid (20% del train), con re-estratificación si es posible.\n",
        "    \"\"\"\n",
        "    rng = np.random.RandomState(seed)\n",
        "    n_total = X.shape[0]\n",
        "    n_sub = min(n_sub, n_total)\n",
        "    idx_sub = rng.choice(n_total, size=n_sub, replace=False)\n",
        "\n",
        "    X_sub = X[idx_sub]\n",
        "    y_sub = y[idx_sub]\n",
        "    # etiquetas auxiliares para estratificación\n",
        "    ycat_sub = stratify_from_df_or_y(df_labels, idx_sub, y_sub) if df_labels is not None else make_strat_labels(y_sub[:,0])\n",
        "    # escalar objetivo en el subset\n",
        "    scaler = MinMaxScaler()\n",
        "    y_sub_scaled = scaler.fit_transform(y_sub)\n",
        "\n",
        "    split_kwargs = dict(test_size=test_size, random_state=seed, shuffle=True)\n",
        "    if ycat_sub is not None:\n",
        "        X_tr, X_te, y_tr, y_te, ycat_tr, ycat_te = train_test_split(\n",
        "            X_sub, y_sub_scaled, ycat_sub, stratify=ycat_sub, **split_kwargs\n",
        "        )\n",
        "    else:\n",
        "        X_tr, X_te, y_tr, y_te = train_test_split(X_sub, y_sub_scaled, **split_kwargs)\n",
        "        ycat_tr = ycat_te = None\n",
        "\n",
        "    # Validación (20% del train)\n",
        "    if ycat_tr is not None:\n",
        "        y_tr_raw = y_tr[:,0]\n",
        "        ycat_t = make_strat_labels(y_tr_raw, n_bins=3, min_per_class=2)\n",
        "        if ycat_t is not None:\n",
        "            X_tr, X_va, y_tr, y_va, ycat_tr, ycat_va = train_test_split(\n",
        "                X_tr, y_tr, ycat_tr, test_size=0.20, random_state=seed, stratify=ycat_t\n",
        "            )\n",
        "        else:\n",
        "            X_tr, X_va, y_tr, y_va = train_test_split(\n",
        "                X_tr, y_tr, test_size=0.20, random_state=seed, shuffle=True\n",
        "            )\n",
        "            ycat_va = None\n",
        "    else:\n",
        "        X_tr, X_va, y_tr, y_va = train_test_split(\n",
        "            X_tr, y_tr, test_size=0.20, random_state=seed, shuffle=True\n",
        "        )\n",
        "        ycat_va = None\n",
        "\n",
        "    # Reporte rápido\n",
        "    print(\"Originales (conservados):\", X_orig.shape, y_orig.shape)\n",
        "    print(f\"Subset de {n_sub}:\", X_sub.shape, y_sub.shape)\n",
        "    print(\"Train/Valid/Test:\", X_tr.shape, X_va.shape, X_te.shape)\n",
        "    if ycat_sub is not None:\n",
        "        print(\"Distribución clases subset:\", Counter(ycat_sub))\n",
        "\n",
        "    return {\n",
        "        \"idx_sub\": idx_sub,\n",
        "        \"X_train\": X_tr, \"X_valid\": X_va, \"X_test\": X_te,\n",
        "        \"y_train\": y_tr, \"y_valid\": y_va, \"y_test\": y_te\n",
        "    }\n",
        "from copy import deepcopy\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "def make_tabnet(cat_info, params):\n",
        "    cat_idxs = [i for i, f in enumerate(features) if f in CATEGORICAL_COLUMNS]\n",
        "    cat_dims = [categorical_dims[f] for f in features if f in CATEGORICAL_COLUMNS]\n",
        "    cat_emb_dim = [min(params['emb'], max(4, (dim + 1)//2)) for dim in cat_dims]\n",
        "    return cat_idxs, cat_dims, cat_emb_dim\n",
        "\n",
        "def build_optimizer(optimizer_type, learning_rate, momentum, weight_decay):\n",
        "    if optimizer_type == 'adam':\n",
        "        return torch.optim.Adam, {'lr': float(min(max(learning_rate, 1e-4), 3e-3)), 'weight_decay': weight_decay}\n",
        "    if optimizer_type == 'adamw':\n",
        "        return torch.optim.AdamW, {'lr': float(min(max(learning_rate, 1e-4), 3e-3)), 'weight_decay': weight_decay}\n",
        "    if optimizer_type == 'sgd':\n",
        "        return torch.optim.SGD, {'lr': float(min(max(learning_rate, 1e-3), 1e-1)), 'momentum': momentum, 'weight_decay': weight_decay}\n",
        "    if optimizer_type == 'rmsprop':\n",
        "        return torch.optim.RMSprop, {'lr': float(min(max(learning_rate, 1e-4), 3e-3)), 'momentum': momentum, 'weight_decay': weight_decay}\n",
        "\n",
        "def objective_regression(trial):\n",
        "    # Capacidad TabNet\n",
        "    n_d     = trial.suggest_int('n_d', 8, 32)\n",
        "    n_a     = trial.suggest_int('n_a', 8, 32)\n",
        "    n_steps = trial.suggest_int('n_steps', 3, 5)\n",
        "\n",
        "    gamma         = trial.suggest_float('gamma', 1.0, 2.0)\n",
        "    lambda_sparse = trial.suggest_float('lambda_sparse', 1e-6, 1e-3, log=True)\n",
        "\n",
        "    batch_size  = trial.suggest_categorical('batch_size', [64, 128, 256])\n",
        "    mask_type   = trial.suggest_categorical('mask_type', ['entmax', 'sparsemax'])\n",
        "    emb         = trial.suggest_int('emb', 4, 24)\n",
        "\n",
        "    momentum      = trial.suggest_float('momentum', 0.5, 0.95)\n",
        "    learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-1, log=True)\n",
        "    weight_decay  = trial.suggest_float('weight_decay', 1e-6, 1e-4, log=True)\n",
        "\n",
        "    scheduler_gamma = trial.suggest_float('scheduler_gamma', 0.95, 0.995)\n",
        "    step_size       = trial.suggest_int('step_size', 5, 15)\n",
        "\n",
        "    virtual_batch_size = trial.suggest_categorical('virtual_batch_size', [32, 64])\n",
        "    if isinstance(batch_size, int) and isinstance(virtual_batch_size, int) and virtual_batch_size > batch_size:\n",
        "        virtual_batch_size = batch_size // 2 if batch_size >= 64 else batch_size\n",
        "\n",
        "    optimizer_type = trial.suggest_categorical('optimizer_type', ['adam', 'adamw', 'sgd', 'rmsprop'])\n",
        "    optimizer_fn, optimizer_params = build_optimizer(optimizer_type, learning_rate, momentum, weight_decay)\n",
        "\n",
        "    p   = trial.suggest_float('p', 0.0, 0.30)\n",
        "    aug = RegressionSMOTE(p=p)\n",
        "\n",
        "    cat_idxs = [i for i, f in enumerate(features) if f in CATEGORICAL_COLUMNS]\n",
        "    cat_dims = [categorical_dims[f] for f in features if f in CATEGORICAL_COLUMNS]\n",
        "    cat_emb_dim = [min(emb, max(4, (dim + 1)//2)) for dim in cat_dims]\n",
        "\n",
        "    model = CustomTabNetRegressor(\n",
        "        cat_dims=cat_dims, cat_emb_dim=cat_emb_dim, cat_idxs=cat_idxs,\n",
        "        n_d=n_d, n_a=n_a, n_steps=n_steps, gamma=gamma, lambda_sparse=lambda_sparse,\n",
        "        mask_type=mask_type, optimizer_fn=optimizer_fn, optimizer_params=optimizer_params,\n",
        "        scheduler_params={\"gamma\": scheduler_gamma, \"step_size\": step_size},\n",
        "        scheduler_fn=torch.optim.lr_scheduler.StepLR, verbose=True\n",
        "    )\n",
        "    model.fit(\n",
        "        X_train=X_train, y_train=y_train,\n",
        "        eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
        "        eval_name=['train', 'valid'],\n",
        "        eval_metric=['mae'],\n",
        "        loss_fn=my_r2_score_fn,  # (conserva tu lógica)\n",
        "        max_epochs=100, patience=40,\n",
        "        batch_size=batch_size, virtual_batch_size=virtual_batch_size,\n",
        "        num_workers=1, drop_last=False, augmentations=aug,\n",
        "    )\n",
        "    mae = model.history['loss'][-1]\n",
        "    return mae\n",
        "\n",
        "def eval_and_print(title, clf_model, X_test, y_test):\n",
        "    \"\"\"Evalúa R² en escala original (inverse_transform) y lo imprime.\"\"\"\n",
        "    y_pred = clf_model.predict(X_test)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    print(f\"{title}: R2={r2:.4f}\")\n",
        "    return r2\n",
        "\n",
        "def run_three_training_strategies(\n",
        "    # modelos / kwargs\n",
        "    clf_base,                   # modelo ya entrenado en la Fase 1 (con warm_start=True)\n",
        "    model_init_kwargs,          # dict con los kwargs para construir un modelo nuevo idéntico (desde cero)\n",
        "    # datos antiguos (Fase 1)\n",
        "    X_train_old, y_train_old,   # típicamente (X_train, y_train[:,0:1]) de los 1000\n",
        "    X_test_old, y_test_old,  # test y scaler usados en la Fase 1\n",
        "    # datos nuevos (Fase 2)\n",
        "    X_tr_new, y_tr_new,         # train de los 500\n",
        "    X_va_new, y_va_new,         # valid de los 500 (para early stopping)\n",
        "    X_te_new, y_te_new,  # test nuevo y su scaler\n",
        "    # entrenamiento\n",
        "    batch_size, virtual_batch_size, aug,\n",
        "    max_epochs_ft_inc=200, patience_ft_inc=70,\n",
        "    max_epochs_ft_new=200, patience_ft_new=70,\n",
        "    max_epochs_scratch=200, patience_scratch=70,\n",
        "    lower_lr_factor=0.1, min_lr=1e-5\n",
        "):\n",
        "    \"\"\"\n",
        "    Ejecuta:\n",
        "      A) Fine-tuning incremental (old + new)\n",
        "      B) Fine-tuning no incremental (solo new)\n",
        "      C) Desde cero (old + new)\n",
        "    y evalúa R² en test viejo y test nuevo (ambos en escala original).\n",
        "    Devuelve un dict con los R².\n",
        "    \"\"\"\n",
        "    results = {}\n",
        "\n",
        "    # =============================\n",
        "    # A) Fine-tuning incremental\n",
        "    # =============================\n",
        "    clf_ft_inc = deepcopy(clf_base)  # copia del clf ya entrenado\n",
        "    # bajar LR para fine-tune (opcional, recomendado)\n",
        "    if hasattr(clf_ft_inc, \"_optimizer\"):\n",
        "        for g in clf_ft_inc._optimizer.param_groups:\n",
        "            g[\"lr\"] = max(g[\"lr\"] * lower_lr_factor, min_lr)\n",
        "\n",
        "    X_inc = np.concatenate([X_train_old, X_tr_new], axis=0)\n",
        "    y_inc = np.concatenate([y_train_old, y_tr_new], axis=0)\n",
        "\n",
        "    clf_ft_inc.fit(\n",
        "        X_train=X_inc, y_train=y_inc,\n",
        "        eval_set=[(X_inc, y_inc), (X_va_new, y_va_new)],\n",
        "        eval_name=['train_inc', 'valid_new'],\n",
        "        eval_metric=['mae'], loss_fn=my_r2_score_fn,\n",
        "        max_epochs=max_epochs_ft_inc, patience=patience_ft_inc,\n",
        "        batch_size=batch_size, virtual_batch_size=virtual_batch_size,\n",
        "        num_workers=1, drop_last=False, augmentations=aug,\n",
        "    )\n",
        "\n",
        "    print(\"\\n== Desempeño: Fine-tuning incremental ==\")\n",
        "    r2_old_inc = eval_and_print(\"Test viejo (FT incremental)\", clf_ft_inc, X_test_old, y_test_old)\n",
        "    r2_new_inc = eval_and_print(\"Test nuevo (FT incremental)\", clf_ft_inc, X_te_new,  y_te_new)\n",
        "    results[\"fine_tune_incremental\"] = {\"R2_old_test\": r2_old_inc, \"R2_new_test\": r2_new_inc, \"model\": clf_ft_inc}\n",
        "\n",
        "    # =============================\n",
        "    # B) Fine-tuning no incremental (solo nuevos)\n",
        "    # =============================\n",
        "    clf_ft_new = deepcopy(clf_base)\n",
        "    if hasattr(clf_ft_new, \"_optimizer\"):\n",
        "        for g in clf_ft_new._optimizer.param_groups:\n",
        "            g[\"lr\"] = max(g[\"lr\"] * lower_lr_factor, min_lr)\n",
        "\n",
        "    clf_ft_new.fit(\n",
        "        X_train=X_tr_new, y_train=y_tr_new,\n",
        "        eval_set=[(X_tr_new, y_tr_new), (X_va_new, y_va_new)],\n",
        "        eval_name=['train_new', 'valid_new'],\n",
        "        eval_metric=['mae'], loss_fn=my_r2_score_fn,\n",
        "        max_epochs=max_epochs_ft_new, patience=patience_ft_new,\n",
        "        batch_size=batch_size, virtual_batch_size=virtual_batch_size,\n",
        "        num_workers=1, drop_last=False, augmentations=aug,\n",
        "    )\n",
        "\n",
        "    print(\"\\n== Desempeño: Fine-tuning NO incremental (solo nuevos) ==\")\n",
        "    r2_old_new = eval_and_print(\"Test viejo (FT no incremental)\", clf_ft_new, X_test_old, y_test_old)\n",
        "    r2_new_new = eval_and_print(\"Test nuevo (FT no incremental)\", clf_ft_new, X_te_new,  y_te_new)\n",
        "    results[\"fine_tune_only_new\"] = {\"R2_old_test\": r2_old_new, \"R2_new_test\": r2_new_new, \"model\": clf_ft_new}\n",
        "\n",
        "    # =============================\n",
        "    # C) Desde cero (cumulative old+new)\n",
        "    # =============================\n",
        "    # model_init_kwargs debe contener todo lo necesario para reconstruir el TabNet\n",
        "    clf_scratch = CustomTabNetRegressor(**model_init_kwargs)\n",
        "\n",
        "    X_cum = np.concatenate([X_train_old, X_tr_new], axis=0)\n",
        "    y_cum = np.concatenate([y_train_old, y_tr_new], axis=0)\n",
        "\n",
        "    clf_scratch.fit(\n",
        "        X_train=X_cum, y_train=y_cum,\n",
        "        eval_set=[(X_cum, y_cum), (X_va_new, y_va_new)],\n",
        "        eval_name=['train_cum', 'valid_new'],\n",
        "        eval_metric=['mae'], loss_fn=my_r2_score_fn,\n",
        "        max_epochs=max_epochs_scratch, patience=patience_scratch,\n",
        "        batch_size=batch_size, virtual_batch_size=virtual_batch_size,\n",
        "        num_workers=1, drop_last=False, augmentations=aug,\n",
        "    )\n",
        "\n",
        "    print(\"\\n== Desempeño: Desde cero (old+new) ==\")\n",
        "    r2_old_sc = eval_and_print(\"Test viejo (desde cero)\", clf_scratch, X_test_old, y_test_old)\n",
        "    r2_new_sc = eval_and_print(\"Test nuevo (desde cero)\", clf_scratch, X_te_new,  y_te_new)\n",
        "    results[\"from_scratch\"] = {\"R2_old_test\": r2_old_sc, \"R2_new_test\": r2_new_sc, \"model\": clf_scratch}\n",
        "    return results\n",
        "def pick_new_indices(n_new=500, seed=123):\n",
        "    rng = np.random.RandomState(seed)\n",
        "    universe = np.setdiff1d(np.arange(X.shape[0]), splits_1000[\"idx_sub\"], assume_unique=True)\n",
        "    n_new = min(n_new, universe.shape[0])\n",
        "    return rng.choice(universe, size=n_new, replace=False)\n",
        "Xdata = df = pd.read_pickle('/content/CHEC/SuperEventos_Criticidad_AguasAbajo_CODEs.pkl')\n",
        "Xdata = Xdata[Xdata['duracion_h'] <= 100]\n",
        "# ---------------------------------------------------------\n",
        "# Etapa 1: seleccionar objetivo (SAIDI o SAIFI) con forma (N,1)\n",
        "# Extraer variables objetivo\n",
        "Dur_h = Xdata['duracion_h'].values\n",
        "SAIDI = Xdata['SAIDI'].values\n",
        "df1=Xdata.copy()\n",
        "# Eliminar columnas no utilizadas\n",
        "Xdata.drop(['inicio_evento', 'h0-solar_rad', 'h0-uv', 'h1-solar_rad', 'h1-uv', 'h2-solar_rad', 'h2-uv', 'h3-solar_rad', 'h3-uv',\n",
        "            'h4-solar_rad', 'h4-uv', 'h5-solar_rad', 'h5-uv', 'h19-solar_rad', 'h19-uv', 'h20-solar_rad', 'h20-uv',\n",
        "            'h21-solar_rad', 'h21-uv', 'h22-solar_rad', 'h22-uv', 'h23-solar_rad', 'h23-uv', 'evento', 'fin', 'inicio',\n",
        "            'cnt_usus', 'DEP', 'MUN', 'FECHA', 'NIVEL_C', 'VALOR_C', 'TRAMOS_AGUAS_ABAJO', 'EQUIPOS_PUNTOS',\n",
        "            'PUNTOS_POLIGONO', 'LONGITUD2', 'LATITUD2', 'FECHA_C','TRAMOS_AGUAS_ABAJO_CODES','ORDER_'],\n",
        "           inplace=True, axis=1)\n",
        "\n",
        "# Definir la variable objetivo y eliminarla del conjunto de características\n",
        "target = ['SAIFI', 'SAIDI', 'duracion_h']\n",
        "y1 = Xdata[target].values\n",
        "Xdata.drop(target, axis=1, inplace=True)\n",
        "y = y1[:, 0:1].astype('float32')\n",
        "\n",
        "# Copia de trabajo de X\n",
        "df = Xdata.copy()\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Etapa 2: tipificar columnas\n",
        "NUMERIC_COLUMNS = df.select_dtypes(include=['number']).columns.tolist()\n",
        "CATEGORICAL_COLUMNS = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Etapa 3: imputación numérica\n",
        "max_values = {}\n",
        "for col in NUMERIC_COLUMNS:\n",
        "    max_value = pd.to_numeric(df[col], errors='coerce').max()\n",
        "    if pd.isna(max_value):\n",
        "        max_value = 0.0\n",
        "    max_values[col] = max_value\n",
        "    df[col] = pd.to_numeric(df[col], errors='coerce').fillna(-10.0 * max_value)\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Etapa 4: codificación categórica\n",
        "label_encoders = {}\n",
        "categorical_dims = {}\n",
        "for col in CATEGORICAL_COLUMNS:\n",
        "    enc = LabelEncoder()\n",
        "    s = df[col].astype(str).fillna(\"no aplica\")\n",
        "    enc.fit(s)\n",
        "    df[col] = enc.transform(s)\n",
        "    label_encoders[col] = enc\n",
        "    categorical_dims[col] = len(enc.classes_)\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Etapa 5: construir matrices X, y\n",
        "unused_feat = []\n",
        "# Si Xdata NO incluye el target, basta con tomar todas las columnas\n",
        "features = [c for c in df.columns if c not in unused_feat]\n",
        "X = df[features].values.astype('float32')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Incorporación de nuevas características"
      ],
      "metadata": {
        "id": "dnosfi5dEm8G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Xdata = df = pd.read_pickle('/content/CHEC/SuperEventos_Criticidad_AguasAbajo_CODEs.pkl')\n",
        "Xdata = Xdata[Xdata['duracion_h'] <= 100]\n",
        "Xdata = Xdata.iloc[:1000]\n",
        "Rayos=pd.read_pickle('/content/CHEC/Data_CHEC/Rayos.pkl')\n",
        "Rayos['FECHA'] = pd.to_datetime(Rayos['FECHA'])\n",
        "Vegetacion=pd.read_pickle('/content/CHEC/Data_CHEC/Vegetacion.pkl')\n",
        "Vegetacion['LATITUD'] = Vegetacion['LATITUD'].astype(float)\n",
        "Vegetacion['LONGITUD'] = Vegetacion['LONGITUD'].astype(float)"
      ],
      "metadata": {
        "id": "92Dtwt15lYTo"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Rayos.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Zrr72ii8d70p",
        "outputId": "291b239d-5626-40ce-903d-25e8bd32e850"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                ID  LATITUD  LONGITUD ALTITUD  TIPO  CORRIENTE  ERROR   CODE  \\\n",
              "0  202009191522446   4.9487  -75.5995    12,4     2       -5.3  0,016   1657   \n",
              "1    2020076142486   4.9488  -75.7033       0     1       -5.8  0,061  58412   \n",
              "2   20200784256395   4.9488  -75.6958     6,6     2        5.2  0,016   4244   \n",
              "3  202008193652495   4.6288  -75.6113    10,1     2        5.0  0,003   A186   \n",
              "4   20200823350497   4.9488  -76.0051       0     1      -24.7  0,145  36021   \n",
              "\n",
              "    FPARENT  DISTANCIA_A_NODO               FECHA        DEP  \\\n",
              "0  CHA23L16         78.252413 2020-09-03 14:15:22     CALDAS   \n",
              "1  INS23L13         24.710599 2020-07-10 01:01:42  RISARALDA   \n",
              "2  INS23L13         35.126961 2020-07-04 03:42:56  RISARALDA   \n",
              "3  ROS40L21        289.085969 2020-08-22 14:36:52    QUINDÍO   \n",
              "4  BOA23L14        354.305040 2020-08-13 18:35:04  RISARALDA   \n",
              "\n",
              "                   MUN  \n",
              "0           VILLAMARÍA  \n",
              "1  SANTA ROSA DE CABAL  \n",
              "2  SANTA ROSA DE CABAL  \n",
              "3             CIRCASIA  \n",
              "4               BALBOA  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c7830a10-aeb0-4c81-98be-8c67af18bdfd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>LATITUD</th>\n",
              "      <th>LONGITUD</th>\n",
              "      <th>ALTITUD</th>\n",
              "      <th>TIPO</th>\n",
              "      <th>CORRIENTE</th>\n",
              "      <th>ERROR</th>\n",
              "      <th>CODE</th>\n",
              "      <th>FPARENT</th>\n",
              "      <th>DISTANCIA_A_NODO</th>\n",
              "      <th>FECHA</th>\n",
              "      <th>DEP</th>\n",
              "      <th>MUN</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>202009191522446</td>\n",
              "      <td>4.9487</td>\n",
              "      <td>-75.5995</td>\n",
              "      <td>12,4</td>\n",
              "      <td>2</td>\n",
              "      <td>-5.3</td>\n",
              "      <td>0,016</td>\n",
              "      <td>1657</td>\n",
              "      <td>CHA23L16</td>\n",
              "      <td>78.252413</td>\n",
              "      <td>2020-09-03 14:15:22</td>\n",
              "      <td>CALDAS</td>\n",
              "      <td>VILLAMARÍA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020076142486</td>\n",
              "      <td>4.9488</td>\n",
              "      <td>-75.7033</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-5.8</td>\n",
              "      <td>0,061</td>\n",
              "      <td>58412</td>\n",
              "      <td>INS23L13</td>\n",
              "      <td>24.710599</td>\n",
              "      <td>2020-07-10 01:01:42</td>\n",
              "      <td>RISARALDA</td>\n",
              "      <td>SANTA ROSA DE CABAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20200784256395</td>\n",
              "      <td>4.9488</td>\n",
              "      <td>-75.6958</td>\n",
              "      <td>6,6</td>\n",
              "      <td>2</td>\n",
              "      <td>5.2</td>\n",
              "      <td>0,016</td>\n",
              "      <td>4244</td>\n",
              "      <td>INS23L13</td>\n",
              "      <td>35.126961</td>\n",
              "      <td>2020-07-04 03:42:56</td>\n",
              "      <td>RISARALDA</td>\n",
              "      <td>SANTA ROSA DE CABAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>202008193652495</td>\n",
              "      <td>4.6288</td>\n",
              "      <td>-75.6113</td>\n",
              "      <td>10,1</td>\n",
              "      <td>2</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0,003</td>\n",
              "      <td>A186</td>\n",
              "      <td>ROS40L21</td>\n",
              "      <td>289.085969</td>\n",
              "      <td>2020-08-22 14:36:52</td>\n",
              "      <td>QUINDÍO</td>\n",
              "      <td>CIRCASIA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20200823350497</td>\n",
              "      <td>4.9488</td>\n",
              "      <td>-76.0051</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-24.7</td>\n",
              "      <td>0,145</td>\n",
              "      <td>36021</td>\n",
              "      <td>BOA23L14</td>\n",
              "      <td>354.305040</td>\n",
              "      <td>2020-08-13 18:35:04</td>\n",
              "      <td>RISARALDA</td>\n",
              "      <td>BALBOA</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c7830a10-aeb0-4c81-98be-8c67af18bdfd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c7830a10-aeb0-4c81-98be-8c67af18bdfd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c7830a10-aeb0-4c81-98be-8c67af18bdfd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-8bf715fd-45f4-4ea2-ba84-df8b28e5badd\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8bf715fd-45f4-4ea2-ba84-df8b28e5badd')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-8bf715fd-45f4-4ea2-ba84-df8b28e5badd button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "Rayos"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Rayos.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XsIZ4zw1eQDF",
        "outputId": "4ed165cc-d4ac-46f1-938a-e2a0c348c06d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['ID', 'LATITUD', 'LONGITUD', 'ALTITUD', 'TIPO', 'CORRIENTE', 'ERROR',\n",
              "       'CODE', 'FPARENT', 'DISTANCIA_A_NODO', 'FECHA', 'DEP', 'MUN'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Vegetacion.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "EUyfx2xZNCq7",
        "outputId": "139e4a98-6370-403e-b93c-d43bb3b6f3f9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   NOM_COMUN      TIPO_VEGET ESTADO_INICIAL      FECHA LADO_RED  DAP_ESTIM  \\\n",
              "0     YARUMO  Bosque natural          Nuevo 2023-11-30   Debajo         22   \n",
              "1     GUADUA         Guadual          Nuevo 2023-11-30   Debajo         11   \n",
              "2  MANDARINO        Frutales          Nuevo 2023-11-30   Debajo         28   \n",
              "3      GUAMO    Cafe/sombrio          Nuevo 2023-11-30   Debajo         45   \n",
              "4     GUADUA         Guadual          Nuevo 2023-11-30   Debajo         12   \n",
              "\n",
              "   LONG_INTER TIPO_INTER NIVEL_RIES CIRCUITO_TRAMO  NODO_1  NODO_2   LONGITUD  \\\n",
              "0           6    Rocería      Medio       ESM40L27  A06084  A06085 -75.714305   \n",
              "1           6       Tala      Medio       ESM40L27  A06089  A06090 -75.726387   \n",
              "2           6       Poda       Alto       ESM40L28  A06059  A06060 -75.645768   \n",
              "3           6       Poda      Medio       ESM40L27  A06070  A06071 -75.674651   \n",
              "4           6       Tala      Medio       ESM40L27  A06087  A06088 -75.723988   \n",
              "\n",
              "    LATITUD        DEP        MUN  \n",
              "0  5.013050  RISARALDA   MARSELLA  \n",
              "1  5.023843  RISARALDA   MARSELLA  \n",
              "2  4.992025     CALDAS  CHINCHINÁ  \n",
              "3  4.993295     CALDAS  CHINCHINÁ  \n",
              "4  5.018694  RISARALDA   MARSELLA  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a0ca2405-aafd-4a01-89e9-61c09a8f3fa7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>NOM_COMUN</th>\n",
              "      <th>TIPO_VEGET</th>\n",
              "      <th>ESTADO_INICIAL</th>\n",
              "      <th>FECHA</th>\n",
              "      <th>LADO_RED</th>\n",
              "      <th>DAP_ESTIM</th>\n",
              "      <th>LONG_INTER</th>\n",
              "      <th>TIPO_INTER</th>\n",
              "      <th>NIVEL_RIES</th>\n",
              "      <th>CIRCUITO_TRAMO</th>\n",
              "      <th>NODO_1</th>\n",
              "      <th>NODO_2</th>\n",
              "      <th>LONGITUD</th>\n",
              "      <th>LATITUD</th>\n",
              "      <th>DEP</th>\n",
              "      <th>MUN</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>YARUMO</td>\n",
              "      <td>Bosque natural</td>\n",
              "      <td>Nuevo</td>\n",
              "      <td>2023-11-30</td>\n",
              "      <td>Debajo</td>\n",
              "      <td>22</td>\n",
              "      <td>6</td>\n",
              "      <td>Rocería</td>\n",
              "      <td>Medio</td>\n",
              "      <td>ESM40L27</td>\n",
              "      <td>A06084</td>\n",
              "      <td>A06085</td>\n",
              "      <td>-75.714305</td>\n",
              "      <td>5.013050</td>\n",
              "      <td>RISARALDA</td>\n",
              "      <td>MARSELLA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>GUADUA</td>\n",
              "      <td>Guadual</td>\n",
              "      <td>Nuevo</td>\n",
              "      <td>2023-11-30</td>\n",
              "      <td>Debajo</td>\n",
              "      <td>11</td>\n",
              "      <td>6</td>\n",
              "      <td>Tala</td>\n",
              "      <td>Medio</td>\n",
              "      <td>ESM40L27</td>\n",
              "      <td>A06089</td>\n",
              "      <td>A06090</td>\n",
              "      <td>-75.726387</td>\n",
              "      <td>5.023843</td>\n",
              "      <td>RISARALDA</td>\n",
              "      <td>MARSELLA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>MANDARINO</td>\n",
              "      <td>Frutales</td>\n",
              "      <td>Nuevo</td>\n",
              "      <td>2023-11-30</td>\n",
              "      <td>Debajo</td>\n",
              "      <td>28</td>\n",
              "      <td>6</td>\n",
              "      <td>Poda</td>\n",
              "      <td>Alto</td>\n",
              "      <td>ESM40L28</td>\n",
              "      <td>A06059</td>\n",
              "      <td>A06060</td>\n",
              "      <td>-75.645768</td>\n",
              "      <td>4.992025</td>\n",
              "      <td>CALDAS</td>\n",
              "      <td>CHINCHINÁ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>GUAMO</td>\n",
              "      <td>Cafe/sombrio</td>\n",
              "      <td>Nuevo</td>\n",
              "      <td>2023-11-30</td>\n",
              "      <td>Debajo</td>\n",
              "      <td>45</td>\n",
              "      <td>6</td>\n",
              "      <td>Poda</td>\n",
              "      <td>Medio</td>\n",
              "      <td>ESM40L27</td>\n",
              "      <td>A06070</td>\n",
              "      <td>A06071</td>\n",
              "      <td>-75.674651</td>\n",
              "      <td>4.993295</td>\n",
              "      <td>CALDAS</td>\n",
              "      <td>CHINCHINÁ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>GUADUA</td>\n",
              "      <td>Guadual</td>\n",
              "      <td>Nuevo</td>\n",
              "      <td>2023-11-30</td>\n",
              "      <td>Debajo</td>\n",
              "      <td>12</td>\n",
              "      <td>6</td>\n",
              "      <td>Tala</td>\n",
              "      <td>Medio</td>\n",
              "      <td>ESM40L27</td>\n",
              "      <td>A06087</td>\n",
              "      <td>A06088</td>\n",
              "      <td>-75.723988</td>\n",
              "      <td>5.018694</td>\n",
              "      <td>RISARALDA</td>\n",
              "      <td>MARSELLA</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a0ca2405-aafd-4a01-89e9-61c09a8f3fa7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a0ca2405-aafd-4a01-89e9-61c09a8f3fa7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a0ca2405-aafd-4a01-89e9-61c09a8f3fa7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-199de928-ff4d-4716-b6e1-30994801b279\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-199de928-ff4d-4716-b6e1-30994801b279')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-199de928-ff4d-4716-b6e1-30994801b279 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "Vegetacion",
              "summary": "{\n  \"name\": \"Vegetacion\",\n  \"rows\": 18482,\n  \"fields\": [\n    {\n      \"column\": \"NOM_COMUN\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 181,\n        \"samples\": [\n          \"ARRAYAN\",\n          \"TACHUELO\",\n          \"ZAPOTE COSTENO\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TIPO_VEGET\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 16,\n        \"samples\": [\n          \"Bosque natural\",\n          \"Guadual\",\n          \"Rastrojo\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ESTADO_INICIAL\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"Nuevo\",\n          \"Ejecutado\",\n          \"Existente\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FECHA\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2016-08-24 00:00:00\",\n        \"max\": \"2024-09-17 00:00:00\",\n        \"num_unique_values\": 411,\n        \"samples\": [\n          \"2024-07-01 00:00:00\",\n          \"2022-11-16 00:00:00\",\n          \"2024-03-22 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LADO_RED\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"Un lado\",\n          \"Derecha\",\n          \"Debajo\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DAP_ESTIM\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 26,\n        \"min\": 0,\n        \"max\": 1000,\n        \"num_unique_values\": 106,\n        \"samples\": [\n          92,\n          100,\n          12\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LONG_INTER\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1168,\n        \"min\": 0,\n        \"max\": 158912,\n        \"num_unique_values\": 84,\n        \"samples\": [\n          37,\n          6,\n          120\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TIPO_INTER\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"Tala\",\n          \" \",\n          \"Rocer\\u00eda\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"NIVEL_RIES\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"Medio\",\n          \"Alto\",\n          \"Potencial\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CIRCUITO_TRAMO\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 213,\n        \"samples\": [\n          \"SNA23L15\",\n          \"RIO30L12\",\n          \"SIO23L14\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"NODO_1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9351,\n        \"samples\": [\n          \"W30646\",\n          \"B20164\",\n          \"B38063\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"NODO_2\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9825,\n        \"samples\": [\n          \"W33171\",\n          \"L17410\",\n          \"M10037\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LONGITUD\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4041674559757641,\n        \"min\": -76.20494234,\n        \"max\": -74.64997614,\n        \"num_unique_values\": 18080,\n        \"samples\": [\n          -75.73091437,\n          -75.600309,\n          -74.70046517\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LATITUD\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.20856029881161403,\n        \"min\": 4.569118596,\n        \"max\": 5.79366362,\n        \"num_unique_values\": 18252,\n        \"samples\": [\n          4.946111731,\n          5.28692,\n          5.1087307\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DEP\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"RISARALDA\",\n          \"CALDAS\",\n          \"QUIND\\u00cdO\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MUN\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 43,\n        \"samples\": [\n          \"PEREIRA\",\n          \"LA MERCED\",\n          \"AP\\u00cdA\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Vegetacion.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z84YCqKZeSxu",
        "outputId": "ee57fe93-76a5-4475-bd3f-35add60f16e0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['NOM_COMUN', 'TIPO_VEGET', 'ESTADO_INICIAL', 'FECHA', 'LADO_RED',\n",
              "       'DAP_ESTIM', 'LONG_INTER', 'TIPO_INTER', 'NIVEL_RIES', 'CIRCUITO_TRAMO',\n",
              "       'NODO_1', 'NODO_2', 'LONGITUD', 'LATITUD', 'DEP', 'MUN'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Xdata.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGHbRGV7f8a5",
        "outputId": "cba6b8fb-7e6d-44c8-c1cf-81aca5de11c7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 355)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.spatial import cKDTree\n",
        "from pandas.api.types import is_numeric_dtype\n",
        "from ast import literal_eval\n",
        "from tqdm import tqdm\n",
        "\n",
        "def enriquecer_eventos_con_rayos_y_vegetacion(\n",
        "    Eventos: pd.DataFrame,\n",
        "    Rayos: pd.DataFrame,\n",
        "    Vegetacion: pd.DataFrame,\n",
        "    *,\n",
        "    radio_rayos: float = 0.005,        # ~0.5 km en grados aprox.\n",
        "    ventana_dias: int = 1,             # [inicio - ventana_dias, inicio]\n",
        "    radio_vegetacion: float = 0.0003,  # ~30 m aprox. en grados\n",
        "    veg_vars: list | None = None,      # variables de interés en Vegetación\n",
        "    usar_tqdm: bool = True,\n",
        "    col_lat: str = 'LATITUD',\n",
        "    col_lon: str = 'LONGITUD'\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Para cada evento, toma TODAS las (LATITUD,LONGITUD) únicas de su municipio (MUN)\n",
        "    como puntos de consulta y busca alrededor:\n",
        "      - RAYOS: dentro de radio_rayos y en la ventana temporal [inicio - ventana_dias, inicio].\n",
        "      - VEGETACIÓN: dentro de radio_vegetacion (solo espacial).\n",
        "\n",
        "    Vegetación:\n",
        "      * 'conteo_vegetacion'\n",
        "      * Para cada var en veg_vars:\n",
        "          - Si es numérica (o numérico-like): {mean, median, min, max, std} (std=0 si 1 dato)\n",
        "          - Si es categórica: {mode}. Si var == 'NOM_COMUN' -> columna 'nombre_comun_mas_frecuente'\n",
        "    \"\"\"\n",
        "\n",
        "    # ---------------------------\n",
        "    # Normalización de insumos\n",
        "    # ---------------------------\n",
        "    Eventos = Eventos.copy()\n",
        "\n",
        "    # Asegurar tipos numéricos de lat/lon y fecha en Rayos / Vegetación\n",
        "    for df in (Rayos, Vegetacion, Eventos):\n",
        "        for c in (col_lat, col_lon):\n",
        "            if c in df.columns:\n",
        "                df[c] = pd.to_numeric(df[c], errors='coerce')\n",
        "\n",
        "    if 'FECHA' in Rayos.columns:\n",
        "        Rayos['FECHA'] = pd.to_datetime(Rayos['FECHA'], errors='coerce')\n",
        "    if 'inicio' in Eventos.columns:\n",
        "        Eventos['inicio'] = pd.to_datetime(Eventos['inicio'], errors='coerce')\n",
        "\n",
        "    if 'MUN' not in Eventos.columns:\n",
        "        raise ValueError(\"Eventos debe contener la columna 'MUN'.\")\n",
        "\n",
        "    # ---------------------------\n",
        "    # Helpers\n",
        "    # ---------------------------\n",
        "    def _build_kd_by_group(df, key_col='MUN', lat=col_lat, lon=col_lon):\n",
        "        \"\"\"Construye KDTree por grupo, alineado a índices tras dropna.\"\"\"\n",
        "        trees = {}\n",
        "        for k, g in df.groupby(key_col):\n",
        "            mask = g[[lat, lon]].notna().all(axis=1)\n",
        "            g_f = g.loc[mask]\n",
        "            if not g_f.empty:\n",
        "                coords = g_f[[lat, lon]].to_numpy()\n",
        "                trees[k] = (cKDTree(coords), g_f)\n",
        "        return trees\n",
        "\n",
        "    def _query_indices_for_points(tree, points, r):\n",
        "        \"\"\"Une índices cercanos para múltiples puntos.\"\"\"\n",
        "        idxs = set()\n",
        "        for (lat, lon) in points:\n",
        "            try:\n",
        "                lat = float(lat); lon = float(lon)\n",
        "            except Exception:\n",
        "                continue\n",
        "            idxs.update(tree.query_ball_point([lat, lon], r=r))\n",
        "        return idxs\n",
        "\n",
        "    def _std_safe(s: pd.Series):\n",
        "        s = pd.to_numeric(s, errors='coerce').dropna()\n",
        "        return 0.0 if len(s) <= 1 else float(s.std())\n",
        "\n",
        "    def _is_numeric_like(series: pd.Series) -> bool:\n",
        "        \"\"\"Decide si tratar una variable como numérica (dtype numérico o ≥60% convertible).\"\"\"\n",
        "        if is_numeric_dtype(series):\n",
        "            return True\n",
        "        s_num = pd.to_numeric(series, errors='coerce')\n",
        "        return s_num.notna().mean() >= 0.60\n",
        "\n",
        "    def _veg_out_cols_for(var: str, kind: str) -> list[str]:\n",
        "        \"\"\"Define columnas de salida para cada variable.\"\"\"\n",
        "        if kind == 'numeric':\n",
        "            return [f'{var}_mean', f'{var}_median', f'{var}_min', f'{var}_max', f'{var}_std']\n",
        "        # categórica\n",
        "        if var == 'NOM_COMUN':\n",
        "            return ['nombre_comun_mas_frecuente']\n",
        "        return [f'{var}_mode']\n",
        "\n",
        "    def _veg_empty_vals_for(kind: str) -> list:\n",
        "        if kind == 'numeric':\n",
        "            return [np.nan, np.nan, np.nan, np.nan, 0.0]\n",
        "        return [np.nan]  # categórica\n",
        "\n",
        "    # ---------------------------\n",
        "    # Puntos por municipio (cache)\n",
        "    # ---------------------------\n",
        "    pts_cache_mun: dict = {}\n",
        "    if (col_lat in Eventos.columns) and (col_lon in Eventos.columns):\n",
        "        tmp = (\n",
        "            Eventos[['MUN', col_lat, col_lon]]\n",
        "            .dropna()\n",
        "            .drop_duplicates()\n",
        "        )\n",
        "        for k, g in tmp.groupby('MUN'):\n",
        "            pts_cache_mun[k] = [ (float(a), float(b)) for a, b in g[[col_lat, col_lon]].to_numpy() ]\n",
        "    else:\n",
        "        # Si no hay LATITUD/LONGITUD en Eventos, no hay puntos municipio-latlon\n",
        "        pts_cache_mun = {}\n",
        "\n",
        "    # ---------------------------------------------------------------------\n",
        "    # (1) RAYOS\n",
        "    # ---------------------------------------------------------------------\n",
        "    rayos_trees = _build_kd_by_group(Rayos, key_col='MUN', lat=col_lat, lon=col_lon)\n",
        "\n",
        "    cols_rayos = [\n",
        "        'ALTITUD_mean', 'ALTITUD_median', 'ALTITUD_min', 'ALTITUD_max', 'ALTITUD_std',\n",
        "        'CORRIENTE_mean', 'CORRIENTE_median', 'CORRIENTE_min', 'CORRIENTE_max', 'CORRIENTE_std',\n",
        "        'TIPO_1_count', 'TIPO_2_count'\n",
        "    ]\n",
        "    out_rayos = []\n",
        "\n",
        "    iterator = Eventos.itertuples()\n",
        "    pbar = tqdm(total=len(Eventos), desc='Rayos (por lat/lon de municipio)') if usar_tqdm else None\n",
        "    for ev in iterator:\n",
        "        mun = getattr(ev, 'MUN', None)\n",
        "        inicio = pd.to_datetime(getattr(ev, 'inicio', pd.NaT), errors='coerce')\n",
        "        puntos = pts_cache_mun.get(mun, [])\n",
        "\n",
        "        if not mun or mun not in rayos_trees or not puntos or pd.isna(inicio):\n",
        "            out_rayos.append([np.nan]*len(cols_rayos))\n",
        "            if pbar: pbar.update(1)\n",
        "            continue\n",
        "\n",
        "        _, rayos_mun = rayos_trees[mun]\n",
        "        rayos_mun = rayos_mun.dropna(subset=[col_lat, col_lon, 'FECHA'])\n",
        "        if rayos_mun.empty:\n",
        "            out_rayos.append([np.nan]*len(cols_rayos))\n",
        "            if pbar: pbar.update(1)\n",
        "            continue\n",
        "\n",
        "        rayos_temp = rayos_mun[(rayos_mun['FECHA'] >= inicio - pd.Timedelta(days=ventana_dias)) &\n",
        "                               (rayos_mun['FECHA'] <= inicio)]\n",
        "        if rayos_temp.empty:\n",
        "            out_rayos.append([np.nan]*len(cols_rayos))\n",
        "            if pbar: pbar.update(1)\n",
        "            continue\n",
        "\n",
        "        tree_temp = cKDTree(rayos_temp[[col_lat, col_lon]].to_numpy())\n",
        "        idxs = _query_indices_for_points(tree_temp, puntos, r=radio_rayos)\n",
        "        if not idxs:\n",
        "            out_rayos.append([np.nan]*len(cols_rayos))\n",
        "            if pbar: pbar.update(1)\n",
        "            continue\n",
        "\n",
        "        sub = rayos_temp.iloc[list(idxs)].copy()\n",
        "        if 'ALTITUD' in sub.columns:\n",
        "            sub['ALTITUD'] = pd.to_numeric(sub['ALTITUD'], errors='coerce')\n",
        "        else:\n",
        "            sub['ALTITUD'] = np.nan\n",
        "\n",
        "        if 'CORRIENTE' in sub.columns:\n",
        "            sub['CORRIENTE'] = pd.to_numeric(sub['CORRIENTE'], errors='coerce').abs()\n",
        "        else:\n",
        "            sub['CORRIENTE'] = np.nan\n",
        "\n",
        "        tipo_col = 'TIPO' if 'TIPO' in sub.columns else None\n",
        "        out_rayos.append([\n",
        "            sub['ALTITUD'].mean(), sub['ALTITUD'].median(), sub['ALTITUD'].min(), sub['ALTITUD'].max(), _std_safe(sub['ALTITUD']),\n",
        "            sub['CORRIENTE'].mean(), sub['CORRIENTE'].median(), sub['CORRIENTE'].min(), sub['CORRIENTE'].max(), _std_safe(sub['CORRIENTE']),\n",
        "            (sub[tipo_col] == 1).sum() if tipo_col else np.nan,\n",
        "            (sub[tipo_col] == 2).sum() if tipo_col else np.nan,\n",
        "        ])\n",
        "\n",
        "        if pbar: pbar.update(1)\n",
        "    if pbar: pbar.close()\n",
        "\n",
        "    df_rayos = pd.DataFrame(out_rayos, columns=cols_rayos, index=Eventos.index)\n",
        "    Eventos.loc[df_rayos.index, df_rayos.columns] = df_rayos\n",
        "\n",
        "    # ---------------------------------------------------------------------\n",
        "    # (2) VEGETACIÓN (dinámico por veg_vars)\n",
        "    # ---------------------------------------------------------------------\n",
        "    if veg_vars is None:\n",
        "        veg_vars = ['NOM_COMUN'] if 'NOM_COMUN' in Vegetacion.columns else []\n",
        "\n",
        "    # Clasificar variables (forzar 'NOM_COMUN' como categórica)\n",
        "    veg_specs = []\n",
        "    for var in veg_vars:\n",
        "        if var not in Vegetacion.columns:\n",
        "            veg_specs.append((var, 'missing'))\n",
        "        else:\n",
        "            if var == 'NOM_COMUN':\n",
        "                kind = 'cat'\n",
        "            else:\n",
        "                kind = 'numeric' if _is_numeric_like(Vegetacion[var]) else 'cat'\n",
        "            veg_specs.append((var, kind))\n",
        "\n",
        "    # Armar columnas de salida\n",
        "    cols_veg = ['conteo_vegetacion']\n",
        "    for var, kind in veg_specs:\n",
        "        cols_veg += _veg_out_cols_for(var, kind if kind != 'missing' else 'cat')\n",
        "\n",
        "    veg_trees = _build_kd_by_group(Vegetacion, key_col='MUN', lat=col_lat, lon=col_lon)\n",
        "    out_veg = []\n",
        "\n",
        "    def _compute_veg_row(sub_df: pd.DataFrame) -> list:\n",
        "        row_vals = [len(sub_df)]  # conteo_vegetacion\n",
        "        for var, kind in veg_specs:\n",
        "            if var not in sub_df.columns or sub_df.empty:\n",
        "                row_vals += _veg_empty_vals_for(kind if kind != 'missing' else 'cat')\n",
        "                continue\n",
        "\n",
        "            if kind == 'numeric':\n",
        "                s = pd.to_numeric(sub_df[var], errors='coerce')\n",
        "                row_vals += [\n",
        "                    s.mean(), s.median(), s.min(), s.max(),\n",
        "                    (0.0 if s.dropna().shape[0] <= 1 else float(s.std()))\n",
        "                ]\n",
        "            else:  # categórica (incluye NOM_COMUN)\n",
        "                s = sub_df[var].dropna()\n",
        "                moda = s.mode()\n",
        "                row_vals += [ (moda.iloc[0] if not moda.empty else np.nan) ]\n",
        "        return row_vals\n",
        "\n",
        "    iterator = Eventos.itertuples()\n",
        "    pbar = tqdm(total=len(Eventos), desc='Vegetación (por lat/lon de municipio)') if usar_tqdm else None\n",
        "    for ev in iterator:\n",
        "        mun = getattr(ev, 'MUN', None)\n",
        "        puntos = pts_cache_mun.get(mun, [])\n",
        "\n",
        "        if not mun or mun not in veg_trees or not puntos:\n",
        "            empty_vals = [0]\n",
        "            for _, kind in veg_specs:\n",
        "                empty_vals += _veg_empty_vals_for(kind if kind != 'missing' else 'cat')\n",
        "            out_veg.append(empty_vals)\n",
        "            if pbar: pbar.update(1)\n",
        "            continue\n",
        "\n",
        "        _, veg_mun = veg_trees[mun]\n",
        "        veg_mun = veg_mun.dropna(subset=[col_lat, col_lon])\n",
        "        if veg_mun.empty:\n",
        "            empty_vals = [0]\n",
        "            for _, kind in veg_specs:\n",
        "                empty_vals += _veg_empty_vals_for(kind if kind != 'missing' else 'cat')\n",
        "            out_veg.append(empty_vals)\n",
        "            if pbar: pbar.update(1)\n",
        "            continue\n",
        "\n",
        "        tree_veg = cKDTree(veg_mun[[col_lat, col_lon]].to_numpy())\n",
        "        idxs = _query_indices_for_points(tree_veg, puntos, r=radio_vegetacion)\n",
        "        if not idxs:\n",
        "            empty_vals = [0]\n",
        "            for _, kind in veg_specs:\n",
        "                empty_vals += _veg_empty_vals_for(kind if kind != 'missing' else 'cat')\n",
        "            out_veg.append(empty_vals)\n",
        "            if pbar: pbar.update(1)\n",
        "            continue\n",
        "\n",
        "        sub = veg_mun.iloc[list(idxs)]\n",
        "        out_veg.append(_compute_veg_row(sub))\n",
        "        if pbar: pbar.update(1)\n",
        "    if pbar: pbar.close()\n",
        "\n",
        "    df_veg = pd.DataFrame(out_veg, columns=cols_veg, index=Eventos.index)\n",
        "    Eventos.loc[df_veg.index, df_veg.columns] = df_veg\n",
        "\n",
        "    return Eventos\n"
      ],
      "metadata": {
        "id": "3VRafIJmAZi0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xdata=enriquecer_eventos_con_rayos_y_vegetacion(Xdata, Rayos, Vegetacion,ventana_dias= 24,veg_vars=['NOM_COMUN','ESTADO_INICIAL','LADO_RED','DAP_ESTIM','LONG_INTER','TIPO_INTER', 'NIVEL_RIES'])\n",
        "Xdata.to_pickle('SuperEventos_Criticidad_AguasAbajo_CODEs.pkl')\n",
        "Xdata.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jziKonkRfVvt",
        "outputId": "4eabd42e-0d6a-4516-bb16-8121c7401335"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Rayos (por lat/lon de municipio): 100%|██████████| 1000/1000 [00:35<00:00, 28.54it/s]\n",
            "Vegetación (por lat/lon de municipio): 100%|██████████| 1000/1000 [00:06<00:00, 163.73it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 369)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Xdata.iloc[:,-14:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "5mXa-K-0jGgm",
        "outputId": "a823320b-b290-4eab-be05-e22e2139449e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    ESTADO_INICIAL_mode LADO_RED_mode  DAP_ESTIM_mean  DAP_ESTIM_median  \\\n",
              "0             Ejecutado        Debajo        3.000000               0.0   \n",
              "1             Ejecutado        Debajo        3.000000               0.0   \n",
              "2             Ejecutado        Debajo        3.000000               0.0   \n",
              "3             Ejecutado        Debajo        3.000000               0.0   \n",
              "4             Ejecutado        Debajo        3.000000               0.0   \n",
              "..                  ...           ...             ...               ...   \n",
              "995           Ejecutado        Debajo       31.500000              26.0   \n",
              "996           Ejecutado        Debajo       21.333333              20.0   \n",
              "997           Ejecutado        Debajo       20.555556              20.0   \n",
              "998           Ejecutado        Debajo       20.555556              20.0   \n",
              "999                 NaN           NaN             NaN               NaN   \n",
              "\n",
              "     DAP_ESTIM_min  DAP_ESTIM_max  DAP_ESTIM_std  LONG_INTER_mean  \\\n",
              "0              0.0            9.0       5.196152         2.000000   \n",
              "1              0.0            9.0       5.196152         2.000000   \n",
              "2              0.0            9.0       5.196152         2.000000   \n",
              "3              0.0            9.0       5.196152         2.000000   \n",
              "4              0.0            9.0       5.196152         2.000000   \n",
              "..             ...            ...            ...              ...   \n",
              "995            1.0           70.0      20.277619         7.666667   \n",
              "996           16.0           28.0       6.110101         2.666667   \n",
              "997           10.0           30.0       6.821127         4.222222   \n",
              "998           10.0           30.0       6.821127         4.222222   \n",
              "999            NaN            NaN       0.000000              NaN   \n",
              "\n",
              "     LONG_INTER_median  LONG_INTER_min  LONG_INTER_max  LONG_INTER_std  \\\n",
              "0                  0.0             0.0             6.0        3.464102   \n",
              "1                  0.0             0.0             6.0        3.464102   \n",
              "2                  0.0             0.0             6.0        3.464102   \n",
              "3                  0.0             0.0             6.0        3.464102   \n",
              "4                  0.0             0.0             6.0        3.464102   \n",
              "..                 ...             ...             ...             ...   \n",
              "995               10.0             2.0            10.0        3.113996   \n",
              "996                2.0             2.0             4.0        1.154701   \n",
              "997                4.0             0.0            10.0        2.773886   \n",
              "998                4.0             0.0            10.0        2.773886   \n",
              "999                NaN             NaN             NaN        0.000000   \n",
              "\n",
              "    TIPO_INTER_mode NIVEL_RIES_mode  \n",
              "0              Poda            Alto  \n",
              "1              Poda            Alto  \n",
              "2              Poda            Alto  \n",
              "3              Poda            Alto  \n",
              "4              Poda            Alto  \n",
              "..              ...             ...  \n",
              "995            Poda            Alto  \n",
              "996            Poda            Alto  \n",
              "997            Poda            Alto  \n",
              "998            Poda            Alto  \n",
              "999             NaN             NaN  \n",
              "\n",
              "[1000 rows x 14 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-618276a8-09b5-453a-b2b3-bb3e5259ad36\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ESTADO_INICIAL_mode</th>\n",
              "      <th>LADO_RED_mode</th>\n",
              "      <th>DAP_ESTIM_mean</th>\n",
              "      <th>DAP_ESTIM_median</th>\n",
              "      <th>DAP_ESTIM_min</th>\n",
              "      <th>DAP_ESTIM_max</th>\n",
              "      <th>DAP_ESTIM_std</th>\n",
              "      <th>LONG_INTER_mean</th>\n",
              "      <th>LONG_INTER_median</th>\n",
              "      <th>LONG_INTER_min</th>\n",
              "      <th>LONG_INTER_max</th>\n",
              "      <th>LONG_INTER_std</th>\n",
              "      <th>TIPO_INTER_mode</th>\n",
              "      <th>NIVEL_RIES_mode</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ejecutado</td>\n",
              "      <td>Debajo</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>5.196152</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>3.464102</td>\n",
              "      <td>Poda</td>\n",
              "      <td>Alto</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ejecutado</td>\n",
              "      <td>Debajo</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>5.196152</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>3.464102</td>\n",
              "      <td>Poda</td>\n",
              "      <td>Alto</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ejecutado</td>\n",
              "      <td>Debajo</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>5.196152</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>3.464102</td>\n",
              "      <td>Poda</td>\n",
              "      <td>Alto</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Ejecutado</td>\n",
              "      <td>Debajo</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>5.196152</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>3.464102</td>\n",
              "      <td>Poda</td>\n",
              "      <td>Alto</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Ejecutado</td>\n",
              "      <td>Debajo</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>5.196152</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>3.464102</td>\n",
              "      <td>Poda</td>\n",
              "      <td>Alto</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>Ejecutado</td>\n",
              "      <td>Debajo</td>\n",
              "      <td>31.500000</td>\n",
              "      <td>26.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>20.277619</td>\n",
              "      <td>7.666667</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>3.113996</td>\n",
              "      <td>Poda</td>\n",
              "      <td>Alto</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>Ejecutado</td>\n",
              "      <td>Debajo</td>\n",
              "      <td>21.333333</td>\n",
              "      <td>20.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>6.110101</td>\n",
              "      <td>2.666667</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.154701</td>\n",
              "      <td>Poda</td>\n",
              "      <td>Alto</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>Ejecutado</td>\n",
              "      <td>Debajo</td>\n",
              "      <td>20.555556</td>\n",
              "      <td>20.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>6.821127</td>\n",
              "      <td>4.222222</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2.773886</td>\n",
              "      <td>Poda</td>\n",
              "      <td>Alto</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>Ejecutado</td>\n",
              "      <td>Debajo</td>\n",
              "      <td>20.555556</td>\n",
              "      <td>20.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>6.821127</td>\n",
              "      <td>4.222222</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2.773886</td>\n",
              "      <td>Poda</td>\n",
              "      <td>Alto</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 14 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-618276a8-09b5-453a-b2b3-bb3e5259ad36')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-618276a8-09b5-453a-b2b3-bb3e5259ad36 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-618276a8-09b5-453a-b2b3-bb3e5259ad36');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-cc9e810e-8835-4981-9378-1461305f9c33\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cc9e810e-8835-4981-9378-1461305f9c33')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-cc9e810e-8835-4981-9378-1461305f9c33 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"Xdata\",\n  \"rows\": 1000,\n  \"fields\": [\n    {\n      \"column\": \"ESTADO_INICIAL_mode\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Inspeccionado\",\n          \"Pendiente Otro\",\n          \"Pendiente Apagon\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LADO_RED_mode\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Ambos Lados\",\n          \"Derecha\",\n          \"Debajo\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DAP_ESTIM_mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12.104251230624387,\n        \"min\": 0.0,\n        \"max\": 67.5,\n        \"num_unique_values\": 34,\n        \"samples\": [\n          18.8,\n          55.0,\n          7.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DAP_ESTIM_median\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14.027048244737722,\n        \"min\": 0.0,\n        \"max\": 75.0,\n        \"num_unique_values\": 21,\n        \"samples\": [\n          0.0,\n          75.0,\n          55.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DAP_ESTIM_min\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11.952697634368075,\n        \"min\": 0.0,\n        \"max\": 55.0,\n        \"num_unique_values\": 18,\n        \"samples\": [\n          0.0,\n          1.0,\n          12.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DAP_ESTIM_max\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 22.082006111476396,\n        \"min\": 0.0,\n        \"max\": 100.0,\n        \"num_unique_values\": 21,\n        \"samples\": [\n          9.0,\n          32.0,\n          28.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DAP_ESTIM_std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.6391376932579025,\n        \"min\": 0.0,\n        \"max\": 34.03429642777023,\n        \"num_unique_values\": 30,\n        \"samples\": [\n          2.8867513459481287,\n          6.013872850889572,\n          34.03429642777023\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LONG_INTER_mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.1876406996500215,\n        \"min\": 0.0,\n        \"max\": 40.0,\n        \"num_unique_values\": 31,\n        \"samples\": [\n          12.4,\n          6.666666666666667,\n          11.714285714285714\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LONG_INTER_median\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.1893195437840465,\n        \"min\": 0.0,\n        \"max\": 40.0,\n        \"num_unique_values\": 17,\n        \"samples\": [\n          0.0,\n          6.0,\n          8.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LONG_INTER_min\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.246108369547764,\n        \"min\": 0.0,\n        \"max\": 40.0,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          8.0,\n          0.0,\n          15.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LONG_INTER_max\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14.223763201740978,\n        \"min\": 0.0,\n        \"max\": 50.0,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          0.0,\n          30.0,\n          6.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LONG_INTER_std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.4901933128748897,\n        \"min\": 0.0,\n        \"max\": 12.898801687262281,\n        \"num_unique_values\": 29,\n        \"samples\": [\n          7.211102550927978,\n          3.5355339059327378,\n          2.449489742783178\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TIPO_INTER_mode\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Rocer\\u00eda\",\n          \"Poda\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"NIVEL_RIES_mode\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Alto\",\n          \"Medio\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Dur_h = Xdata['duracion_h'].values\n",
        "SAIDI = Xdata['SAIDI'].values\n",
        "df1=Xdata.copy()\n",
        "# Eliminar columnas no utilizadas\n",
        "Xdata.drop(['inicio_evento', 'h0-solar_rad', 'h0-uv', 'h1-solar_rad', 'h1-uv', 'h2-solar_rad', 'h2-uv', 'h3-solar_rad', 'h3-uv',\n",
        "            'h4-solar_rad', 'h4-uv', 'h5-solar_rad', 'h5-uv', 'h19-solar_rad', 'h19-uv', 'h20-solar_rad', 'h20-uv',\n",
        "            'h21-solar_rad', 'h21-uv', 'h22-solar_rad', 'h22-uv', 'h23-solar_rad', 'h23-uv', 'evento', 'fin', 'inicio',\n",
        "            'cnt_usus', 'DEP', 'MUN', 'FECHA', 'NIVEL_C', 'VALOR_C', 'TRAMOS_AGUAS_ABAJO', 'EQUIPOS_PUNTOS',\n",
        "            'PUNTOS_POLIGONO', 'LONGITUD2', 'LATITUD2', 'FECHA_C','TRAMOS_AGUAS_ABAJO_CODES','ORDER_'],\n",
        "           inplace=True, axis=1)\n",
        "\n",
        "# Definir la variable objetivo y eliminarla del conjunto de características\n",
        "target = ['SAIFI', 'SAIDI', 'duracion_h']\n",
        "y1 = Xdata[target].values\n",
        "Xdata.drop(target, axis=1, inplace=True)\n",
        "y = y1[:, 0:1].astype('float32')\n",
        "\n",
        "# Copia de trabajo de X\n",
        "df = Xdata.copy()\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Etapa 2: tipificar columnas\n",
        "NUMERIC_COLUMNS = df.select_dtypes(include=['number']).columns.tolist()\n",
        "CATEGORICAL_COLUMNS = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Etapa 3: imputación numérica\n",
        "max_values = {}\n",
        "for col in NUMERIC_COLUMNS:\n",
        "    max_value = pd.to_numeric(df[col], errors='coerce').max()\n",
        "    if pd.isna(max_value):\n",
        "        max_value = 0.0\n",
        "    max_values[col] = max_value\n",
        "    df[col] = pd.to_numeric(df[col], errors='coerce').fillna(-10.0 * max_value)\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Etapa 4: codificación categórica\n",
        "label_encoders = {}\n",
        "categorical_dims = {}\n",
        "for col in CATEGORICAL_COLUMNS:\n",
        "    enc = LabelEncoder()\n",
        "    s = df[col].astype(str).fillna(\"no aplica\")\n",
        "    enc.fit(s)\n",
        "    df[col] = enc.transform(s)\n",
        "    label_encoders[col] = enc\n",
        "    categorical_dims[col] = len(enc.classes_)\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Etapa 5: construir matrices X, y\n",
        "unused_feat = []\n",
        "# Si Xdata NO incluye el target, basta con tomar todas las columnas\n",
        "features = [c for c in df.columns if c not in unused_feat]\n",
        "X = df[features].values.astype('float32')\n",
        "# Etapa 6: clases auxiliares para estratificación\n",
        "try:\n",
        "    # usar etiqueta externa si existe\n",
        "    y_categorized = df1['NIVEL_C'].values.astype(int)\n",
        "except Exception:\n",
        "    # fallback: terciles del objetivo\n",
        "    percentiles = np.percentile(y[:, 0], [33.33, 66.66])\n",
        "    y_categorized = np.digitize(y[:, 0].flatten(), bins=percentiles).astype(int)\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Etapa 7: escalar objetivo (regresión)\n",
        "scaler = MinMaxScaler()\n",
        "y_scaled = scaler.fit_transform(y)\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Etapa 8: split train/test estratificado\n",
        "X_train, X_test, y_train, y_test, ycat_train, ycat_test = train_test_split(\n",
        "    X, y_scaled, y_categorized, test_size=0.20, random_state=42, stratify=y_categorized\n",
        ")\n",
        "\n",
        "# Etapa 8b: split train/valid estratificado por percentiles de y_train\n",
        "percentiles_t = np.percentile(y_train[:, 0], [25, 50, 75])\n",
        "y_categorized_t = np.digitize(y_train[:, 0].flatten(), bins=percentiles_t).astype(int)\n",
        "\n",
        "X_train, X_valid, y_train, y_valid, ycat_train, ycat_valid = train_test_split(\n",
        "    X_train, y_train, ycat_train, test_size=0.20, random_state=42, stratify=y_categorized_t\n",
        ")\n",
        "\n",
        "# Comprobaciones rápidas\n",
        "print(X.shape, y.shape)\n",
        "print(\"Train/Valid/Test:\", X_train.shape, X_valid.shape, X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lvp4foXlErX",
        "outputId": "93ee4e93-4820-42d7-8d33-817099504ff8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000, 326) (1000, 1)\n",
            "Train/Valid/Test: (640, 326) (160, 326) (200, 326)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Logo UNAL CHEC](https://miro.medium.com/v2/resize:fit:1100/format:webp/0*lu62RCEko0VYe-YZ)\n",
        "\n"
      ],
      "metadata": {
        "id": "0mwgoq6ePRAh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler())\n",
        "\n",
        "study.optimize(objective_regression, n_trials=15)\n",
        "\n",
        "print(\"Best hyperparameters for regression: \", study.best_params)\n",
        "print(\"Best mae: \", study.best_value)\n",
        "par = study.best_params\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDxnDSJNSnAI",
        "outputId": "43c11eca-bb21-4271-f698-88162c6f89e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-09-05 05:44:49,489] A new study created in memory with name: no-name-07c23c89-d6ae-4a26-8cea-0e5d421f516a\n",
            "/usr/local/lib/python3.12/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 271.92625| train_mae: 25.25287| valid_mae: 24.57386|  0:00:01s\n",
            "epoch 1  | loss: 116.51288| train_mae: 3.98531 | valid_mae: 3.92739 |  0:00:02s\n",
            "epoch 2  | loss: 153.20446| train_mae: 5.04861 | valid_mae: 5.97843 |  0:00:03s\n",
            "epoch 3  | loss: 31.68513| train_mae: 13.03509| valid_mae: 12.8926 |  0:00:04s\n",
            "epoch 4  | loss: 37.5296 | train_mae: 10.24223| valid_mae: 10.5753 |  0:00:06s\n",
            "epoch 5  | loss: 11.63218| train_mae: 1.03958 | valid_mae: 1.04903 |  0:00:07s\n",
            "epoch 6  | loss: 4.20039 | train_mae: 1.26825 | valid_mae: 1.26902 |  0:00:08s\n",
            "epoch 7  | loss: 1.4267  | train_mae: 0.4804  | valid_mae: 0.36659 |  0:00:09s\n",
            "epoch 8  | loss: 2.69515 | train_mae: 0.84933 | valid_mae: 0.88982 |  0:00:10s\n",
            "epoch 9  | loss: 3.28872 | train_mae: 0.2533  | valid_mae: 0.23891 |  0:00:11s\n",
            "epoch 10 | loss: 1.31982 | train_mae: 0.08341 | valid_mae: 0.07679 |  0:00:11s\n",
            "epoch 11 | loss: 1.12629 | train_mae: 0.06308 | valid_mae: 0.06426 |  0:00:12s\n",
            "epoch 12 | loss: 1.00371 | train_mae: 0.05701 | valid_mae: 0.0485  |  0:00:13s\n",
            "epoch 13 | loss: 1.60722 | train_mae: 0.05336 | valid_mae: 0.05405 |  0:00:14s\n",
            "epoch 14 | loss: 1.00042 | train_mae: 0.07085 | valid_mae: 0.07516 |  0:00:16s\n",
            "epoch 15 | loss: 0.93577 | train_mae: 0.03582 | valid_mae: 0.03142 |  0:00:17s\n",
            "epoch 16 | loss: 0.92384 | train_mae: 0.07288 | valid_mae: 0.07676 |  0:00:18s\n",
            "epoch 17 | loss: 1.16698 | train_mae: 0.0768  | valid_mae: 0.07396 |  0:00:19s\n",
            "epoch 18 | loss: 1.01272 | train_mae: 0.03663 | valid_mae: 0.03634 |  0:00:20s\n",
            "epoch 19 | loss: 0.92599 | train_mae: 0.03294 | valid_mae: 0.03023 |  0:00:21s\n",
            "epoch 20 | loss: 0.83289 | train_mae: 0.03781 | valid_mae: 0.02853 |  0:00:22s\n",
            "epoch 21 | loss: 0.81095 | train_mae: 0.03698 | valid_mae: 0.03885 |  0:00:23s\n",
            "epoch 22 | loss: 0.76961 | train_mae: 0.02818 | valid_mae: 0.02543 |  0:00:24s\n",
            "epoch 23 | loss: 0.72851 | train_mae: 0.02179 | valid_mae: 0.01869 |  0:00:25s\n",
            "epoch 24 | loss: 0.56213 | train_mae: 0.03627 | valid_mae: 0.0366  |  0:00:26s\n",
            "epoch 25 | loss: 0.53922 | train_mae: 0.03775 | valid_mae: 0.03746 |  0:00:27s\n",
            "epoch 26 | loss: 0.53712 | train_mae: 0.03035 | valid_mae: 0.02998 |  0:00:28s\n",
            "epoch 27 | loss: 0.79783 | train_mae: 0.04096 | valid_mae: 0.04095 |  0:00:30s\n",
            "epoch 28 | loss: 1.12164 | train_mae: 0.05527 | valid_mae: 0.06849 |  0:00:31s\n",
            "epoch 29 | loss: 0.64845 | train_mae: 0.16949 | valid_mae: 0.16981 |  0:00:32s\n",
            "epoch 30 | loss: 0.72097 | train_mae: 0.24514 | valid_mae: 0.23959 |  0:00:33s\n",
            "epoch 31 | loss: 0.54147 | train_mae: 0.18779 | valid_mae: 0.18159 |  0:00:34s\n",
            "epoch 32 | loss: 0.76381 | train_mae: 0.04543 | valid_mae: 0.04402 |  0:00:35s\n",
            "epoch 33 | loss: 0.56599 | train_mae: 0.26563 | valid_mae: 0.25942 |  0:00:36s\n",
            "epoch 34 | loss: 0.77318 | train_mae: 0.39419 | valid_mae: 0.39376 |  0:00:37s\n",
            "epoch 35 | loss: 0.82584 | train_mae: 0.3866  | valid_mae: 0.37725 |  0:00:38s\n",
            "epoch 36 | loss: 0.5442  | train_mae: 0.57781 | valid_mae: 0.57343 |  0:00:39s\n",
            "epoch 37 | loss: 1.2082  | train_mae: 0.52416 | valid_mae: 0.54602 |  0:00:40s\n",
            "epoch 38 | loss: 0.35957 | train_mae: 0.33786 | valid_mae: 0.34269 |  0:00:41s\n",
            "epoch 39 | loss: 0.49295 | train_mae: 0.22663 | valid_mae: 0.22356 |  0:00:42s\n",
            "epoch 40 | loss: 0.57468 | train_mae: 0.20618 | valid_mae: 0.19581 |  0:00:44s\n",
            "epoch 41 | loss: 0.75824 | train_mae: 0.17157 | valid_mae: 0.16724 |  0:00:45s\n",
            "epoch 42 | loss: 0.37213 | train_mae: 0.1178  | valid_mae: 0.11643 |  0:00:46s\n",
            "epoch 43 | loss: 0.43834 | train_mae: 0.1041  | valid_mae: 0.10109 |  0:00:47s\n",
            "epoch 44 | loss: 0.32248 | train_mae: 0.21933 | valid_mae: 0.21712 |  0:00:48s\n",
            "epoch 45 | loss: 0.35158 | train_mae: 0.13552 | valid_mae: 0.13497 |  0:00:49s\n",
            "epoch 46 | loss: 0.59914 | train_mae: 0.2913  | valid_mae: 0.29511 |  0:00:50s\n",
            "epoch 47 | loss: 0.40399 | train_mae: 0.35553 | valid_mae: 0.36245 |  0:00:51s\n",
            "epoch 48 | loss: 0.37392 | train_mae: 0.33018 | valid_mae: 0.3349  |  0:00:52s\n",
            "epoch 49 | loss: 0.37283 | train_mae: 0.2446  | valid_mae: 0.25201 |  0:00:53s\n",
            "epoch 50 | loss: 0.25885 | train_mae: 0.1847  | valid_mae: 0.19017 |  0:00:54s\n",
            "epoch 51 | loss: 0.42897 | train_mae: 0.14268 | valid_mae: 0.14593 |  0:00:55s\n",
            "epoch 52 | loss: 0.18691 | train_mae: 0.15476 | valid_mae: 0.15946 |  0:00:57s\n",
            "epoch 53 | loss: 0.44415 | train_mae: 0.08511 | valid_mae: 0.08851 |  0:00:58s\n",
            "epoch 54 | loss: 0.24023 | train_mae: 0.07193 | valid_mae: 0.07425 |  0:00:59s\n",
            "epoch 55 | loss: 0.31591 | train_mae: 0.07034 | valid_mae: 0.07341 |  0:01:00s\n",
            "epoch 56 | loss: 0.21018 | train_mae: 0.08352 | valid_mae: 0.08668 |  0:01:01s\n",
            "epoch 57 | loss: 0.20293 | train_mae: 0.05343 | valid_mae: 0.05607 |  0:01:02s\n",
            "epoch 58 | loss: 0.23246 | train_mae: 0.03898 | valid_mae: 0.03663 |  0:01:03s\n",
            "epoch 59 | loss: 0.48039 | train_mae: 0.04246 | valid_mae: 0.03964 |  0:01:04s\n",
            "epoch 60 | loss: 0.22557 | train_mae: 0.04097 | valid_mae: 0.03823 |  0:01:05s\n",
            "epoch 61 | loss: 0.26538 | train_mae: 0.03643 | valid_mae: 0.03433 |  0:01:06s\n",
            "epoch 62 | loss: 0.17037 | train_mae: 0.02696 | valid_mae: 0.02666 |  0:01:07s\n",
            "epoch 63 | loss: 0.25731 | train_mae: 0.02011 | valid_mae: 0.01828 |  0:01:08s\n",
            "epoch 64 | loss: 0.32893 | train_mae: 0.01982 | valid_mae: 0.0182  |  0:01:10s\n",
            "epoch 65 | loss: 0.2555  | train_mae: 0.02993 | valid_mae: 0.02836 |  0:01:11s\n",
            "epoch 66 | loss: 0.51323 | train_mae: 0.02704 | valid_mae: 0.02638 |  0:01:12s\n",
            "epoch 67 | loss: 0.3059  | train_mae: 0.02452 | valid_mae: 0.02406 |  0:01:13s\n",
            "epoch 68 | loss: 0.25209 | train_mae: 0.02343 | valid_mae: 0.02214 |  0:01:14s\n",
            "epoch 69 | loss: 0.37737 | train_mae: 0.03365 | valid_mae: 0.03499 |  0:01:17s\n",
            "epoch 70 | loss: 0.24825 | train_mae: 0.03104 | valid_mae: 0.03127 |  0:01:18s\n",
            "epoch 71 | loss: 0.19016 | train_mae: 0.02479 | valid_mae: 0.02337 |  0:01:19s\n",
            "epoch 72 | loss: 0.22584 | train_mae: 0.02372 | valid_mae: 0.02329 |  0:01:20s\n",
            "epoch 73 | loss: 0.2398  | train_mae: 0.02603 | valid_mae: 0.02584 |  0:01:21s\n",
            "epoch 74 | loss: 0.3088  | train_mae: 0.02842 | valid_mae: 0.0277  |  0:01:22s\n",
            "epoch 75 | loss: 0.20894 | train_mae: 0.0212  | valid_mae: 0.01991 |  0:01:23s\n",
            "epoch 76 | loss: 0.1933  | train_mae: 0.01809 | valid_mae: 0.01604 |  0:01:24s\n",
            "epoch 77 | loss: 0.40417 | train_mae: 0.01771 | valid_mae: 0.01692 |  0:01:25s\n",
            "epoch 78 | loss: 0.26319 | train_mae: 0.01854 | valid_mae: 0.0178  |  0:01:27s\n",
            "epoch 79 | loss: 0.36345 | train_mae: 0.01548 | valid_mae: 0.01395 |  0:01:27s\n",
            "epoch 80 | loss: 0.19462 | train_mae: 0.016   | valid_mae: 0.01464 |  0:01:28s\n",
            "epoch 81 | loss: 0.18365 | train_mae: 0.01828 | valid_mae: 0.01716 |  0:01:29s\n",
            "epoch 82 | loss: 0.12841 | train_mae: 0.01815 | valid_mae: 0.01761 |  0:01:30s\n",
            "epoch 83 | loss: 0.20463 | train_mae: 0.01675 | valid_mae: 0.01721 |  0:01:31s\n",
            "epoch 84 | loss: 0.20085 | train_mae: 0.01413 | valid_mae: 0.01437 |  0:01:32s\n",
            "epoch 85 | loss: 0.20467 | train_mae: 0.01312 | valid_mae: 0.0118  |  0:01:34s\n",
            "epoch 86 | loss: 0.20997 | train_mae: 0.0112  | valid_mae: 0.00982 |  0:01:35s\n",
            "epoch 87 | loss: 0.19505 | train_mae: 0.01221 | valid_mae: 0.00968 |  0:01:36s\n",
            "epoch 88 | loss: 0.22615 | train_mae: 0.01208 | valid_mae: 0.00985 |  0:01:37s\n",
            "epoch 89 | loss: 0.13643 | train_mae: 0.01181 | valid_mae: 0.00943 |  0:01:38s\n",
            "epoch 90 | loss: 0.15542 | train_mae: 0.01137 | valid_mae: 0.00985 |  0:01:39s\n",
            "epoch 91 | loss: 0.13528 | train_mae: 0.01074 | valid_mae: 0.01097 |  0:01:40s\n",
            "epoch 92 | loss: 0.39122 | train_mae: 0.00998 | valid_mae: 0.01062 |  0:01:41s\n",
            "epoch 93 | loss: 0.17713 | train_mae: 0.0118  | valid_mae: 0.01096 |  0:01:42s\n",
            "epoch 94 | loss: 0.16291 | train_mae: 0.01193 | valid_mae: 0.01171 |  0:01:43s\n",
            "epoch 95 | loss: 0.08858 | train_mae: 0.01194 | valid_mae: 0.01317 |  0:01:44s\n",
            "epoch 96 | loss: 0.49021 | train_mae: 0.01132 | valid_mae: 0.01343 |  0:01:45s\n",
            "epoch 97 | loss: 0.27142 | train_mae: 0.01133 | valid_mae: 0.012   |  0:01:46s\n",
            "epoch 98 | loss: 0.22807 | train_mae: 0.0135  | valid_mae: 0.01392 |  0:01:48s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-09-05 05:46:51,285] Trial 0 finished with value: 0.16774559617042542 and parameters: {'n_d': 25, 'n_a': 11, 'n_steps': 3, 'gamma': 1.2767044583220173, 'lambda_sparse': 0.00021743503701894743, 'batch_size': 256, 'mask_type': 'entmax', 'emb': 9, 'momentum': 0.8378948181524486, 'learning_rate': 0.0026985781664567872, 'weight_decay': 4.039364356411261e-05, 'scheduler_gamma': 0.9852634307945352, 'step_size': 11, 'virtual_batch_size': 32, 'optimizer_type': 'rmsprop', 'p': 0.1794052271724728}. Best is trial 0 with value: 0.16774559617042542.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 99 | loss: 0.16775 | train_mae: 0.01439 | valid_mae: 0.01586 |  0:01:49s\n",
            "Stop training because you reached max_epochs = 100 with best_epoch = 89 and best_valid_mae = 0.00943\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 14047.09344| train_mae: 91.82583| valid_mae: 89.55322|  0:00:01s\n",
            "epoch 1  | loss: 6236.75177| train_mae: 85.91447| valid_mae: 82.48672|  0:00:03s\n",
            "epoch 2  | loss: 8690.83115| train_mae: 38.12731| valid_mae: 37.9627 |  0:00:04s\n",
            "epoch 3  | loss: 7207.35773| train_mae: 27.89284| valid_mae: 29.19356|  0:00:06s\n",
            "epoch 4  | loss: 8996.16973| train_mae: 27.57042| valid_mae: 31.06845|  0:00:09s\n",
            "epoch 5  | loss: 6347.51808| train_mae: 19.80003| valid_mae: 19.29023|  0:00:10s\n",
            "epoch 6  | loss: 6281.75803| train_mae: 23.48881| valid_mae: 24.07481|  0:00:12s\n",
            "epoch 7  | loss: 5184.08166| train_mae: 24.10659| valid_mae: 22.98389|  0:00:14s\n",
            "epoch 8  | loss: 3866.64102| train_mae: 20.60244| valid_mae: 21.74703|  0:00:15s\n",
            "epoch 9  | loss: 6184.68173| train_mae: 18.44676| valid_mae: 20.38288|  0:00:17s\n",
            "epoch 10 | loss: 4558.98179| train_mae: 16.69636| valid_mae: 14.88144|  0:00:19s\n",
            "epoch 11 | loss: 3518.85027| train_mae: 26.76334| valid_mae: 26.16837|  0:00:21s\n",
            "epoch 12 | loss: 4442.47365| train_mae: 16.1451 | valid_mae: 17.33214|  0:00:23s\n",
            "epoch 13 | loss: 2886.58246| train_mae: 15.92513| valid_mae: 13.49194|  0:00:25s\n",
            "epoch 14 | loss: 3470.35291| train_mae: 9.72592 | valid_mae: 13.9978 |  0:00:26s\n",
            "epoch 15 | loss: 2898.62137| train_mae: 8.17255 | valid_mae: 7.59293 |  0:00:28s\n",
            "epoch 16 | loss: 3116.73549| train_mae: 6.4463  | valid_mae: 6.1986  |  0:00:30s\n",
            "epoch 17 | loss: 5897.22706| train_mae: 7.25843 | valid_mae: 6.24014 |  0:00:31s\n",
            "epoch 18 | loss: 4261.23419| train_mae: 6.64305 | valid_mae: 5.71794 |  0:00:33s\n",
            "epoch 19 | loss: 3043.96854| train_mae: 4.89029 | valid_mae: 5.20785 |  0:00:35s\n",
            "epoch 20 | loss: 2633.35616| train_mae: 4.72512 | valid_mae: 4.26002 |  0:00:37s\n",
            "epoch 21 | loss: 2754.1477| train_mae: 5.05983 | valid_mae: 4.87046 |  0:00:39s\n",
            "epoch 22 | loss: 5456.32092| train_mae: 4.65319 | valid_mae: 4.02056 |  0:00:40s\n",
            "epoch 23 | loss: 2524.42297| train_mae: 4.99949 | valid_mae: 5.0246  |  0:00:42s\n",
            "epoch 24 | loss: 2984.08522| train_mae: 4.92128 | valid_mae: 4.33874 |  0:00:44s\n",
            "epoch 25 | loss: 2831.76895| train_mae: 3.89834 | valid_mae: 3.7977  |  0:00:45s\n",
            "epoch 26 | loss: 1428.3393| train_mae: 4.5718  | valid_mae: 4.3258  |  0:00:48s\n",
            "epoch 27 | loss: 3973.56907| train_mae: 3.47641 | valid_mae: 3.49609 |  0:00:50s\n",
            "epoch 28 | loss: 2647.92599| train_mae: 3.68572 | valid_mae: 3.3699  |  0:00:51s\n",
            "epoch 29 | loss: 3304.36319| train_mae: 3.71991 | valid_mae: 4.03343 |  0:00:53s\n",
            "epoch 30 | loss: 2961.10633| train_mae: 3.76475 | valid_mae: 3.95266 |  0:00:55s\n",
            "epoch 31 | loss: 2948.22434| train_mae: 3.76608 | valid_mae: 3.56593 |  0:00:56s\n",
            "epoch 32 | loss: 2015.51602| train_mae: 3.88326 | valid_mae: 3.24695 |  0:00:58s\n",
            "epoch 33 | loss: 1996.73848| train_mae: 3.99973 | valid_mae: 3.64139 |  0:01:00s\n",
            "epoch 34 | loss: 1906.04791| train_mae: 4.07239 | valid_mae: 3.96591 |  0:01:02s\n",
            "epoch 35 | loss: 2436.856| train_mae: 3.80774 | valid_mae: 3.14387 |  0:01:04s\n",
            "epoch 36 | loss: 1869.57335| train_mae: 3.27925 | valid_mae: 2.7955  |  0:01:06s\n",
            "epoch 37 | loss: 3151.47977| train_mae: 2.84199 | valid_mae: 2.89113 |  0:01:07s\n",
            "epoch 38 | loss: 1163.35274| train_mae: 2.57363 | valid_mae: 2.82889 |  0:01:09s\n",
            "epoch 39 | loss: 1774.94671| train_mae: 2.0124  | valid_mae: 2.21694 |  0:01:11s\n",
            "epoch 40 | loss: 1401.10806| train_mae: 1.95583 | valid_mae: 2.50306 |  0:01:13s\n",
            "epoch 41 | loss: 2303.66837| train_mae: 1.44237 | valid_mae: 1.71262 |  0:01:15s\n",
            "epoch 42 | loss: 1993.76908| train_mae: 1.26443 | valid_mae: 1.63359 |  0:01:17s\n",
            "epoch 43 | loss: 2068.63806| train_mae: 1.2421  | valid_mae: 1.45764 |  0:01:18s\n",
            "epoch 44 | loss: 2477.26041| train_mae: 1.19495 | valid_mae: 1.44207 |  0:01:20s\n",
            "epoch 45 | loss: 1593.14704| train_mae: 1.1816  | valid_mae: 1.33874 |  0:01:22s\n",
            "epoch 46 | loss: 2497.20379| train_mae: 1.16606 | valid_mae: 1.28162 |  0:01:23s\n",
            "epoch 47 | loss: 1790.13223| train_mae: 1.07423 | valid_mae: 1.30234 |  0:01:25s\n",
            "epoch 48 | loss: 1884.05523| train_mae: 1.07122 | valid_mae: 1.41075 |  0:01:28s\n",
            "epoch 49 | loss: 1967.57622| train_mae: 1.00387 | valid_mae: 1.19616 |  0:01:29s\n",
            "epoch 50 | loss: 1497.89493| train_mae: 0.92053 | valid_mae: 1.10145 |  0:01:31s\n",
            "epoch 51 | loss: 1994.8274| train_mae: 0.92885 | valid_mae: 1.15339 |  0:01:33s\n",
            "epoch 52 | loss: 2521.46871| train_mae: 0.92873 | valid_mae: 1.06429 |  0:01:34s\n",
            "epoch 53 | loss: 1871.33967| train_mae: 0.919   | valid_mae: 1.04326 |  0:01:36s\n",
            "epoch 54 | loss: 1797.15841| train_mae: 0.92043 | valid_mae: 0.97041 |  0:01:38s\n",
            "epoch 55 | loss: 2520.42125| train_mae: 0.9199  | valid_mae: 0.86365 |  0:01:40s\n",
            "epoch 56 | loss: 1137.89822| train_mae: 0.87745 | valid_mae: 0.92469 |  0:01:42s\n",
            "epoch 57 | loss: 1945.96944| train_mae: 0.89057 | valid_mae: 0.91408 |  0:01:44s\n",
            "epoch 58 | loss: 1511.17573| train_mae: 0.9002  | valid_mae: 1.05126 |  0:01:45s\n",
            "epoch 59 | loss: 1216.89197| train_mae: 0.90471 | valid_mae: 0.85198 |  0:01:47s\n",
            "epoch 60 | loss: 1578.50254| train_mae: 0.9167  | valid_mae: 0.73539 |  0:01:49s\n",
            "epoch 61 | loss: 1347.05169| train_mae: 0.88413 | valid_mae: 0.85968 |  0:01:51s\n",
            "epoch 62 | loss: 1985.43278| train_mae: 0.85651 | valid_mae: 0.87488 |  0:01:53s\n",
            "epoch 63 | loss: 1525.46872| train_mae: 0.87058 | valid_mae: 0.91322 |  0:01:55s\n",
            "epoch 64 | loss: 1079.08039| train_mae: 0.89664 | valid_mae: 0.84303 |  0:01:57s\n",
            "epoch 65 | loss: 1549.89783| train_mae: 0.8506  | valid_mae: 0.75631 |  0:01:59s\n",
            "epoch 66 | loss: 893.0561| train_mae: 0.83851 | valid_mae: 0.80229 |  0:02:00s\n",
            "epoch 67 | loss: 1546.74746| train_mae: 0.78133 | valid_mae: 0.80408 |  0:02:02s\n",
            "epoch 68 | loss: 2884.49336| train_mae: 0.81604 | valid_mae: 0.88424 |  0:02:03s\n",
            "epoch 69 | loss: 1318.59325| train_mae: 0.7845  | valid_mae: 0.81809 |  0:02:06s\n",
            "epoch 70 | loss: 1390.20711| train_mae: 0.82667 | valid_mae: 0.82152 |  0:02:08s\n",
            "epoch 71 | loss: 1186.94806| train_mae: 0.83174 | valid_mae: 0.90781 |  0:02:09s\n",
            "epoch 72 | loss: 1538.51716| train_mae: 0.79165 | valid_mae: 0.83556 |  0:02:11s\n",
            "epoch 73 | loss: 1514.96439| train_mae: 0.774   | valid_mae: 0.89259 |  0:02:13s\n",
            "epoch 74 | loss: 1235.15655| train_mae: 0.75612 | valid_mae: 0.76075 |  0:02:14s\n",
            "epoch 75 | loss: 1419.76046| train_mae: 0.77726 | valid_mae: 0.84308 |  0:02:16s\n",
            "epoch 76 | loss: 3422.03577| train_mae: 0.75735 | valid_mae: 0.80753 |  0:02:18s\n",
            "epoch 77 | loss: 1404.63262| train_mae: 0.81815 | valid_mae: 0.8303  |  0:02:20s\n",
            "epoch 78 | loss: 1270.28134| train_mae: 0.8391  | valid_mae: 0.80174 |  0:02:22s\n",
            "epoch 79 | loss: 911.22356| train_mae: 0.81007 | valid_mae: 0.8317  |  0:02:24s\n",
            "epoch 80 | loss: 974.89804| train_mae: 0.78211 | valid_mae: 0.71281 |  0:02:26s\n",
            "epoch 81 | loss: 1022.60085| train_mae: 0.77961 | valid_mae: 0.86429 |  0:02:27s\n",
            "epoch 82 | loss: 1588.27465| train_mae: 0.75665 | valid_mae: 0.91656 |  0:02:29s\n",
            "epoch 83 | loss: 1199.39096| train_mae: 0.75752 | valid_mae: 1.16616 |  0:02:31s\n",
            "epoch 84 | loss: 1670.75898| train_mae: 0.82399 | valid_mae: 1.01415 |  0:02:33s\n",
            "epoch 85 | loss: 1183.43915| train_mae: 0.76587 | valid_mae: 0.96622 |  0:02:35s\n",
            "epoch 86 | loss: 1127.57621| train_mae: 0.7772  | valid_mae: 1.01022 |  0:02:37s\n",
            "epoch 87 | loss: 1217.42358| train_mae: 0.74768 | valid_mae: 1.01467 |  0:02:38s\n",
            "epoch 88 | loss: 934.13721| train_mae: 0.71708 | valid_mae: 1.0035  |  0:02:40s\n",
            "epoch 89 | loss: 1132.45095| train_mae: 0.71626 | valid_mae: 1.03982 |  0:02:42s\n",
            "epoch 90 | loss: 1220.7238| train_mae: 0.71859 | valid_mae: 0.98295 |  0:02:43s\n",
            "epoch 91 | loss: 1208.4534| train_mae: 0.74796 | valid_mae: 0.98664 |  0:02:46s\n",
            "epoch 92 | loss: 939.60723| train_mae: 0.74277 | valid_mae: 1.02632 |  0:02:48s\n",
            "epoch 93 | loss: 1860.98912| train_mae: 0.70575 | valid_mae: 0.98944 |  0:02:49s\n",
            "epoch 94 | loss: 988.80047| train_mae: 0.68085 | valid_mae: 0.93896 |  0:02:51s\n",
            "epoch 95 | loss: 998.46465| train_mae: 0.72088 | valid_mae: 0.95394 |  0:02:53s\n",
            "epoch 96 | loss: 874.83576| train_mae: 0.7429  | valid_mae: 0.96702 |  0:02:54s\n",
            "epoch 97 | loss: 1136.80945| train_mae: 0.70763 | valid_mae: 0.94851 |  0:02:56s\n",
            "epoch 98 | loss: 1139.49825| train_mae: 0.71632 | valid_mae: 0.95148 |  0:02:58s\n",
            "epoch 99 | loss: 1356.74156| train_mae: 0.70894 | valid_mae: 0.86265 |  0:03:00s\n",
            "Stop training because you reached max_epochs = 100 with best_epoch = 80 and best_valid_mae = 0.71281\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-09-05 05:49:55,365] Trial 1 finished with value: 1356.7415557861327 and parameters: {'n_d': 18, 'n_a': 23, 'n_steps': 5, 'gamma': 1.2200593872830134, 'lambda_sparse': 2.1646129449895796e-06, 'batch_size': 64, 'mask_type': 'sparsemax', 'emb': 14, 'momentum': 0.7718995901460693, 'learning_rate': 0.00028328508652435814, 'weight_decay': 2.7419645555209715e-05, 'scheduler_gamma': 0.9709430293139852, 'step_size': 9, 'virtual_batch_size': 32, 'optimizer_type': 'adam', 'p': 0.023050692015054684}. Best is trial 0 with value: 0.16774559617042542.\n",
            "/usr/local/lib/python3.12/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 2484.19469| train_mae: 94.69408| valid_mae: 95.32561|  0:00:01s\n",
            "epoch 1  | loss: 1104.06787| train_mae: 25.20789| valid_mae: 22.6221 |  0:00:03s\n",
            "epoch 2  | loss: 749.13465| train_mae: 42.2212 | valid_mae: 44.70208|  0:00:05s\n",
            "epoch 3  | loss: 2428.00749| train_mae: 36.31425| valid_mae: 35.06764|  0:00:07s\n",
            "epoch 4  | loss: 1788.0575| train_mae: 37.61064| valid_mae: 36.10211|  0:00:09s\n",
            "epoch 5  | loss: 524.56212| train_mae: 33.63172| valid_mae: 40.86635|  0:00:11s\n",
            "epoch 6  | loss: 465.49125| train_mae: 30.54578| valid_mae: 36.15289|  0:00:13s\n",
            "epoch 7  | loss: 387.22532| train_mae: 23.77735| valid_mae: 21.05051|  0:00:14s\n",
            "epoch 8  | loss: 416.92058| train_mae: 6.76607 | valid_mae: 7.54987 |  0:00:16s\n",
            "epoch 9  | loss: 260.27273| train_mae: 9.69735 | valid_mae: 11.27608|  0:00:18s\n",
            "epoch 10 | loss: 265.13235| train_mae: 5.67813 | valid_mae: 7.36142 |  0:00:21s\n",
            "epoch 11 | loss: 277.66488| train_mae: 4.77812 | valid_mae: 4.5058  |  0:00:22s\n",
            "epoch 12 | loss: 179.79005| train_mae: 2.79457 | valid_mae: 3.09774 |  0:00:24s\n",
            "epoch 13 | loss: 177.99688| train_mae: 2.29016 | valid_mae: 2.58062 |  0:00:26s\n",
            "epoch 14 | loss: 175.98373| train_mae: 2.00478 | valid_mae: 1.98543 |  0:00:28s\n",
            "epoch 15 | loss: 82.2856 | train_mae: 2.72513 | valid_mae: 2.54736 |  0:00:29s\n",
            "epoch 16 | loss: 215.34344| train_mae: 2.34136 | valid_mae: 2.93728 |  0:00:31s\n",
            "epoch 17 | loss: 85.04073| train_mae: 1.78305 | valid_mae: 1.82811 |  0:00:34s\n",
            "epoch 18 | loss: 72.3495 | train_mae: 1.2515  | valid_mae: 1.10033 |  0:00:36s\n",
            "epoch 19 | loss: 76.84373| train_mae: 1.22195 | valid_mae: 0.95462 |  0:00:37s\n",
            "epoch 20 | loss: 42.06735| train_mae: 0.87591 | valid_mae: 0.84581 |  0:00:39s\n",
            "epoch 21 | loss: 34.12379| train_mae: 0.7588  | valid_mae: 0.67504 |  0:00:41s\n",
            "epoch 22 | loss: 31.9495 | train_mae: 0.5191  | valid_mae: 0.50758 |  0:00:43s\n",
            "epoch 23 | loss: 21.30414| train_mae: 0.55523 | valid_mae: 0.49017 |  0:00:45s\n",
            "epoch 24 | loss: 17.4703 | train_mae: 0.3274  | valid_mae: 0.29374 |  0:00:47s\n",
            "epoch 25 | loss: 20.6564 | train_mae: 0.32635 | valid_mae: 0.32748 |  0:00:50s\n",
            "epoch 26 | loss: 11.96521| train_mae: 0.25534 | valid_mae: 0.24648 |  0:00:53s\n",
            "epoch 27 | loss: 9.8376  | train_mae: 0.18125 | valid_mae: 0.159   |  0:00:54s\n",
            "epoch 28 | loss: 9.83575 | train_mae: 0.12006 | valid_mae: 0.12088 |  0:00:56s\n",
            "epoch 29 | loss: 16.42812| train_mae: 0.09453 | valid_mae: 0.10164 |  0:00:59s\n",
            "epoch 30 | loss: 5.77927 | train_mae: 0.07758 | valid_mae: 0.08233 |  0:01:01s\n",
            "epoch 31 | loss: 5.29195 | train_mae: 0.06135 | valid_mae: 0.06866 |  0:01:03s\n",
            "epoch 32 | loss: 2.49575 | train_mae: 0.05157 | valid_mae: 0.05323 |  0:01:05s\n",
            "epoch 33 | loss: 2.10529 | train_mae: 0.03872 | valid_mae: 0.03826 |  0:01:07s\n",
            "epoch 34 | loss: 4.14193 | train_mae: 0.05621 | valid_mae: 0.0503  |  0:01:09s\n",
            "epoch 35 | loss: 2.64367 | train_mae: 0.02839 | valid_mae: 0.02381 |  0:01:11s\n",
            "epoch 36 | loss: 1.19788 | train_mae: 0.02578 | valid_mae: 0.02249 |  0:01:13s\n",
            "epoch 37 | loss: 1.37409 | train_mae: 0.02599 | valid_mae: 0.02316 |  0:01:15s\n",
            "epoch 38 | loss: 1.38288 | train_mae: 0.03235 | valid_mae: 0.02853 |  0:01:17s\n",
            "epoch 39 | loss: 1.37841 | train_mae: 0.0242  | valid_mae: 0.02187 |  0:01:19s\n",
            "epoch 40 | loss: 1.22897 | train_mae: 0.022   | valid_mae: 0.01853 |  0:01:21s\n",
            "epoch 41 | loss: 1.19012 | train_mae: 0.02324 | valid_mae: 0.01842 |  0:01:23s\n",
            "epoch 42 | loss: 1.30652 | train_mae: 0.02176 | valid_mae: 0.01586 |  0:01:25s\n",
            "epoch 43 | loss: 7.01977 | train_mae: 0.03012 | valid_mae: 0.02315 |  0:01:27s\n",
            "epoch 44 | loss: 2.20351 | train_mae: 0.06095 | valid_mae: 0.0469  |  0:01:29s\n",
            "epoch 45 | loss: 2.1389  | train_mae: 0.03397 | valid_mae: 0.02295 |  0:01:31s\n",
            "epoch 46 | loss: 2.36018 | train_mae: 0.02393 | valid_mae: 0.01655 |  0:01:33s\n",
            "epoch 47 | loss: 1.3939  | train_mae: 0.02494 | valid_mae: 0.01752 |  0:01:35s\n",
            "epoch 48 | loss: 1.85577 | train_mae: 0.02236 | valid_mae: 0.01629 |  0:01:37s\n",
            "epoch 49 | loss: 1.6331  | train_mae: 0.02013 | valid_mae: 0.015   |  0:01:39s\n",
            "epoch 50 | loss: 1.14113 | train_mae: 0.02191 | valid_mae: 0.01913 |  0:01:41s\n",
            "epoch 51 | loss: 1.08169 | train_mae: 0.02237 | valid_mae: 0.01811 |  0:01:43s\n",
            "epoch 52 | loss: 1.31162 | train_mae: 0.02027 | valid_mae: 0.01647 |  0:01:45s\n",
            "epoch 53 | loss: 1.04007 | train_mae: 0.0218  | valid_mae: 0.01659 |  0:01:47s\n",
            "epoch 54 | loss: 1.02809 | train_mae: 0.02079 | valid_mae: 0.0164  |  0:01:49s\n",
            "epoch 55 | loss: 1.2657  | train_mae: 0.02561 | valid_mae: 0.01885 |  0:01:51s\n",
            "epoch 56 | loss: 1.07347 | train_mae: 0.02352 | valid_mae: 0.01856 |  0:01:53s\n",
            "epoch 57 | loss: 1.16126 | train_mae: 0.02499 | valid_mae: 0.02062 |  0:01:55s\n",
            "epoch 58 | loss: 1.1149  | train_mae: 0.02172 | valid_mae: 0.01723 |  0:01:57s\n",
            "epoch 59 | loss: 1.63361 | train_mae: 0.02437 | valid_mae: 0.01796 |  0:01:59s\n",
            "epoch 60 | loss: 1.07497 | train_mae: 0.01647 | valid_mae: 0.01372 |  0:02:01s\n",
            "epoch 61 | loss: 1.03476 | train_mae: 0.01775 | valid_mae: 0.01253 |  0:02:03s\n",
            "epoch 62 | loss: 1.06538 | train_mae: 0.01628 | valid_mae: 0.0145  |  0:02:06s\n",
            "epoch 63 | loss: 1.44996 | train_mae: 0.01663 | valid_mae: 0.01568 |  0:02:07s\n",
            "epoch 64 | loss: 1.69701 | train_mae: 0.01693 | valid_mae: 0.01391 |  0:02:09s\n",
            "epoch 65 | loss: 0.95543 | train_mae: 0.02216 | valid_mae: 0.01868 |  0:02:11s\n",
            "epoch 66 | loss: 1.19265 | train_mae: 0.01652 | valid_mae: 0.01533 |  0:02:13s\n",
            "epoch 67 | loss: 1.05339 | train_mae: 0.01548 | valid_mae: 0.0167  |  0:02:15s\n",
            "epoch 68 | loss: 1.07354 | train_mae: 0.01815 | valid_mae: 0.01479 |  0:02:17s\n",
            "epoch 69 | loss: 1.05802 | train_mae: 0.01903 | valid_mae: 0.01672 |  0:02:19s\n",
            "epoch 70 | loss: 1.14241 | train_mae: 0.02068 | valid_mae: 0.01832 |  0:02:21s\n",
            "epoch 71 | loss: 0.97105 | train_mae: 0.01585 | valid_mae: 0.01359 |  0:02:23s\n",
            "epoch 72 | loss: 1.33166 | train_mae: 0.01842 | valid_mae: 0.01282 |  0:02:26s\n",
            "epoch 73 | loss: 1.09705 | train_mae: 0.01839 | valid_mae: 0.01463 |  0:02:31s\n",
            "epoch 74 | loss: 0.93991 | train_mae: 0.02172 | valid_mae: 0.01822 |  0:02:35s\n",
            "epoch 75 | loss: 0.96978 | train_mae: 0.01821 | valid_mae: 0.01499 |  0:02:38s\n",
            "epoch 76 | loss: 1.29038 | train_mae: 0.01717 | valid_mae: 0.01452 |  0:02:42s\n",
            "epoch 77 | loss: 0.98021 | train_mae: 0.01525 | valid_mae: 0.01349 |  0:02:47s\n",
            "epoch 78 | loss: 0.9296  | train_mae: 0.01665 | valid_mae: 0.01185 |  0:02:49s\n",
            "epoch 79 | loss: 1.0211  | train_mae: 0.02278 | valid_mae: 0.01855 |  0:02:51s\n",
            "epoch 80 | loss: 0.93277 | train_mae: 0.01837 | valid_mae: 0.01557 |  0:02:53s\n",
            "epoch 81 | loss: 1.01773 | train_mae: 0.01797 | valid_mae: 0.01366 |  0:02:55s\n",
            "epoch 82 | loss: 0.97611 | train_mae: 0.0204  | valid_mae: 0.01612 |  0:02:56s\n",
            "epoch 83 | loss: 0.94845 | train_mae: 0.01797 | valid_mae: 0.01338 |  0:02:59s\n",
            "epoch 84 | loss: 0.83776 | train_mae: 0.01699 | valid_mae: 0.01236 |  0:03:01s\n",
            "epoch 85 | loss: 1.02342 | train_mae: 0.0208  | valid_mae: 0.01433 |  0:03:03s\n",
            "epoch 86 | loss: 1.01088 | train_mae: 0.0155  | valid_mae: 0.01174 |  0:03:05s\n",
            "epoch 87 | loss: 0.90593 | train_mae: 0.018   | valid_mae: 0.01375 |  0:03:07s\n",
            "epoch 88 | loss: 0.91249 | train_mae: 0.01821 | valid_mae: 0.01576 |  0:03:08s\n",
            "epoch 89 | loss: 0.82113 | train_mae: 0.01658 | valid_mae: 0.01262 |  0:03:10s\n",
            "epoch 90 | loss: 1.43371 | train_mae: 0.01862 | valid_mae: 0.01486 |  0:03:13s\n",
            "epoch 91 | loss: 1.29021 | train_mae: 0.01945 | valid_mae: 0.01667 |  0:03:15s\n",
            "epoch 92 | loss: 0.97531 | train_mae: 0.01566 | valid_mae: 0.01475 |  0:03:17s\n",
            "epoch 93 | loss: 1.00798 | train_mae: 0.01678 | valid_mae: 0.01487 |  0:03:18s\n",
            "epoch 94 | loss: 0.89346 | train_mae: 0.01672 | valid_mae: 0.01333 |  0:03:20s\n",
            "epoch 95 | loss: 1.25364 | train_mae: 0.01618 | valid_mae: 0.01399 |  0:03:22s\n",
            "epoch 96 | loss: 1.36696 | train_mae: 0.01706 | valid_mae: 0.01307 |  0:03:25s\n",
            "epoch 97 | loss: 0.73409 | train_mae: 0.01794 | valid_mae: 0.01356 |  0:03:27s\n",
            "epoch 98 | loss: 0.82665 | train_mae: 0.01873 | valid_mae: 0.01598 |  0:03:29s\n",
            "epoch 99 | loss: 1.0824  | train_mae: 0.01736 | valid_mae: 0.01365 |  0:03:30s\n",
            "Stop training because you reached max_epochs = 100 with best_epoch = 86 and best_valid_mae = 0.01174\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-09-05 05:53:29,742] Trial 2 finished with value: 1.0823955535888672 and parameters: {'n_d': 29, 'n_a': 16, 'n_steps': 5, 'gamma': 1.7388756312377902, 'lambda_sparse': 3.1534474240913024e-06, 'batch_size': 64, 'mask_type': 'entmax', 'emb': 15, 'momentum': 0.5142848494131601, 'learning_rate': 0.011046385775149133, 'weight_decay': 1.7536412970947171e-06, 'scheduler_gamma': 0.9689897207687074, 'step_size': 5, 'virtual_batch_size': 32, 'optimizer_type': 'adamw', 'p': 0.07198264673935191}. Best is trial 0 with value: 0.16774559617042542.\n",
            "/usr/local/lib/python3.12/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 1078.00094| train_mae: 15.37752| valid_mae: 16.66172|  0:00:01s\n",
            "epoch 1  | loss: 310.02507| train_mae: 19.20212| valid_mae: 24.58351|  0:00:02s\n",
            "epoch 2  | loss: 213.97578| train_mae: 139.44009| valid_mae: 139.16814|  0:00:04s\n",
            "epoch 3  | loss: 120.05261| train_mae: 232.64221| valid_mae: 231.66821|  0:00:05s\n",
            "epoch 4  | loss: 82.79048| train_mae: 60.74608| valid_mae: 61.25182|  0:00:07s\n",
            "epoch 5  | loss: 54.43558| train_mae: 129.54793| valid_mae: 128.53545|  0:00:08s\n",
            "epoch 6  | loss: 62.38545| train_mae: 41.90364| valid_mae: 42.27773|  0:00:09s\n",
            "epoch 7  | loss: 29.40224| train_mae: 8.61691 | valid_mae: 9.24906 |  0:00:10s\n",
            "epoch 8  | loss: 31.29958| train_mae: 8.46839 | valid_mae: 7.89872 |  0:00:11s\n",
            "epoch 9  | loss: 22.10001| train_mae: 14.15624| valid_mae: 14.19948|  0:00:13s\n",
            "epoch 10 | loss: 22.20976| train_mae: 5.01511 | valid_mae: 5.63505 |  0:00:14s\n",
            "epoch 11 | loss: 9.65101 | train_mae: 7.63587 | valid_mae: 7.54035 |  0:00:16s\n",
            "epoch 12 | loss: 8.13014 | train_mae: 24.00174| valid_mae: 27.35791|  0:00:17s\n",
            "epoch 13 | loss: 6.02049 | train_mae: 5.08157 | valid_mae: 6.32164 |  0:00:19s\n",
            "epoch 14 | loss: 4.03477 | train_mae: 3.37341 | valid_mae: 3.22971 |  0:00:20s\n",
            "epoch 15 | loss: 3.39026 | train_mae: 8.66136 | valid_mae: 8.83152 |  0:00:21s\n",
            "epoch 16 | loss: 2.89452 | train_mae: 6.35497 | valid_mae: 5.12707 |  0:00:22s\n",
            "epoch 17 | loss: 2.85783 | train_mae: 4.97057 | valid_mae: 4.83391 |  0:00:24s\n",
            "epoch 18 | loss: 1.93913 | train_mae: 10.42899| valid_mae: 10.10258|  0:00:25s\n",
            "epoch 19 | loss: 2.67171 | train_mae: 3.23256 | valid_mae: 3.56787 |  0:00:26s\n",
            "epoch 20 | loss: 2.09646 | train_mae: 4.02837 | valid_mae: 4.2621  |  0:00:27s\n",
            "epoch 21 | loss: 1.86442 | train_mae: 2.69752 | valid_mae: 2.39809 |  0:00:29s\n",
            "epoch 22 | loss: 1.7173  | train_mae: 2.2434  | valid_mae: 2.07521 |  0:00:31s\n",
            "epoch 23 | loss: 1.13524 | train_mae: 1.66977 | valid_mae: 1.49095 |  0:00:32s\n",
            "epoch 24 | loss: 1.07856 | train_mae: 2.40548 | valid_mae: 2.36586 |  0:00:33s\n",
            "epoch 25 | loss: 1.609   | train_mae: 4.98035 | valid_mae: 4.34588 |  0:00:34s\n",
            "epoch 26 | loss: 1.12188 | train_mae: 1.1938  | valid_mae: 1.23383 |  0:00:36s\n",
            "epoch 27 | loss: 1.0165  | train_mae: 0.81887 | valid_mae: 0.90416 |  0:00:37s\n",
            "epoch 28 | loss: 0.99297 | train_mae: 0.63804 | valid_mae: 0.63761 |  0:00:38s\n",
            "epoch 29 | loss: 0.96439 | train_mae: 4.28802 | valid_mae: 4.48438 |  0:00:40s\n",
            "epoch 30 | loss: 0.85879 | train_mae: 2.55938 | valid_mae: 2.46339 |  0:00:41s\n",
            "epoch 31 | loss: 1.01553 | train_mae: 4.24481 | valid_mae: 4.29631 |  0:00:43s\n",
            "epoch 32 | loss: 0.89791 | train_mae: 5.26961 | valid_mae: 5.35979 |  0:00:44s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_params = par\n",
        "\n",
        "n_d = best_params['n_d']; n_a = best_params['n_a']; n_steps = best_params['n_steps']\n",
        "gamma = best_params['gamma']; lambda_sparse = best_params['lambda_sparse']\n",
        "mask_type = best_params['mask_type']; batch_size = best_params['batch_size']\n",
        "emb = best_params['emb']; p = best_params['p']\n",
        "momentum = best_params['momentum']; learning_rate = best_params['learning_rate']\n",
        "weight_decay = best_params['weight_decay']\n",
        "scheduler_gamma = best_params['scheduler_gamma']; step_size = best_params['step_size']\n",
        "virtual_batch_size = best_params['virtual_batch_size']; optimizer_type = best_params['optimizer_type']\n",
        "\n",
        "# Optimizer config (misma lógica)\n",
        "optimizer_fn, optimizer_params = optimizer_fn, optimizer_params = build_optimizer(optimizer_type, learning_rate, momentum, weight_decay)\n",
        "\n",
        "\n",
        "# Aumento y categóricas\n",
        "aug = RegressionSMOTE(p=p)\n",
        "cat_idxs = [i for i, f in enumerate(features) if f in CATEGORICAL_COLUMNS]\n",
        "cat_dims = [categorical_dims[f] for f in features if f in CATEGORICAL_COLUMNS]\n",
        "cat_emb_dim = [min(emb, (dim + 1)//2) for dim in cat_dims]\n",
        "\n",
        "clf = CustomTabNetRegressor(\n",
        "    cat_dims=cat_dims, cat_emb_dim=cat_emb_dim, cat_idxs=cat_idxs,\n",
        "    n_d=n_d, n_a=n_a, n_steps=n_steps, gamma=gamma, lambda_sparse=lambda_sparse,\n",
        "    mask_type=mask_type, optimizer_fn=optimizer_fn, optimizer_params=optimizer_params,\n",
        "    scheduler_params={\"gamma\": scheduler_gamma, \"step_size\": step_size},\n",
        "    scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
        "    momentum=momentum, verbose=True\n",
        ")\n",
        "\n",
        "clf.fit(\n",
        "    X_train=X_train, y_train=y_train[:,0:1],\n",
        "    eval_set=[(X_train, y_train[:,0:1]), (X_valid, y_valid[:,0:1])],\n",
        "    eval_name=['train', 'valid'], eval_metric=['mae'],\n",
        "    loss_fn=my_r2_score_fn,\n",
        "    max_epochs=200, patience=70,\n",
        "    batch_size=batch_size, virtual_batch_size=virtual_batch_size,\n",
        "    num_workers=1, drop_last=False, augmentations=aug,\n",
        ")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aKnXo3CNUsM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=clf.predict(X_test)\n",
        "y_pred_ = scaler.inverse_transform(y_pred)\n",
        "y_test_ = scaler.inverse_transform(y_test)\n",
        "# Plot 2\n",
        "r2_1 = r2_score(y_test, y_pred)\n",
        "print(f\" Test  -> R2={r2_1:.4f}\")"
      ],
      "metadata": {
        "id": "9avV4zk8Wafg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(clf, \"model.pth\")"
      ],
      "metadata": {
        "id": "FllT3OXdVjFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "M_explain, masks = clf.explain(X)\n",
        "M_explain, masks = clf.explain(X)\n",
        "aux=[]\n",
        "for i in masks:\n",
        "    aux.append(np.array(masks[i]))\n",
        "masks=np.array(aux)\n",
        "mask=masks.sum(axis=0)\n",
        "mask=mask-np.min(mask)\n",
        "mask=mask/np.max(mask)\n",
        "np.save('mask.npy',mask)"
      ],
      "metadata": {
        "id": "HhumdTQvWTHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "min_val = np.min(mask)\n",
        "max_val = np.max(mask)\n",
        "\n",
        "# Crear figura\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "# Gráfico de la máscara\n",
        "im = ax.imshow(mask, aspect='auto', cmap='viridis', vmin=min_val, vmax=max_val)\n",
        "ax.set_title(\"Relevancia\", fontsize=14)\n",
        "ax.set_xlabel(\"Características\", fontsize=12)\n",
        "ax.set_ylabel(\"Muestras\", fontsize=12)\n",
        "\n",
        "# Barra de color\n",
        "cbar = fig.colorbar(im, ax=ax, orientation='vertical', fraction=0.046, pad=0.04)\n",
        "cbar.set_label(\"Valores\", fontsize=12)\n",
        "\n",
        "# Mostrar la gráfica\n",
        "plt.tight_layout()\n",
        "plt.savefig('Mask.pdf')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QUqr1mAZWeEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from scipy.special import softmax\n",
        "\n",
        "# Asume que `mask`, `y_categorized`, y `columns` ya están definidos\n",
        "normalized_mask = softmax(mask, axis=1)\n",
        "class_titles = ['Todas las muestras', 'Riesgo Bajo', 'Riesgo Medio', 'Riesgo Alto', 'Riesgo Muy Alto']\n",
        "columns=df.columns\n",
        "# Crear la figura con 1 fila y 5 columnas\n",
        "fig, axes = plt.subplots(1, 5, figsize=(40, 15))\n",
        "\n",
        "for selected_class, ax in enumerate(axes):\n",
        "    if selected_class == 0:\n",
        "        # Todas las muestras\n",
        "        column_relevance = np.mean(normalized_mask, axis=0)\n",
        "        top_20_indices = np.argsort(column_relevance)[-20:]\n",
        "        top_20_columns = [columns[i] for i in top_20_indices]\n",
        "        top_20_mask = normalized_mask[:, top_20_indices]\n",
        "        sns.violinplot(data=top_20_mask, inner=\"box\", cut=0, ax=ax)\n",
        "        ax.set_title(class_titles[selected_class])\n",
        "    else:\n",
        "        # Filtrar por clase\n",
        "        class_idx = selected_class - 1\n",
        "        if np.any(y_categorized == class_idx):\n",
        "            column_relevance = np.mean(normalized_mask[y_categorized == class_idx], axis=0)\n",
        "            top_20_indices = np.argsort(column_relevance)[-20:]\n",
        "            top_20_columns = [columns[i] for i in top_20_indices]\n",
        "            top_20_mask = normalized_mask[y_categorized == class_idx][:, top_20_indices]\n",
        "            sns.violinplot(data=top_20_mask, inner=\"box\", cut=0, ax=ax)\n",
        "            ax.set_title(class_titles[selected_class])\n",
        "        else:\n",
        "            ax.text(0.5, 0.5, f'No hay datos para\\n{class_titles[selected_class]}',\n",
        "                    fontsize=14, ha='center', va='center')\n",
        "            ax.set_axis_off()\n",
        "\n",
        "    ax.set_xticks(range(len(top_20_columns)))\n",
        "    ax.set_xticklabels(top_20_columns, rotation=90, fontsize=8)\n",
        "    ax.set_ylabel(\"Valores\", fontsize=10)\n",
        "    ax.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('violin.pdf')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "HFwANYm-pM-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_dataframe(redmt, df, label_encoders, df1, ind,tip,s,scolumns):\n",
        "    \"\"\"\n",
        "    Procesa un DataFrame `redmt` usando coordenadas y LabelEncoders, y devuelve un DataFrame resultante.\n",
        "\n",
        "    Args:\n",
        "        redmt (pd.DataFrame): DataFrame base con información de referencia.\n",
        "        df (pd.DataFrame): DataFrame con coordenadas para encontrar vecinos cercanos.\n",
        "        label_encoders (dict): Diccionario con `LabelEncoder` para columnas categóricas.\n",
        "        df1 (pd.DataFrame): DataFrame con la fila de interés.\n",
        "        ind (int): Índice de la fila de interés en `df1`.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame resultante con los datos procesados.\n",
        "    \"\"\"\n",
        "    # Convertir las columnas de fecha\n",
        "    df1['inicio'] = pd.to_datetime(df1['inicio'])\n",
        "    df1['FECHA_C'] = df1['inicio'].dt.to_period('M')\n",
        "\n",
        "    # Seleccionar la fila de interés de `df1` (por índice)\n",
        "    row_of_interest = df1.loc[[ind]].copy()\n",
        "    #print('1',row_of_interest[['LATITUD','LONGITUD']].values)\n",
        "    #row_of_interest[scolumns]=np.nan\n",
        "    # Vaciar los valores de las columnas en `scolumns`\n",
        "    #for col in scolumns:\n",
        "    #    if col in row_of_interest.columns:\n",
        "    #        row_of_interest[col] = np.nan\n",
        "\n",
        "    # Extraer las listas de coordenadas y equipos desde la fila de interés\n",
        "    if s==0:\n",
        "        #aux = eval(row_of_interest.loc[ind, 'TRAMOS_AGUAS_ABAJO'])\n",
        "        aux=  list(eval(row_of_interest.loc[ind,'TRAMOS_AGUAS_ABAJO_CODES']))\n",
        "    else:\n",
        "        aux = eval(row_of_interest.loc[ind, 'EQUIPOS_PUNTOS'])\n",
        "\n",
        "\n",
        "    # DataFrame para almacenar las nuevas filas\n",
        "    new_rows = []\n",
        "    # Iterar sobre cada elemento de `aux` para filtrar y duplicar\n",
        "    for i in aux:\n",
        "        # Filtrar `redmt` según las condiciones dadas\n",
        "        if s==0:\n",
        "            filtered_row = redmt[\n",
        "              (redmt['FECHA_C'] == row_of_interest.loc[ind, 'FECHA_C']) &\n",
        "              (redmt['equipo_ope']== i)\n",
        "                ]\n",
        "\n",
        "        else:\n",
        "            filtered_row = redmt[\n",
        "              (redmt['FECHA_C'] == row_of_interest.loc[ind, 'FECHA_C']) &\n",
        "              (redmt['LATITUD'] == i[0]) &\n",
        "              (redmt['LONGITUD'] == i[1])]\n",
        "\n",
        "\n",
        "        #print('2',filtered_row[['LATITUD','LONGITUD']].values)\n",
        "        # Si hay filas que cumplen la condición, reemplazar columnas en la fila de interés\n",
        "        if not filtered_row.empty:\n",
        "            for _, row in filtered_row.iterrows():\n",
        "                #print(3,redmt.columns)\n",
        "                # Crear una copia de la fila de interés y reemplazar las columnas correspondientes\n",
        "                temp_row = row_of_interest.copy()\n",
        "                temp_row[redmt.columns] = row.values  # Reemplaza las columnas de redmt\n",
        "                #temp_row['LATITUD'] = np.float64(i[0])  # Asegura precisión en la asignación\n",
        "                #temp_row['LONGITUD'] = np.float64(i[1])\n",
        "                new_rows.append(temp_row)\n",
        "    if not new_rows:\n",
        "        # Retornar un DataFrame vacío con las columnas esperadas\n",
        "        aux1=pd.DataFrame(columns=df1.columns)\n",
        "        aux1.drop(['inicio_evento', 'h0-solar_rad', 'h0-uv', 'h1-solar_rad', 'h1-uv', 'h2-solar_rad', 'h2-uv', 'h3-solar_rad', 'h3-uv',\n",
        "            'h4-solar_rad', 'h4-uv', 'h5-solar_rad', 'h5-uv', 'h19-solar_rad', 'h19-uv', 'h20-solar_rad', 'h20-uv',\n",
        "            'h21-solar_rad', 'h21-uv', 'h22-solar_rad', 'h22-uv', 'h23-solar_rad', 'h23-uv', 'evento', 'fin', 'inicio',\n",
        "            'cnt_usus', 'DEP', 'MUN', 'FECHA', 'NIVEL_C', 'VALOR_C', 'TRAMOS_AGUAS_ABAJO', 'EQUIPOS_PUNTOS',\n",
        "            'PUNTOS_POLIGONO', 'LONGITUD2', 'LATITUD2', 'FECHA_C','TRAMOS_AGUAS_ABAJO_CODES','ORDER_'],\n",
        "           inplace=True, axis=1)\n",
        "        aux1.drop(target, axis=1, inplace=True)\n",
        "        return pd.DataFrame(columns=scolumns).values,aux1\n",
        "    # Concatenar todas las nuevas filas generadas\n",
        "    result_df = pd.concat(new_rows, ignore_index=True)\n",
        "    result_df=enriquecer_eventos_con_rayos_y_vegetacion(result_df, Rayos, Vegetacion,ventana_dias= 24,veg_vars=['NOM_COMUN','ESTADO_INICIAL','LADO_RED','DAP_ESTIM','LONG_INTER','TIPO_INTER', 'NIVEL_RIES'])\n",
        "\n",
        "    bad_types = (list, dict, set)\n",
        "    hashable_cols = [c for c in result_df.columns\n",
        "                    if not result_df[c].apply(lambda v: isinstance(v, bad_types)).any()]\n",
        "    result_df.drop_duplicates(subset=hashable_cols, inplace=True)\n",
        "\n",
        "    result_df['LATITUD'] = result_df['LATITUD'].astype('float64')\n",
        "    result_df['LONGITUD'] = result_df['LONGITUD'].astype('float64')\n",
        "\n",
        "    result_df1 =result_df.copy()\n",
        "    result_df1['LATITUD'] = result_df1['LATITUD'].astype('float64')\n",
        "    result_df1['LONGITUD'] = result_df1['LONGITUD'].astype('float64')\n",
        "\n",
        "\n",
        "    # Codificar las columnas categóricas usando los LabelEncoder definidos en `label_encoders`\n",
        "    for col, le in label_encoders.items():\n",
        "      if col in result_df.columns:  # Verificar que la columna exista en `result_df`\n",
        "        if col in redmt.columns:  # Si la columna pertenece a redmt\n",
        "            result_df[col] = result_df[col].apply(\n",
        "                lambda x: le.transform([x])[0] if x in le.classes_ else np.nan\n",
        "            )\n",
        "        else:  # Si no pertenece a redmt\n",
        "            result_df[col] = result_df[col].fillna(\"no aplica\")  # Rellenar NaN con \"no aplica\"\n",
        "            result_df[col] = result_df[col].apply(\n",
        "                lambda x: le.transform([x])[0] if x in le.classes_ else 0\n",
        "            )\n",
        "\n",
        "\n",
        "    # Reemplazar valores NaN en columnas categóricas usando el valor más cercano\n",
        "    categorical_columns = redmt.select_dtypes(include=['object', 'category']).columns\n",
        "\n",
        "    # Preparar las coordenadas (LATITUD y LONGITUD) de `df`\n",
        "    df_coords = df[['LATITUD', 'LONGITUD']].dropna()\n",
        "\n",
        "    # Modelo de vecinos más cercanos\n",
        "    nbrs = NearestNeighbors(n_neighbors=1, algorithm='auto').fit(df_coords)\n",
        "\n",
        "    # Recorrer las columnas categóricas de result_df\n",
        "    for col in result_df.columns:\n",
        "        if col in redmt.columns:  # Verificar si la columna pertenece a redmt\n",
        "            nan_indices = result_df[result_df[col].isna()].index  # Índices con NaN en la columna\n",
        "            for idx in nan_indices:\n",
        "                # Coordenadas de la fila con NaN\n",
        "                query_coords = result_df.loc[idx, ['LATITUD', 'LONGITUD']].values.reshape(1, -1)\n",
        "                with warnings.catch_warnings():\n",
        "                    warnings.filterwarnings(\"ignore\", message=\"X does not have valid feature names, but NearestNeighbors was fitted with feature names\")\n",
        "                    distance, neighbor_idx = nbrs.kneighbors(query_coords)\n",
        "                closest_idx = df_coords.iloc[neighbor_idx[0][0]].name\n",
        "                # Reemplazar el valor NaN con el valor del vecino más cercano\n",
        "                result_df.at[idx, col] = df.at[closest_idx, col]\n",
        "        #else:\n",
        "            #result_df[col].astype(str).fillna(\"no aplica\",inplace=True)\n",
        "    for col in NUMERIC_COLUMNS:\n",
        "        max_value = max_values[col]\n",
        "        # Rellenar valores y ajustar el tipo de datos\n",
        "        result_df[col] = result_df[col].fillna(-10 * max_value).astype('float64')\n",
        "\n",
        "    result_df['tipo_equi_ope'] = tip\n",
        "    result_df.drop(['inicio_evento', 'h0-solar_rad', 'h0-uv', 'h1-solar_rad', 'h1-uv', 'h2-solar_rad', 'h2-uv', 'h3-solar_rad', 'h3-uv',\n",
        "            'h4-solar_rad', 'h4-uv', 'h5-solar_rad', 'h5-uv', 'h19-solar_rad', 'h19-uv', 'h20-solar_rad', 'h20-uv',\n",
        "            'h21-solar_rad', 'h21-uv', 'h22-solar_rad', 'h22-uv', 'h23-solar_rad', 'h23-uv', 'evento', 'fin', 'inicio',\n",
        "            'cnt_usus', 'DEP', 'MUN', 'FECHA', 'NIVEL_C', 'VALOR_C', 'TRAMOS_AGUAS_ABAJO', 'EQUIPOS_PUNTOS',\n",
        "            'PUNTOS_POLIGONO', 'LONGITUD2', 'LATITUD2', 'FECHA_C','TRAMOS_AGUAS_ABAJO_CODES','ORDER_'],\n",
        "           inplace=True, axis=1)\n",
        "    result_df.drop(target, axis=1, inplace=True)\n",
        "    result_df1.drop(['inicio_evento', 'h0-solar_rad', 'h0-uv', 'h1-solar_rad', 'h1-uv', 'h2-solar_rad', 'h2-uv', 'h3-solar_rad', 'h3-uv',\n",
        "            'h4-solar_rad', 'h4-uv', 'h5-solar_rad', 'h5-uv', 'h19-solar_rad', 'h19-uv', 'h20-solar_rad', 'h20-uv',\n",
        "            'h21-solar_rad', 'h21-uv', 'h22-solar_rad', 'h22-uv', 'h23-solar_rad', 'h23-uv', 'evento', 'fin', 'inicio',\n",
        "            'cnt_usus', 'DEP', 'MUN', 'FECHA', 'NIVEL_C', 'VALOR_C', 'TRAMOS_AGUAS_ABAJO', 'EQUIPOS_PUNTOS',\n",
        "            'PUNTOS_POLIGONO', 'LONGITUD2', 'LATITUD2', 'FECHA_C','TRAMOS_AGUAS_ABAJO_CODES','ORDER_'],\n",
        "           inplace=True, axis=1)\n",
        "    result_df1.drop(target, axis=1, inplace=True)\n",
        "    result_df1.drop_duplicates(inplace=True)\n",
        "    result_df.drop_duplicates(inplace=True)\n",
        "    return result_df.values,result_df1"
      ],
      "metadata": {
        "id": "AVWBwcwSpo44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "redmt = pd.read_pickle('/content/CHEC/Data_CHEC/REDMT_1.pkl')\n",
        "redmt['FECHA']=pd.to_datetime(redmt['FECHA'])\n",
        "redmt['FECHA_C']=redmt['FECHA'].dt.to_period('M')\n",
        "redmt.rename(columns={'CODE':'equipo_ope'}, inplace=True)\n",
        "apoyos = pd.read_pickle('/content/CHEC/Data_CHEC/APOYOS.pkl')\n",
        "apoyos['FECHA']=pd.to_datetime(apoyos['FECHA'])\n",
        "apoyos['FECHA_C']=apoyos['FECHA'].dt.to_period('M')\n",
        "apoyos.rename(columns={'CODE':'equipo_ope'}, inplace=True)\n",
        "switches = pd.read_pickle('/content/CHEC/Data_CHEC/SWITCHES.pkl')\n",
        "switches['FECHA']=pd.to_datetime(switches['FECHA'])\n",
        "switches['FECHA_C']=switches['FECHA'].dt.to_period('M')\n",
        "trafos = pd.read_pickle('/content/CHEC/Data_CHEC/TRAFOS.pkl')\n",
        "trafos['FECHA']=pd.to_datetime(trafos['FECHA'])\n",
        "trafos['FECHA_C']=trafos['FECHA'].dt.to_period('M')\n",
        "scolumns = list(\n",
        "    set(redmt.columns)\n",
        "    .union(set(apoyos.columns))\n",
        "    .union(set(trafos.columns))\n",
        "    .union(set(switches.columns))\n",
        ")"
      ],
      "metadata": {
        "id": "98E1JyQsqkGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ind=0\n",
        "a1,a1_df = process_dataframe(trafos, df, label_encoders, df1, ind=ind,tip=2,s=1,scolumns=scolumns)\n",
        "del trafos\n",
        "a2,a2_df = process_dataframe(switches, df, label_encoders, df1, ind=ind,tip=0,s=1,scolumns=scolumns)\n",
        "del switches\n",
        "a3,a3_df = process_dataframe(redmt, df, label_encoders, df1, ind=ind,tip=1,s=0,scolumns=scolumns)\n",
        "del redmt\n",
        "a4,a4_df = process_dataframe(apoyos, df, label_encoders, df1, ind=ind,tip=2,s=1,scolumns=scolumns)\n",
        "del apoyos\n",
        "columns=df.columns\n",
        "arrays_to_concatenate = [arr for arr in (a1, a2, a3, a4) if arr.size > 0]\n",
        "a = np.concatenate(arrays_to_concatenate, axis=0)\n",
        "y_e=clf.predict(a)\n",
        "y_e=y_e.flatten()"
      ],
      "metadata": {
        "id": "eOvtb13HqNJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.concat([a1_df,a2_df,a3_df,a4_df],axis=0)['LONG_INTER_median']"
      ],
      "metadata": {
        "id": "ZpKiwJW7rqU_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}